{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Synthetic Test Datasets\n",
    "\n",
    "**Why use Synthetic Test Datasets?**\n",
    "\n",
    "Evaluating the performance of RAG (Retrieval-Augmented Generation) augmented pipelines is crucial.\n",
    "\n",
    "However, manually creating hundreds of QA (Question-Answer-Context) samples from documents can be time-consuming and labor-intensive. Additionally, human-generated questions may struggle to reach the level of complexity needed for thorough evaluation, ultimately affecting the quality of the assessment.\n",
    "\n",
    "Using synthetic data generation can reduce developer time in the data aggregation process **by up to 90%**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from pdfplumber) (10.4.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (42.0.8)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
      "Downloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m124.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
      "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.5 pypdfium2-4.30.1\n"
     ]
    }
   ],
   "source": [
    "! pip install pdfplumber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class PDFLoader:\n",
    "    def __init__(self, file_path: str, start_page: int = None, end_page: int = None):\n",
    "        self.file_path = file_path\n",
    "        self.start_page = start_page\n",
    "        self.end_page = end_page\n",
    "\n",
    "    def load(self) -> Dict[str, Any]:\n",
    "        combined_text = \"\"\n",
    "        metadata = {}\n",
    "\n",
    "        with pdfplumber.open(self.file_path) as pdf:\n",
    "            total_pages = len(pdf.pages)\n",
    "\n",
    "            start = (self.start_page or 1) - 1\n",
    "            end = min(self.end_page or total_pages, total_pages)\n",
    "\n",
    "            for page_num in range(start, end):\n",
    "                page = pdf.pages[page_num]\n",
    "                text = page.extract_text()\n",
    "                combined_text += text + \"\\n\"\n",
    "\n",
    "            metadata = {\n",
    "                \"source\": self.file_path,\n",
    "                \"filename\": self.file_path,\n",
    "                \"total_pages\": total_pages,\n",
    "                \"extracted_pages\": f\"{start + 1}-{end}\"\n",
    "            }\n",
    "\n",
    "            for key, value in pdf.metadata.items():\n",
    "                if isinstance(value, (str, int)):\n",
    "                    metadata[key] = value\n",
    "\n",
    "        return {\n",
    "            \"page_content\": combined_text.strip(),\n",
    "            \"metadata\": metadata\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Used for Practice\n",
    "\n",
    "Amazon Bedrock Manual Documentation (https://docs.aws.amazon.com/bedrock/latest/userguide/)\n",
    "\n",
    "- Link: https://d1jp7kj5nqor8j.cloudfront.net/bedrock-manual.pdf\n",
    "- File name: `bedrock-manual.pdf`\n",
    "\n",
    "_Please copy the downloaded file to the data folder for the practice session_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PDFLoader(\"data/bedrock-ug.pdf\", start_page=19, end_page=100)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Optional\n",
    "\n",
    "def split_text(text: str, chunk_size: int = 1000, chunk_overlap: int = 100, separators: Optional[List[str]] = None) -> List[str]:\n",
    "    separators = separators or [\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "\n",
    "    def _split_text_recursive(text: str, separators: List[str]) -> List[str]:\n",
    "        if not separators:\n",
    "            return [text]\n",
    "\n",
    "        separator = separators[0]\n",
    "        splits = re.split(f\"({re.escape(separator)})\", text)\n",
    "        splits = [\"\".join(splits[i:i+2]) for i in range(0, len(splits), 2)]\n",
    "\n",
    "        final_chunks = []\n",
    "        current_chunk = \"\"\n",
    "\n",
    "        for split in splits:\n",
    "            if len(current_chunk) + len(split) <= chunk_size:\n",
    "                current_chunk += split\n",
    "            else:\n",
    "                if current_chunk:\n",
    "                    final_chunks.append(current_chunk)\n",
    "                if len(split) > chunk_size:\n",
    "                    subsplits = _split_text_recursive(split, separators[1:])\n",
    "                    final_chunks.extend(subsplits)\n",
    "                else:\n",
    "                    current_chunk = split\n",
    "\n",
    "        if current_chunk:\n",
    "            final_chunks.append(current_chunk)\n",
    "\n",
    "        return final_chunks\n",
    "\n",
    "    chunks = _split_text_recursive(text, separators)\n",
    "\n",
    "    if chunk_overlap > 0:\n",
    "        overlapped_chunks = []\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            if i == 0:\n",
    "                overlapped_chunks.append(chunk)\n",
    "            else:\n",
    "                overlap_text = chunks[i-1][-chunk_overlap:]\n",
    "                overlapped_chunks.append(overlap_text + chunk)\n",
    "        chunks = overlapped_chunks\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = split_text(docs['page_content'], 1000, 0)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_with_metadata = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunks_with_metadata.append({\n",
    "        'content': chunk,\n",
    "        'metadata': {\n",
    "            'chunk_id': i,\n",
    "            'filename': docs['metadata'].get('filename', 'unknown')\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"Amazon Bedrock User Guide\\nWhat is Amazon Bedrock?\\nAmazon Bedrock is a fully managed service that makes high-performing foundation models (FMs)\\nfrom leading AI companies and Amazon available for your use through a unified API. You can\\nchoose from a wide range of foundation models to find the model that is best suited for your use\\ncase. Amazon Bedrock also offers a broad set of capabilities to build generative AI applications with\\nsecurity, privacy, and responsible AI. Using Amazon Bedrock, you can easily experiment with and\\nevaluate top foundation models for your use cases, privately customize them with your data using\\ntechniques such as fine-tuning and Retrieval Augmented Generation (RAG), and build agents that\\nexecute tasks using your enterprise systems and data sources.\\nWith Amazon Bedrock's serverless experience, you can get started quickly, privately customize\\nfoundation models with your own data, and easily and securely integrate and deploy them into\\n\",\n",
       " 'metadata': {'chunk_id': 0, 'filename': 'data/bedrock-ug.pdf'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_with_metadata[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Q&A Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.config import Config\n",
    "\n",
    "region = 'us-west-2'\n",
    "retry_config = Config(\n",
    "    region_name=region,\n",
    "    retries={\"max_attempts\": 10, \"mode\": \"standard\"}\n",
    ")\n",
    "boto3_client = boto3.client(\"bedrock-runtime\", region_name=region, config=retry_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from time import sleep\n",
    "\n",
    "def converse_with_bedrock(model_id, sys_prompt, usr_prompt):\n",
    "    temperature = 0.5\n",
    "    top_p = 0.9\n",
    "    inference_config = {\"temperature\": temperature, \"topP\": top_p}\n",
    "    response = boto3_client.converse(\n",
    "        modelId=model_id,\n",
    "        messages=usr_prompt, \n",
    "        system=sys_prompt,\n",
    "        inferenceConfig=inference_config,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def create_prompt(sys_template, user_template):\n",
    "    sys_prompt = [{\"text\": sys_template}]\n",
    "    usr_prompt = [{\"role\": \"user\", \"content\": [{\"text\": user_template}]}]\n",
    "    return sys_prompt, usr_prompt\n",
    "\n",
    "def get_context_chunks(chunks_with_metadata, start_id):\n",
    "    context_chunks = [\n",
    "        chunks_with_metadata[start_id]['content'],\n",
    "        chunks_with_metadata[start_id + 1]['content'],\n",
    "        chunks_with_metadata[start_id + 2]['content']\n",
    "    ]\n",
    "    return \" \".join(context_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Use \n",
    "\n",
    "LLM will generate Q&A dataset that conforms to the schema description in the tooluse config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_config = {\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"QuestionAnswerGenerator\",\n",
    "                \"description\": \"Generates questions and answers based on the given context.\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"question\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The generated question\"\n",
    "                            },\n",
    "                            \"answer\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The answer to the generated question\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"question\", \"answer\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converse_with_bedrock_tools(sys_prompt, usr_prompt, tool_config):\n",
    "    temperature = 0.0\n",
    "    top_p = 0.1\n",
    "    top_k = 1\n",
    "    inference_config = {\"temperature\": temperature, \"topP\": top_p}\n",
    "    additional_model_fields = {\"top_k\": top_k}\n",
    "    response = boto3_client.converse(\n",
    "        modelId=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "        messages=usr_prompt,\n",
    "        system=sys_prompt,\n",
    "        inferenceConfig=inference_config,\n",
    "        additionalModelRequestFields=additional_model_fields,\n",
    "        toolConfig=tool_config\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def parse_tool_use(message):\n",
    "    stop_reason = message['stopReason']\n",
    "\n",
    "    if stop_reason == 'tool_use':\n",
    "        tool_requests = message['output']['message']['content']\n",
    "        for tool_request in tool_requests:\n",
    "            if 'toolUse' in tool_request:\n",
    "                tool = tool_request['toolUse']\n",
    "\n",
    "                if tool['name'] == 'QuestionAnswerGenerator':\n",
    "                    return tool['input']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A Dataset Generation Instruction\n",
    "\n",
    "- `simple`: directly answerable questions from the given context\n",
    "- `complex`: reasoning questions and answers.\n",
    "\n",
    "_Modify the system/user prompts tailored to your dataset_\n",
    "\n",
    "Generated Q&A pair will be stored in `data/qa_dataset.jsonl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_dataset(chunks, num_pairs=5, output_file=\"data/sample_qa_dataset.jsonl\"):\n",
    "    total_chunks = len(chunks)\n",
    "    dataset = []\n",
    "\n",
    "    for i in range(num_pairs):\n",
    "        start_id = random.randint(0, total_chunks - 3)\n",
    "        context = get_context_chunks(chunks_with_metadata, start_id)\n",
    "\n",
    "        if i % 2 == 0:\n",
    "            sys_template = \"\"\"\n",
    "            You are an expert at generating practical questions based on given documentation.\n",
    "            Your task is to generate complex, reasoning questions and answers.\n",
    "\n",
    "            Follow these rules:\n",
    "            1. Generate questions that reflect real user information needs related to the document's subject matter (e.g., technical docs : feature availability, implementation details)\n",
    "            2. Ensure questions are relevant, concise, preferably under 25 words, and fully answerable with the provided information\n",
    "            3. Focus on extracting key information that users are likely to seek, while avoiding narrow or less important questions.\n",
    "            4. When provided with code blocks, focus on understanding the overall functionality rather than the specific syntax or variables. Feel free to request examples of how to use key APIs or features.\n",
    "            5. Do not use phrases like 'based on the provided context' or 'according to the context'.\n",
    "            \"\"\"\n",
    "            question_type = \"complex\"\n",
    "        else:\n",
    "            sys_template = \"\"\"\n",
    "            You are an expert at generating practical questions based on given documentation.\n",
    "            Your task is to create simple, directly answerable questions from the given context.\n",
    "\n",
    "            Follow these rules:\n",
    "            1. Generate questions that reflect real user information needs related to the document's subject matter (e.g., technical docs : feature availability, implementation details)\n",
    "            2. Ensure questions are relevant, concise, preferably under 10 words, and fully answerable with the provided information\n",
    "            3. Focus on extracting key information that users are likely to seek, while avoiding narrow or less important questions.\n",
    "            4. When provided with code blocks, focus on understanding the overall functionality rather than the specific syntax or variables. Feel free to request examples of how to use key APIs or features.\n",
    "            5. Do not use phrases like 'based on the provided context' or 'according to the context'.\n",
    "            \"\"\"\n",
    "            question_type = \"simple\"\n",
    "\n",
    "        user_template = f\"\"\"\n",
    "        Generate a {question_type} question and its answer based on the following context:\n",
    "\n",
    "        Context: {context}\n",
    "\n",
    "        Use the QuestionAnswerGenerator tool to provide the output.\n",
    "        \"\"\"\n",
    "\n",
    "        sys_prompt, user_prompt = create_prompt(sys_template, user_template)\n",
    "        response = converse_with_bedrock_tools(sys_prompt, user_prompt, tool_config)\n",
    "        qa_data = parse_tool_use(response)\n",
    "\n",
    "        if qa_data:\n",
    "            qa_item = {\n",
    "                \"question\": qa_data[\"question\"],\n",
    "                \"ground_truth\": qa_data[\"answer\"],\n",
    "                \"question_type\": question_type,\n",
    "                \"contexts\": context\n",
    "            }\n",
    "\n",
    "            print(qa_item)\n",
    "\n",
    "            with open(output_file, 'a') as f:\n",
    "                json.dump(qa_item, f)\n",
    "                f.write('\\n')\n",
    "\n",
    "            dataset.append(qa_item)\n",
    "\n",
    "        sleep(5)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'question': 'What command lists available foundation models in Amazon Bedrock?', \n",
    "'ground_truth': 'The command to list available foundation models in Amazon Bedrock is: aws bedrock list-foundation-models --region us-east-1', \n",
    "'question_type': 'simple', \n",
    "'contexts': 'This section guides you through trying out some common operations in Amazon Bedrock using the\\nAWS CLI to test that your permissions and authentication are set up properly. Before you run the\\nfollowing examples, you should check that you have fulfilled the following prerequisites:\\nPrerequisites\\n• You have an AWS account and a user or role with authentication set up and the necessary\\npermissions for Amazon Bedrock. Otherwise, follow the steps at Getting started with the API.\\n• You\\'ve requested access to the Amazon Titan Text G1 - Express model. Otherwise, follow the\\nsteps at Request access to an Amazon Bedrock foundation model.\\nRequest access to Amazon Bedrock models 18\\nAmazon Bedrock User Guide\\n• You\\'ve installed and set up authentication for the AWS CLI. To install the CLI, follow the steps at\\nInstall or update to the latest version of the AWS CLI. Verify that you\\'ve set up your credentials to\\nuse the CLI by following the steps at Get credentials to grant programmatic access.\\n Test that your permissions are set up properly for Amazon Bedrock, using a user or role that you set\\nup with the proper permissions.\\nTopics\\n• List the foundation models that Amazon Bedrock has to offer\\n• Submit a text prompt to a model and generate a text response with InvokeModel\\n• Submit a text prompt to a model and generate a text response with Converse\\nList the foundation models that Amazon Bedrock has to offer\\nThe following example runs the ListFoundationModels operation using an Amazon Bedrock\\nendpoint. ListFoundationModels lists the foundation models (FMs) that are available in\\nAmazon Bedrock in your region. In a terminal, run the following command:\\naws bedrock list-foundation-models --region us-east-1\\nIf the command is successful, the response returns a list of foundation models that are available in\\nAmazon Bedrock.\\nSubmit a text prompt to a model and generate a text response with InvokeModel\\nThe following example runs the InvokeModel operation using an Amazon Bedrock runtime\\n endpoint. InvokeModel lets you submit a prompt to generate a model response. In a terminal, run\\nthe following command:\\naws bedrock-runtime invoke-model \\\\\\n--model-id amazon.titan-text-express-v1 \\\\\\n--body \\'{\"inputText\": \"Describe the purpose of a \\\\\"hello world\\\\\" program in one line.\",\\n\"textGenerationConfig\" : {\"maxTokenCount\": 512, \"temperature\": 0.5, \"topP\": 0.9}}\\' \\\\\\n--cli-binary-format raw-in-base64-out \\\\\\ninvoke-model-output-text.txt\\nRun examples with the AWS CLI 19\\nAmazon Bedrock User Guide\\nIf the command is successful, the response generated by the model is written to the invoke-\\nmodel-output-text.txt file. The text response is returned in the outputText field, alongside\\naccompanying information.\\nSubmit a text prompt to a model and generate a text response with Converse\\nThe following example runs the Converse operation using an Amazon Bedrock runtime endpoint.\\nConverse lets you submit a prompt to generate a model response. We recommend using\\n'}\n",
    "\n",
    "'question': 'What are the key steps to set up and manage access for Amazon Bedrock in an existing AWS account, and how does this process differ from setting up access for a new administrative user?', \n",
    "'ground_truth': 'For an existing AWS account, the key steps to set up and manage access for Amazon Bedrock are:\\n\\n1. Create an IAM role with the AmazonBedrockFullAccess managed policy.\\n2. Create a custom policy to manage access to Amazon Bedrock models, including marketplace actions like ViewSubscriptions, Unsubscribe, and Subscribe.\\n3. Attach the custom policy to the Amazon Bedrock role.\\n4. Add users to the Amazon Bedrock role and grant them permissions to switch to this role.\\n\\nThis process differs from setting up access for a new administrative user in the following ways:\\n- For new users, you would configure access using the default IAM Identity Center directory.\\n- New administrative users receive a sign-in URL for the AWS access portal.\\n- Existing account setup focuses on creating and managing IAM roles, while new user setup involves creating IAM Identity Center users.\\n- The existing account method provides more granular control over permissions through custom policies, whereas the new user method relies more on predefined access levels within IAM Identity Center.', \n",
    "'question_type': 'complex', \n",
    "'contexts': 'Configure user access with the default IAM Identity Center directory in the AWS IAM Identity\\nCenter User Guide.\\nSign in as the user with administrative access\\n• To sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email\\naddress when you created the IAM Identity Center user.\\nFor help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in\\nthe AWS Sign-In User Guide.\\nTo learn more about IAM, see Identity and access management for Amazon Bedrock and the IAM\\nUser Guide.\\nAfter you have created an administrative user, proceed to I already have an AWS account to set up\\npermissions for Amazon Bedrock.\\nI already have an AWS account\\nUse IAM to create a role for with the necessary permissions to use Amazon Bedrock. You can then\\nadd users to this role to grant the permissions.\\nI already have an AWS account 7\\nAmazon Bedrock User Guide\\nTo create an Amazon Bedrock role\\n 1. Create a role with a name of your choice by following the steps at Creating a role to delegate\\npermissions to an IAM user in the IAM User Guide. When you reach the step to attach a policy\\nto the role, attach the AmazonBedrockFullAccess AWS managed policy.\\n2. Create a new policy to allow your role to manage access to Amazon Bedrock models. From the\\nfollowing list, select the link that corresponds to your method of choice and follow the steps.\\nUse the following JSON object as the policy.\\n• Creating IAM policies (console)\\n• Creating IAM policies (AWS CLI)\\n• Creating IAM policies (AWS API)\\n{\\n\"Version\": \"2012-10-17\",\\n\"Statement\": [\\n{\\n\"Sid\": \"MarketplaceBedrock\",\\n\"Effect\": \"Allow\",\\n\"Action\": [\\n\"aws-marketplace:ViewSubscriptions\",\\n\"aws-marketplace:Unsubscribe\",\\n\"aws-marketplace:Subscribe\"\\n],\\n\"Resource\": \"*\"\\n}\\n]\\n}\\n3. Attach the policy that you created in the last step to your Amazon Bedrock role by following\\nthe steps at Adding and removing IAM identity permissions.\\n To add users to the Amazon Bedrock role\\n1. For users to access an IAM role, you must add them to the role. You can add both users in your\\naccount or from other accounts. To grant users permissions to switch to the Amazon Bedrock\\nrole that you created, follow the steps at Granting a user permissions to switch roles and\\nspecify the Amazon Bedrock role as the Resource.\\nI already have an AWS account 8\\nAmazon Bedrock User Guide\\nNote\\nIf you need to create more users in your account so that you can give them access\\nto the Amazon Bedrock role, follow the steps in Creating an IAM user in your AWS\\naccount.\\n2. After you\\'ve granted a user permissions to use the Amazon Bedrock role, provide the user\\nwith role name and ID or alias of the account to which the role belongs. Then, guide the user\\nthrough how to switch to the role by following the instructions at Providing information to the\\nuser.\\nRequest access to an Amazon Bedrock foundation model\\n'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What are the key steps for granting a user access to Amazon Bedrock foundation models, and how does the process differ for users within your AWS account versus users from other accounts?', 'ground_truth': 'The process for granting a user access to Amazon Bedrock foundation models involves several key steps:\\n\\n1. Add users to the Amazon Bedrock role:\\n   - For users in your account: Grant permissions to switch roles by following the \"Granting a user permissions to switch roles\" procedure.\\n   - For users from other accounts: Add them directly to the role.\\n\\n2. Provide users with the Amazon Bedrock role name and account ID or alias.\\n\\n3. Guide users on how to switch to the role using the \"Providing information to the user\" instructions.\\n\\n4. Users must sign into the AWS Management Console and switch to the Amazon Bedrock role.\\n\\n5. In the Amazon Bedrock console, users request access to foundation models:\\n   - Navigate to the Model access page\\n   - Review the End User License Agreement (EULA) for desired models\\n   - Choose \"Modify model access\"\\n   - Select either \"Enable all models\" or \"Enable specific models\"\\n   - Submit the access request\\n\\n6. Wait for access to be granted, which may take several minutes.\\n\\nThe main difference in the process for users within your AWS account versus users from other accounts is in the initial step of adding them to the role. Internal users are granted permissions to switch roles, while external users are added directly to the role. Both types of users then follow the same steps to request access to the foundation models through the Amazon Bedrock console.', 'question_type': 'complex', 'contexts': \"To add users to the Amazon Bedrock role\\n1. For users to access an IAM role, you must add them to the role. You can add both users in your\\naccount or from other accounts. To grant users permissions to switch to the Amazon Bedrock\\nrole that you created, follow the steps at Granting a user permissions to switch roles and\\nspecify the Amazon Bedrock role as the Resource.\\nI already have an AWS account 8\\nAmazon Bedrock User Guide\\nNote\\nIf you need to create more users in your account so that you can give them access\\nto the Amazon Bedrock role, follow the steps in Creating an IAM user in your AWS\\naccount.\\n2. After you've granted a user permissions to use the Amazon Bedrock role, provide the user\\nwith role name and ID or alias of the account to which the role belongs. Then, guide the user\\nthrough how to switch to the role by following the instructions at Providing information to the\\nuser.\\nRequest access to an Amazon Bedrock foundation model\\n After setting up your Amazon Bedrock IAM role, you can sign into the Amazon Bedrock console and\\nrequest access to foundation models.\\nTo request access to an Amazon Bedrock FM\\n1. Sign into the AWS Management Console and switch to the Amazon Bedrock role that you set\\nup (or that was set up for you) by following the steps under To switch to a role (console) in\\nSwitching to a role (console).\\n2. Open the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/.\\n3. For the purposes of this tutorial, you should be in the US East (N. Virginia) (us-east-1) Region.\\nTo change regions, choose the Region name at the top right of the console, next to your IAM\\nrole. Then select US East (N. Virginia) (us-east-1).\\n4. Select Model access at the bottom of the left navigation pane.\\n5. On the Model access page, you can review the End User License Agreement (EULA) for models\\nin the EULA column in the Base models table.\\n6. Choose Modify model access.\\n7. Do one of the following:\\n • To request access to all models, choose Enable all models. On the page you're taken to,\\nthe checkboxes next to all the models will be filled.\\n• To request access to specific models, choose Enable specific models. On the page you're\\ntaken to, you have the following options:\\nRequest access to an Amazon Bedrock foundation model 9\\nAmazon Bedrock User Guide\\n• To request access to all models by a provider, select the checkbox next to the provider\\nname.\\n• To request access to one model, select the checkbox next to the model name.\\n8. For the purposes of the following tutorials, you should minimally request access to the\\nAmazon Titan Text G1 - Express and Amazon Titan Image Generator G1 V1 models. Then\\nchoose Next.\\n9. Review the models that you're requesting access to and the Terms. When you're ready, choose\\nSubmit to request access.\\n10. Access may take several minutes to complete. When access is granted to a model, the Access\\nstatus for that model willbecome Access granted.\\n\"}\n",
      "{'question': 'What is the recommended expiration time for IAM user access keys?', 'ground_truth': 'IAM recommends limiting access keys to 12 hours.', 'question_type': 'simple', 'contexts': 'How to configure access keys for an IAM user\\nIf you decide to use access keys for an IAM user, AWS recommends that you set an expiration for\\nthe IAM user by including a restrictive inline policy.\\nImportant\\nHeed the following warnings:\\n• Do NOT use your account\\'s root credentials to access AWS resources. These credentials\\nprovide unrestricted account access and are difficult to revoke.\\n• Do NOT put literal access keys or credential information in your application files. If you\\ndo, you create a risk of accidentally exposing your credentials if, for example, you upload\\nthe project to a public repository.\\n• Do NOT include files that contain credentials in your project area.\\n• Manage your access keys securely. Do not provide your access keys to unauthorized\\nparties, even to help find your account identifiers. By doing this, you might give someone\\npermanent access to your account.\\n• Be aware that any credentials stored in the shared AWS credentials file are stored in\\nplaintext.\\n For more details, see Best practices for managing AWS access keys in the AWS General Reference.\\nCreate an IAM user\\n1. On the AWS Management Console Home page, select the IAM service or navigate to the IAM\\nconsole at https://console.aws.amazon.com/iam/.\\nGet credentials to grant programmatic access 15\\nAmazon Bedrock User Guide\\n2. In the navigation pane, select Users and then select Create user.\\n3. Follow the guidance in the IAM console to set up a programmatic user (without access to the\\nAWS Management Console) and without permissions.\\nRestrict user access to a limited time window\\nAny IAM user access keys that you create are long-term credentials. To ensure that these\\ncredentials expire in case they are mishandled, you can make these credentials time-bound by\\ncreating an inline policy that specifies a date after which the keys will no longer be valid.\\n1. Open the IAM user that you just created. In the Permissions tab, choose Add permissions and\\nthen choose Create inline policy.\\n 2. In the JSON editor, specify the following permissions. To use this policy, replace the value for\\naws:CurrentTime timestamp value in the example policy with your own end date.\\nNote\\nIAM recommends that you limit your access keys to 12 hours.\\n{\\n\"Version\": \"2012-10-17\",\\n\"Statement\": [\\n{\\n\"Effect\": \"Deny\",\\n\"Action\": \"*\",\\n\"Resource\": \"*\",\\n\"Condition\": {\\n\"DateGreaterThan\": {\\n\"aws:CurrentTime\": \"2024-01-01T00:00:000\"\\n}\\n}\\n}\\n]\\n}\\nGet credentials to grant programmatic access 16\\nAmazon Bedrock User Guide\\nCreate an access key\\n1. On the User details page, select the Security credentials tab. In the Access keys section,\\nchoose Create access key.\\n2. Indicate that you plan to use these access keys as Other and choose Create access key.\\n3. On the Retrieve access key page, choose Show to reveal the value of your user\\'s secret access\\nkey. You can copy the credentials or download a .csv file.\\nImportant\\nWhen you no longer need this IAM user, we recommend that you remove it and align with\\n'}\n",
      "{'question': 'How do the methods for granting programmatic access differ between IAM users, IAM roles, and workforce identity users, and what are the key considerations for each?', 'ground_truth': 'The methods for granting programmatic access differ based on the type of user:\\n\\n1. IAM users: \\n   - Use long-term credentials with limited duration\\n   - Authenticate using IAM user credentials for AWS CLI\\n   - Use long-term credentials for AWS SDKs and tools\\n   - Manage access keys for AWS APIs\\n\\n2. IAM roles:\\n   - Use temporary credentials\\n   - Apply these credentials across AWS CLI, SDKs, and APIs\\n\\n3. Workforce identity (managed in IAM Identity Center):\\n   - Use temporary credentials\\n   - For AWS CLI: Configure it to use AWS IAM Identity Center\\n   - For AWS SDKs, tools, and APIs: Use IAM Identity Center authentication\\n\\nKey considerations:\\n- IAM users require management of long-term credentials, which may pose security risks if not rotated regularly\\n- IAM roles and workforce identity users leverage temporary credentials, enhancing security\\n- The choice depends on the use case, with IAM roles being more flexible and secure for many scenarios\\n- Workforce identity is ideal for organizations using IAM Identity Center for centralized user management\\n\\nEach method has its own set of instructions and best practices for implementation, emphasizing the importance of choosing the right approach based on security requirements and operational needs.', 'question_type': 'complex', 'contexts': \"and choosing My Account.\\nSecure your AWS account root user\\n1. Sign in to the AWS Management Console as the account owner by choosing Root user and\\nentering your AWS account email address. On the next page, enter your password.\\nFor help signing in by using root user, see Signing in as the root user in the AWS Sign-In User\\nGuide.\\n2. Turn on multi-factor authentication (MFA) for your root user.\\nFor instructions, see Enable a virtual MFA device for your AWS account root user (console) in\\nthe IAM User Guide.\\nI need to install the AWS CLI or an AWS SDK\\nTo install the AWS CLI, follow the steps at Install or update to the latest version of the AWS CLI.\\nTo install an AWS SDK, select the tab that corresponds to the programming language that you\\nwant to use at Tools to Build on AWS. AWS software development kits (SDKs) are available\\nfor many popular programming languages. Each SDK provides an API, code examples, and\\n documentation that make it easier for developers to build applications in their preferred language.\\nSDKs automatically perform useful tasks for you, such as:\\n• Cryptographically sign your service requests\\n• Retry requests\\n• Handle error responses\\nGet credentials to grant programmatic access\\nUsers need programmatic access if they want to interact with AWS outside of the AWS\\nManagement Console. The way to grant programmatic access depends on the type of user that's\\naccessing AWS.\\nTo grant users programmatic access, choose one of the following options.\\nGet credentials to grant programmatic access 13\\nAmazon Bedrock User Guide\\nWhich principal needs To By\\nprogrammatic access?\\nIAM users Limit the duration of long- Following the instructions for\\nterm credentials to sign the interface that you want to\\nprogrammatic requests to the use.\\nAWS CLI, AWS SDKs, or AWS\\n• For the AWS CLI, see\\nAPIs.\\nAuthenticating using IAM\\nuser credentials in the AWS\\nCommand Line Interface\\nUser Guide.\\n • For AWS SDKs and tools,\\nsee Authenticate using\\nlong-term credentials in\\nthe AWS SDKs and Tools\\nReference Guide.\\n• For AWS APIs, see\\nManaging access keys for\\nIAM users in the IAM User\\nGuide.\\nIAM roles Use temporary credentials to Following the instructions in\\nsign programmatic requests Using temporary credentia\\nto the AWS CLI, AWS SDKs, or ls with AWS resources in the\\nAWS APIs. IAM User Guide.\\nWorkforce identity Use temporary credentials to Following the instructions for\\nsign programmatic requests the interface that you want to\\n(Users managed in IAM\\nto the AWS CLI, AWS SDKs, or use.\\nIdentity Center)\\nAWS APIs.\\n• For the AWS CLI, see\\nConfiguring the AWS\\nCLI to use AWS IAM\\nIdentity Center in the AWS\\nCommand Line Interface\\nUser Guide.\\nGet credentials to grant programmatic access 14\\nAmazon Bedrock User Guide\\nWhich principal needs To By\\nprogrammatic access?\\n• For AWS SDKs, tools, and\\nAWS APIs, see IAM Identity\\nCenter authentication in\\nthe AWS SDKs and Tools\\nReference Guide.\\n\"}\n",
      "{'question': 'Which Mistral AI model supports streaming inference?', 'ground_truth': 'All Mistral AI models listed (Mistral 7B, Mistral Large, Mistral Small, and Mixtral 8x7B) support streaming inference.', 'question_type': 'simple', 'contexts': 'Mistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI 7B istral-7b east-1\\nInstruct -\\nus-\\ninstruct\\nwest-2\\n-v0:2\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nSupported foundation models 66\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI Large istral-la east-1\\n(24.02) rge-2402-\\nus-\\nv1:0\\nwest-2\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nMistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI Large istral-la west-2\\n(24.07) rge-2407-\\nv1:0\\nSupported foundation models 67\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI Small istral- east-1\\n (24.02) sm\\nall-2402-\\nv1:0\\nMistral Mixtral mistral.m us- Text Text Yes Link N/A\\nAI 8x7B ixtral-8x east-1\\nInstruct 7b-\\nus-\\ninstru\\nwest-2\\nct-v0:1\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nSupported foundation models 68\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nStability SD3 stability us- Text, Image No Link N/A\\nAI Large .sd3- west-2 Image\\n1.0 large-\\nv1:0\\nStability Stable stability us- Text, Image No Link N/A\\nAI Diffusion .sd3-5- west-2 Image\\n3.5 large-\\nLarge v1:0\\nStability Stable stability us- Text Image No Link N/A\\nAI Image .stable- west-2\\nCore image-\\n1.0 core-\\nv1:0\\nStability Stable stability us- Text Image No Link N/A\\nAI Image .stable- west-2\\nCore image-\\n1.0 core-\\nv1:1\\nStability Stable stability us- Text Image No Link N/A\\nAI Image .stable- west-2\\nUltra image-\\n1.0 ultra-\\nv1:0\\n Stability Stable stability us- Text Image No Link N/A\\nAI Image .stable- west-2\\nUltra image-\\n1.0 ultra-\\nv1:1\\nSupported foundation models 69\\nAmazon Bedrock User Guide\\nNote\\n* Some models are accessible in some Regions only through cross-region inference. To learn\\nmore about cross-region inference, see Increase throughput with cross-region inference and\\nSupported Regions and models for inference profiles.\\nThe following table lists models that have a target date for deprecation. For more information, see\\nModel lifecycle:\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAI21 J2 ai21.j2- us- Text Text, No Link N/A\\nLabs Grande grande- east-1 Chat\\nInstruct instruct\\nAI21 J2 ai21.j2- us- Text Text, No Link N/A\\nLabs Jumbo jumbo- east-1 Chat\\nInstruct instruct\\nAI21 Jurassic- ai21.j2- us- Text Text, No Link N/A\\nLabs 2 Mid mid-v1 east-1 Chat\\nAI21 Jurassic- ai21.j2- us- Text Text, No Link N/A\\n'}\n",
      "{'question': 'How does the regional availability of Amazon Nova models compare to AI21 Labs models in Amazon Bedrock, and what implications might this have for developers choosing between these providers?', 'ground_truth': 'The regional availability of Amazon Nova models is more extensive compared to AI21 Labs models in Amazon Bedrock. Amazon Nova models (Lite, Micro, and Pro) are available in US East (N. Virginia), and have cross-region inference support in US East (Ohio) and US West (Oregon). In contrast, AI21 Labs models (Jamba 1.5 Large, Jamba 1.5 Mini, and Jamba-Instruct) are only available in US East (N. Virginia) with no cross-region inference support mentioned. This difference in availability implies that developers choosing Amazon Nova models have more flexibility in terms of geographical deployment and potentially lower latency for users in different regions. However, those requiring AI21 Labs models may face limitations in regional optimization and might need to consider potential latency issues for users outside the US East region.', 'question_type': 'complex', 'contexts': 'Stability Stable stability us- Text Image No Link N/A\\nAI Image .stable- west-2\\nUltra image-\\n1.0 ultra-\\nv1:1\\nSupported foundation models 69\\nAmazon Bedrock User Guide\\nNote\\n* Some models are accessible in some Regions only through cross-region inference. To learn\\nmore about cross-region inference, see Increase throughput with cross-region inference and\\nSupported Regions and models for inference profiles.\\nThe following table lists models that have a target date for deprecation. For more information, see\\nModel lifecycle:\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAI21 J2 ai21.j2- us- Text Text, No Link N/A\\nLabs Grande grande- east-1 Chat\\nInstruct instruct\\nAI21 J2 ai21.j2- us- Text Text, No Link N/A\\nLabs Jumbo jumbo- east-1 Chat\\nInstruct instruct\\nAI21 Jurassic- ai21.j2- us- Text Text, No Link N/A\\nLabs 2 Mid mid-v1 east-1 Chat\\nAI21 Jurassic- ai21.j2- us- Text Text, No Link N/A\\n Labs 2 Ultra ultra-v1 east-1 Chat\\nStability SDXL stability us- Text, Image No Link N/A\\nAI 1.0 .stable- east-1 Image\\nd\\nus-\\niffusion-\\nwest-2\\nxl-v1\\nSupported foundation models 70\\nAmazon Bedrock User Guide\\nModel support by AWS Region in Amazon Bedrock\\nFor a list of AWS Regions that support Amazon Bedrock, see Amazon Bedrock endpoints and\\nquotas. Amazon Bedrock foundation models differ in their regional support.\\nThe following table shows Region support by model:\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJamba\\n1.5\\nLarge\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJamba\\n1.5\\nMini\\nAI21\\n Yes No No No No No No No No No No No No No No No No\\nLabs\\nJamba-\\nIns\\ntruct\\nAmazon\\nYes No No No No No No No No No No No No No No No No\\nNova\\nCanvas\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nLite\\nModel support by Region 71\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nMicro\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nPro\\nAmazon\\nYes No No No No No No No No No No No No No No No No\\nNova\\nReel\\nAmazon\\nNo No Yes No No Yes No No No No Yes Yes No No No No No\\nRerank\\n1.0\\nAmazon\\nYes No Yes No No Yes No No No No No Yes No No No No No\\nTitan\\nEmbedding\\ns\\nG1\\n-\\nText\\nAmazon\\n'}\n",
      "{'question': 'How do you request access to Amazon Bedrock foundation models?', 'ground_truth': 'To request access to Amazon Bedrock foundation models, sign into the AWS Management Console, open the Amazon Bedrock console, go to Model access, choose Modify model access, select the models you want access to, review the terms, and submit your request.', 'question_type': 'simple', 'contexts': \"After setting up your Amazon Bedrock IAM role, you can sign into the Amazon Bedrock console and\\nrequest access to foundation models.\\nTo request access to an Amazon Bedrock FM\\n1. Sign into the AWS Management Console and switch to the Amazon Bedrock role that you set\\nup (or that was set up for you) by following the steps under To switch to a role (console) in\\nSwitching to a role (console).\\n2. Open the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/.\\n3. For the purposes of this tutorial, you should be in the US East (N. Virginia) (us-east-1) Region.\\nTo change regions, choose the Region name at the top right of the console, next to your IAM\\nrole. Then select US East (N. Virginia) (us-east-1).\\n4. Select Model access at the bottom of the left navigation pane.\\n5. On the Model access page, you can review the End User License Agreement (EULA) for models\\nin the EULA column in the Base models table.\\n6. Choose Modify model access.\\n7. Do one of the following:\\n • To request access to all models, choose Enable all models. On the page you're taken to,\\nthe checkboxes next to all the models will be filled.\\n• To request access to specific models, choose Enable specific models. On the page you're\\ntaken to, you have the following options:\\nRequest access to an Amazon Bedrock foundation model 9\\nAmazon Bedrock User Guide\\n• To request access to all models by a provider, select the checkbox next to the provider\\nname.\\n• To request access to one model, select the checkbox next to the model name.\\n8. For the purposes of the following tutorials, you should minimally request access to the\\nAmazon Titan Text G1 - Express and Amazon Titan Image Generator G1 V1 models. Then\\nchoose Next.\\n9. Review the models that you're requesting access to and the Terms. When you're ready, choose\\nSubmit to request access.\\n10. Access may take several minutes to complete. When access is granted to a model, the Access\\nstatus for that model willbecome Access granted.\\n (Optional tutorials) Explore Amazon Bedrock features through\\nthe console or API\\nAfter requesting access to the foundation models that you want to use, you'll be ready to explore\\nthe different capabilities offered by Amazon Bedrock.\\nIf you want to familiarize yourself more with Amazon Bedrock first, you can continue to the\\nfollowing pages:\\n• To learn how to run basic prompts and generate model responses using the Playgrounds in the\\nAmazon Bedrock console, continue to Getting started in the Amazon Bedrock console.\\n• To learn how to set up access to Amazon Bedrock operations through the Amazon Bedrock API\\nand test out some API calls, continue to Getting started with the API.\\n• To learn about the software development kits (SDKs) supported by Amazon Bedrock, continue to\\nUsing Amazon Bedrock with an AWS SDK.\\nGetting started in the Amazon Bedrock console\\nThis section describes how to use the playgrounds in the AWS console to submit a text prompt to a\\n\"}\n",
      "{'question': 'How can Amazon Bedrock help optimize AI application performance, and what considerations should be taken into account when implementing these optimizations?', 'ground_truth': \"Amazon Bedrock offers several ways to optimize AI application performance. First, you can purchase Provisioned Throughput for foundation models to run inference more efficiently and at discounted rates. This is particularly useful for applications with consistent, high-volume usage. Second, Latency-optimized inference (currently in preview) can be used to achieve faster response times and improved responsiveness for AI applications. Additionally, you can adapt models to specific tasks and domains through fine-tuning or continued pre-training, which can improve performance for particular use cases. \\n\\nWhen implementing these optimizations, consider the following:\\n1. Cost implications: While Provisioned Throughput offers discounted rates, it requires upfront commitment. Evaluate your usage patterns to determine if it's cost-effective.\\n2. Regional availability: Check the supported AWS Regions for the features you plan to use, as not all features may be available in all regions.\\n3. Model selection: Use Amazon Bedrock's evaluation tools to determine the best model for your specific use case before optimizing.\\n4. Preview status: Be aware that some features, like Latency-optimized inference, are in preview and may change.\\n5. Guardrails: Implement appropriate safeguards to prevent inappropriate or unwanted content in your optimized AI applications.\\n\\nBy carefully considering these factors, you can effectively leverage Amazon Bedrock's optimization features to enhance your AI application's performance while managing costs and ensuring appropriate use.\", 'question_type': 'complex', 'contexts': \"• Create applications that reason through how to help a customer – Build agents that use\\nfoundation models, make API calls, and (optionally) query knowledge bases in order to reason\\nthrough and carry out tasks for your customers.\\n• Adapt models to specific tasks and domains with training data – Customize an Amazon\\nBedrock foundation model by providing training data for fine-tuning or continued-pretraining in\\norder to adjust a model's parameters and improve its performance on specific tasks or in certain\\ndomains.\\n• Improve your FM-based application's efficiency and output – Purchase Provisioned Throughput\\nfor a foundation model in order to run inference on models more efficiently and at discounted\\nrates.\\n• Determine the best model for your use case – Evaluate outputs of different models with built-in\\nor custom prompt datasets to determine the model that is best suited for your application.\\n• Prevent inappropriate or unwanted content – Use guardrails to implement safeguards for your\\n generative AI applications.\\n• Optimize your FM's latency – Get faster response times and improved responsiveness for AI\\napplications with Latency-optimized inference for foundation models.\\nNote\\nThe Latency Optimized Inference feature is in preview release for Amazon Bedrock and is\\nsubject to change.\\nTo learn about Regions that support Amazon Bedrock and the foundation models and features\\nthat Amazon Bedrock supports, see Supported foundation models in Amazon Bedrock and Feature\\nsupport by AWS Region in Amazon Bedrock.\\nHow do I get started with Amazon Bedrock?\\nWe recommend that you start with Amazon Bedrock by doing the following:\\n1. Familiarize yourself with the terms and concepts that Amazon Bedrock uses.\\n2. Understand how AWS charges you for using Amazon Bedrock.\\n3. Try the Getting started with Amazon Bedrock tutorials. In the tutorials, you learn how to use\\nthe playgrounds in Amazon Bedrock console. You also learn and how to use the AWS SDK to call\\nAmazon Bedrock API operations.\\n How do I get started with Amazon Bedrock? 2\\nAmazon Bedrock User Guide\\n4. Read the documentation for the features that you want to include in your application.\\nAmazon Bedrock pricing\\nWhen you sign up for AWS, your AWS account is automatically signed up for all services in AWS,\\nincluding Amazon Bedrock. However, you are charged only for the services that you use.\\nFor information about pricing for different Amazon Bedrock resources, see Amazon Bedrock\\nPricing.\\nTo see your bill, go to the Billing and Cost Management Dashboard in the AWS Billing and Cost\\nManagement console. To learn more about AWS account billing, see the AWS Billing User Guide. If\\nyou have questions concerning AWS billing and AWS accounts, contact AWS Support.\\nWith Amazon Bedrock, you pay to run inference on any of the third-party foundation models.\\nPricing is based on the volume of input tokens and output tokens, and on whether you have\\n\"}\n",
      "{'question': 'How can you list the foundation models available in Amazon Bedrock?', 'ground_truth': 'You can use the ListFoundationModels operation with an Amazon Bedrock client to list the foundation models available in Amazon Bedrock in your region.', 'question_type': 'simple', 'contexts': 'Run examples with a SageMaker AI notebook 24\\nAmazon Bedrock User Guide\\n\"Action\": \"sts:AssumeRole\"\\n},\\n{\\n\"Sid\": \"SagemakerTrust\",\\n\"Effect\": \"Allow\",\\n\"Principal\": {\\n\"Service\": \"sagemaker.amazonaws.com\"\\n},\\n\"Action\": \"sts:AssumeRole\"\\n}\\n]\\n}\\n2. Sign into the Amazon Bedrock role whose trust policy you just modified.\\n3. Follow the steps at Create an Amazon SageMaker AI Notebook Instance for the tutorial and\\nspecify the ARN of the Amazon Bedrock role that you created to create an SageMaker AI\\nnotebook instance.\\n4. When the Status of the notebook instance is InService, choose the instance and then choose\\nOpen JupyterLab.\\nAfter you open up your SageMaker AI notebook, you can try out the following examples:\\nTopics\\n• List the foundation models that Amazon Bedrock has to offer\\n• Submit a text prompt to a model and generate a response\\nList the foundation models that Amazon Bedrock has to offer\\nThe following example runs the ListFoundationModels operation using an Amazon Bedrock client.\\n ListFoundationModels lists the foundation models (FMs) that are available in Amazon Bedrock\\nin your region. Run the following SDK for Python script to create an Amazon Bedrock client and\\ntest the ListFoundationModels operation:\\n# Use the ListFoundationModels API to show the models that are available in your\\nregion.\\nimport boto3\\n# Create an &BR; client in the &region-us-east-1; Region.\\nbedrock = boto3.client(\\nRun examples with a SageMaker AI notebook 25\\nAmazon Bedrock User Guide\\nservice_name=\"bedrock\"\\n)\\nbedrock.list_foundation_models()\\nIf the script is successful, the response returns a list of foundation models that are available in\\nAmazon Bedrock.\\nSubmit a text prompt to a model and generate a response\\nThe following example runs the Converse operation using an Amazon Bedrock client. Converse\\nlets you submit a prompt to generate a model response. Run the following SDK for Python script to\\ncreate an Amazon Bedrock runtime client and test the Converse operation:\\n # Use the Conversation API to send a text message to Amazon Titan Text G1 - Express.\\nimport boto3\\nfrom botocore.exceptions import ClientError\\n# Create an Amazon Bedrock Runtime client.\\nbrt = boto3.client(\"bedrock-runtime\")\\n# Set the model ID, e.g., Amazon Titan Text G1 - Express.\\nmodel_id = \"amazon.titan-text-express-v1\"\\n# Start a conversation with the user message.\\nuser_message = \"Describe the purpose of a \\'hello world\\' program in one line.\"\\nconversation = [\\n{\\n\"role\": \"user\",\\n\"content\": [{\"text\": user_message}],\\n}\\n]\\ntry:\\n# Send the message to the model, using a basic inference configuration.\\nresponse = brt.converse(\\nmodelId=model_id,\\nmessages=conversation,\\ninferenceConfig={\"maxTokens\": 512, \"temperature\": 0.5, \"topP\": 0.9},\\n)\\n# Extract and print the response text.\\nRun examples with a SageMaker AI notebook 26\\nAmazon Bedrock User Guide\\nresponse_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\\nprint(response_text)\\nexcept (ClientError, Exception) as e:\\n'}\n",
      "{'question': 'What are the key steps for granting a user access to Amazon Bedrock foundation models, and how does the process differ for users within your AWS account versus users from other accounts?', 'ground_truth': 'The process for granting a user access to Amazon Bedrock foundation models involves several key steps:\\n\\n1. Add users to the Amazon Bedrock role:\\n   - For users in your account: Grant permissions to switch roles by following the \"Granting a user permissions to switch roles\" procedure, specifying the Amazon Bedrock role as the Resource.\\n   - For users from other accounts: Add them directly to the role.\\n\\n2. Provide users with the Amazon Bedrock role name and the account ID or alias.\\n\\n3. Guide users on how to switch to the role using the \"Providing information to the user\" instructions.\\n\\n4. Users must sign into the AWS Management Console and switch to the Amazon Bedrock role.\\n\\n5. In the Amazon Bedrock console, users need to:\\n   - Navigate to the Model access page\\n   - Review the End User License Agreement (EULA) for desired models\\n   - Choose \"Modify model access\"\\n   - Request access to specific models or all models\\n   - Submit the access request\\n\\n6. Wait for access to be granted, which may take several minutes.\\n\\nThe main difference in the process for users within your AWS account versus users from other accounts is in the initial step of adding them to the role. Internal users are granted permissions to switch roles, while external users are added directly to the role. Both types of users then follow the same steps to request and gain access to the foundation models.', 'question_type': 'complex', 'contexts': \"To add users to the Amazon Bedrock role\\n1. For users to access an IAM role, you must add them to the role. You can add both users in your\\naccount or from other accounts. To grant users permissions to switch to the Amazon Bedrock\\nrole that you created, follow the steps at Granting a user permissions to switch roles and\\nspecify the Amazon Bedrock role as the Resource.\\nI already have an AWS account 8\\nAmazon Bedrock User Guide\\nNote\\nIf you need to create more users in your account so that you can give them access\\nto the Amazon Bedrock role, follow the steps in Creating an IAM user in your AWS\\naccount.\\n2. After you've granted a user permissions to use the Amazon Bedrock role, provide the user\\nwith role name and ID or alias of the account to which the role belongs. Then, guide the user\\nthrough how to switch to the role by following the instructions at Providing information to the\\nuser.\\nRequest access to an Amazon Bedrock foundation model\\n After setting up your Amazon Bedrock IAM role, you can sign into the Amazon Bedrock console and\\nrequest access to foundation models.\\nTo request access to an Amazon Bedrock FM\\n1. Sign into the AWS Management Console and switch to the Amazon Bedrock role that you set\\nup (or that was set up for you) by following the steps under To switch to a role (console) in\\nSwitching to a role (console).\\n2. Open the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/.\\n3. For the purposes of this tutorial, you should be in the US East (N. Virginia) (us-east-1) Region.\\nTo change regions, choose the Region name at the top right of the console, next to your IAM\\nrole. Then select US East (N. Virginia) (us-east-1).\\n4. Select Model access at the bottom of the left navigation pane.\\n5. On the Model access page, you can review the End User License Agreement (EULA) for models\\nin the EULA column in the Base models table.\\n6. Choose Modify model access.\\n7. Do one of the following:\\n • To request access to all models, choose Enable all models. On the page you're taken to,\\nthe checkboxes next to all the models will be filled.\\n• To request access to specific models, choose Enable specific models. On the page you're\\ntaken to, you have the following options:\\nRequest access to an Amazon Bedrock foundation model 9\\nAmazon Bedrock User Guide\\n• To request access to all models by a provider, select the checkbox next to the provider\\nname.\\n• To request access to one model, select the checkbox next to the model name.\\n8. For the purposes of the following tutorials, you should minimally request access to the\\nAmazon Titan Text G1 - Express and Amazon Titan Image Generator G1 V1 models. Then\\nchoose Next.\\n9. Review the models that you're requesting access to and the Terms. When you're ready, choose\\nSubmit to request access.\\n10. Access may take several minutes to complete. When access is granted to a model, the Access\\nstatus for that model willbecome Access granted.\\n\"}\n",
      "{'question': 'What are the two main prerequisites for running Amazon Bedrock examples?', 'ground_truth': 'The two main prerequisites are having an AWS account with necessary permissions for Amazon Bedrock, and requesting access to the Amazon Titan Text G1 - Express model.', 'question_type': 'simple', 'contexts': 'up properly. Before you run the following examples, you should check that you have fulfilled the\\nfollowing prerequisites:\\nPrerequisites\\n• You have an AWS account and have permissions to access a role with the necessary permissions\\nfor Amazon Bedrock. Otherwise, follow the steps at I already have an AWS account.\\n• You\\'ve requested access to the Amazon Titan Text G1 - Express model. Otherwise, follow the\\nsteps at Request access to an Amazon Bedrock foundation model.\\n• Carry out the following steps to set up IAM permissions for SageMaker AI and create a notebook:\\n1. Modify the trust policy of the Amazon Bedrock role that you set up in I already have an AWS\\naccount through the console, CLI, or API. Attach the following trust policy to the role to\\nallow both the Amazon Bedrock and SageMaker AI services to assume the Amazon Bedrock\\nrole:\\n{\\n\"Version\": \"2012-10-17\",\\n\"Statement\": [\\n{\\n\"Sid\": \"BedrockTrust\",\\n\"Effect\": \"Allow\",\\n\"Principal\": {\\n\"Service\": \"bedrock.amazonaws.com\"\\n},\\n Run examples with a SageMaker AI notebook 24\\nAmazon Bedrock User Guide\\n\"Action\": \"sts:AssumeRole\"\\n},\\n{\\n\"Sid\": \"SagemakerTrust\",\\n\"Effect\": \"Allow\",\\n\"Principal\": {\\n\"Service\": \"sagemaker.amazonaws.com\"\\n},\\n\"Action\": \"sts:AssumeRole\"\\n}\\n]\\n}\\n2. Sign into the Amazon Bedrock role whose trust policy you just modified.\\n3. Follow the steps at Create an Amazon SageMaker AI Notebook Instance for the tutorial and\\nspecify the ARN of the Amazon Bedrock role that you created to create an SageMaker AI\\nnotebook instance.\\n4. When the Status of the notebook instance is InService, choose the instance and then choose\\nOpen JupyterLab.\\nAfter you open up your SageMaker AI notebook, you can try out the following examples:\\nTopics\\n• List the foundation models that Amazon Bedrock has to offer\\n• Submit a text prompt to a model and generate a response\\nList the foundation models that Amazon Bedrock has to offer\\nThe following example runs the ListFoundationModels operation using an Amazon Bedrock client.\\n ListFoundationModels lists the foundation models (FMs) that are available in Amazon Bedrock\\nin your region. Run the following SDK for Python script to create an Amazon Bedrock client and\\ntest the ListFoundationModels operation:\\n# Use the ListFoundationModels API to show the models that are available in your\\nregion.\\nimport boto3\\n# Create an &BR; client in the &region-us-east-1; Region.\\nbedrock = boto3.client(\\nRun examples with a SageMaker AI notebook 25\\nAmazon Bedrock User Guide\\nservice_name=\"bedrock\"\\n)\\nbedrock.list_foundation_models()\\nIf the script is successful, the response returns a list of foundation models that are available in\\nAmazon Bedrock.\\nSubmit a text prompt to a model and generate a response\\nThe following example runs the Converse operation using an Amazon Bedrock client. Converse\\nlets you submit a prompt to generate a model response. Run the following SDK for Python script to\\ncreate an Amazon Bedrock runtime client and test the Converse operation:\\n'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'question': 'What are the key steps for granting a user access to Amazon Bedrock foundation models, and how does the process differ for users within your AWS account versus users from other accounts?',\n",
       "  'ground_truth': 'The process for granting a user access to Amazon Bedrock foundation models involves several key steps:\\n\\n1. Add users to the Amazon Bedrock role:\\n   - For users in your account: Grant permissions to switch roles by following the \"Granting a user permissions to switch roles\" procedure.\\n   - For users from other accounts: Add them directly to the role.\\n\\n2. Provide users with the Amazon Bedrock role name and account ID or alias.\\n\\n3. Guide users on how to switch to the role using the \"Providing information to the user\" instructions.\\n\\n4. Users must sign into the AWS Management Console and switch to the Amazon Bedrock role.\\n\\n5. In the Amazon Bedrock console, users request access to foundation models:\\n   - Navigate to the Model access page\\n   - Review the End User License Agreement (EULA) for desired models\\n   - Choose \"Modify model access\"\\n   - Select either \"Enable all models\" or \"Enable specific models\"\\n   - Submit the access request\\n\\n6. Wait for access to be granted, which may take several minutes.\\n\\nThe main difference in the process for users within your AWS account versus users from other accounts is in the initial step of adding them to the role. Internal users are granted permissions to switch roles, while external users are added directly to the role. Both types of users then follow the same steps to request access to the foundation models through the Amazon Bedrock console.',\n",
       "  'question_type': 'complex',\n",
       "  'contexts': \"To add users to the Amazon Bedrock role\\n1. For users to access an IAM role, you must add them to the role. You can add both users in your\\naccount or from other accounts. To grant users permissions to switch to the Amazon Bedrock\\nrole that you created, follow the steps at Granting a user permissions to switch roles and\\nspecify the Amazon Bedrock role as the Resource.\\nI already have an AWS account 8\\nAmazon Bedrock User Guide\\nNote\\nIf you need to create more users in your account so that you can give them access\\nto the Amazon Bedrock role, follow the steps in Creating an IAM user in your AWS\\naccount.\\n2. After you've granted a user permissions to use the Amazon Bedrock role, provide the user\\nwith role name and ID or alias of the account to which the role belongs. Then, guide the user\\nthrough how to switch to the role by following the instructions at Providing information to the\\nuser.\\nRequest access to an Amazon Bedrock foundation model\\n After setting up your Amazon Bedrock IAM role, you can sign into the Amazon Bedrock console and\\nrequest access to foundation models.\\nTo request access to an Amazon Bedrock FM\\n1. Sign into the AWS Management Console and switch to the Amazon Bedrock role that you set\\nup (or that was set up for you) by following the steps under To switch to a role (console) in\\nSwitching to a role (console).\\n2. Open the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/.\\n3. For the purposes of this tutorial, you should be in the US East (N. Virginia) (us-east-1) Region.\\nTo change regions, choose the Region name at the top right of the console, next to your IAM\\nrole. Then select US East (N. Virginia) (us-east-1).\\n4. Select Model access at the bottom of the left navigation pane.\\n5. On the Model access page, you can review the End User License Agreement (EULA) for models\\nin the EULA column in the Base models table.\\n6. Choose Modify model access.\\n7. Do one of the following:\\n • To request access to all models, choose Enable all models. On the page you're taken to,\\nthe checkboxes next to all the models will be filled.\\n• To request access to specific models, choose Enable specific models. On the page you're\\ntaken to, you have the following options:\\nRequest access to an Amazon Bedrock foundation model 9\\nAmazon Bedrock User Guide\\n• To request access to all models by a provider, select the checkbox next to the provider\\nname.\\n• To request access to one model, select the checkbox next to the model name.\\n8. For the purposes of the following tutorials, you should minimally request access to the\\nAmazon Titan Text G1 - Express and Amazon Titan Image Generator G1 V1 models. Then\\nchoose Next.\\n9. Review the models that you're requesting access to and the Terms. When you're ready, choose\\nSubmit to request access.\\n10. Access may take several minutes to complete. When access is granted to a model, the Access\\nstatus for that model willbecome Access granted.\\n\"},\n",
       " {'question': 'What is the recommended expiration time for IAM user access keys?',\n",
       "  'ground_truth': 'IAM recommends limiting access keys to 12 hours.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': 'How to configure access keys for an IAM user\\nIf you decide to use access keys for an IAM user, AWS recommends that you set an expiration for\\nthe IAM user by including a restrictive inline policy.\\nImportant\\nHeed the following warnings:\\n• Do NOT use your account\\'s root credentials to access AWS resources. These credentials\\nprovide unrestricted account access and are difficult to revoke.\\n• Do NOT put literal access keys or credential information in your application files. If you\\ndo, you create a risk of accidentally exposing your credentials if, for example, you upload\\nthe project to a public repository.\\n• Do NOT include files that contain credentials in your project area.\\n• Manage your access keys securely. Do not provide your access keys to unauthorized\\nparties, even to help find your account identifiers. By doing this, you might give someone\\npermanent access to your account.\\n• Be aware that any credentials stored in the shared AWS credentials file are stored in\\nplaintext.\\n For more details, see Best practices for managing AWS access keys in the AWS General Reference.\\nCreate an IAM user\\n1. On the AWS Management Console Home page, select the IAM service or navigate to the IAM\\nconsole at https://console.aws.amazon.com/iam/.\\nGet credentials to grant programmatic access 15\\nAmazon Bedrock User Guide\\n2. In the navigation pane, select Users and then select Create user.\\n3. Follow the guidance in the IAM console to set up a programmatic user (without access to the\\nAWS Management Console) and without permissions.\\nRestrict user access to a limited time window\\nAny IAM user access keys that you create are long-term credentials. To ensure that these\\ncredentials expire in case they are mishandled, you can make these credentials time-bound by\\ncreating an inline policy that specifies a date after which the keys will no longer be valid.\\n1. Open the IAM user that you just created. In the Permissions tab, choose Add permissions and\\nthen choose Create inline policy.\\n 2. In the JSON editor, specify the following permissions. To use this policy, replace the value for\\naws:CurrentTime timestamp value in the example policy with your own end date.\\nNote\\nIAM recommends that you limit your access keys to 12 hours.\\n{\\n\"Version\": \"2012-10-17\",\\n\"Statement\": [\\n{\\n\"Effect\": \"Deny\",\\n\"Action\": \"*\",\\n\"Resource\": \"*\",\\n\"Condition\": {\\n\"DateGreaterThan\": {\\n\"aws:CurrentTime\": \"2024-01-01T00:00:000\"\\n}\\n}\\n}\\n]\\n}\\nGet credentials to grant programmatic access 16\\nAmazon Bedrock User Guide\\nCreate an access key\\n1. On the User details page, select the Security credentials tab. In the Access keys section,\\nchoose Create access key.\\n2. Indicate that you plan to use these access keys as Other and choose Create access key.\\n3. On the Retrieve access key page, choose Show to reveal the value of your user\\'s secret access\\nkey. You can copy the credentials or download a .csv file.\\nImportant\\nWhen you no longer need this IAM user, we recommend that you remove it and align with\\n'},\n",
       " {'question': 'How do the methods for granting programmatic access differ between IAM users, IAM roles, and workforce identity users, and what are the key considerations for each?',\n",
       "  'ground_truth': 'The methods for granting programmatic access differ based on the type of user:\\n\\n1. IAM users: \\n   - Use long-term credentials with limited duration\\n   - Authenticate using IAM user credentials for AWS CLI\\n   - Use long-term credentials for AWS SDKs and tools\\n   - Manage access keys for AWS APIs\\n\\n2. IAM roles:\\n   - Use temporary credentials\\n   - Apply these credentials across AWS CLI, SDKs, and APIs\\n\\n3. Workforce identity (managed in IAM Identity Center):\\n   - Use temporary credentials\\n   - For AWS CLI: Configure it to use AWS IAM Identity Center\\n   - For AWS SDKs, tools, and APIs: Use IAM Identity Center authentication\\n\\nKey considerations:\\n- IAM users require management of long-term credentials, which may pose security risks if not rotated regularly\\n- IAM roles and workforce identity users leverage temporary credentials, enhancing security\\n- The choice depends on the use case, with IAM roles being more flexible and secure for many scenarios\\n- Workforce identity is ideal for organizations using IAM Identity Center for centralized user management\\n\\nEach method has its own set of instructions and best practices for implementation, emphasizing the importance of choosing the right approach based on security requirements and operational needs.',\n",
       "  'question_type': 'complex',\n",
       "  'contexts': \"and choosing My Account.\\nSecure your AWS account root user\\n1. Sign in to the AWS Management Console as the account owner by choosing Root user and\\nentering your AWS account email address. On the next page, enter your password.\\nFor help signing in by using root user, see Signing in as the root user in the AWS Sign-In User\\nGuide.\\n2. Turn on multi-factor authentication (MFA) for your root user.\\nFor instructions, see Enable a virtual MFA device for your AWS account root user (console) in\\nthe IAM User Guide.\\nI need to install the AWS CLI or an AWS SDK\\nTo install the AWS CLI, follow the steps at Install or update to the latest version of the AWS CLI.\\nTo install an AWS SDK, select the tab that corresponds to the programming language that you\\nwant to use at Tools to Build on AWS. AWS software development kits (SDKs) are available\\nfor many popular programming languages. Each SDK provides an API, code examples, and\\n documentation that make it easier for developers to build applications in their preferred language.\\nSDKs automatically perform useful tasks for you, such as:\\n• Cryptographically sign your service requests\\n• Retry requests\\n• Handle error responses\\nGet credentials to grant programmatic access\\nUsers need programmatic access if they want to interact with AWS outside of the AWS\\nManagement Console. The way to grant programmatic access depends on the type of user that's\\naccessing AWS.\\nTo grant users programmatic access, choose one of the following options.\\nGet credentials to grant programmatic access 13\\nAmazon Bedrock User Guide\\nWhich principal needs To By\\nprogrammatic access?\\nIAM users Limit the duration of long- Following the instructions for\\nterm credentials to sign the interface that you want to\\nprogrammatic requests to the use.\\nAWS CLI, AWS SDKs, or AWS\\n• For the AWS CLI, see\\nAPIs.\\nAuthenticating using IAM\\nuser credentials in the AWS\\nCommand Line Interface\\nUser Guide.\\n • For AWS SDKs and tools,\\nsee Authenticate using\\nlong-term credentials in\\nthe AWS SDKs and Tools\\nReference Guide.\\n• For AWS APIs, see\\nManaging access keys for\\nIAM users in the IAM User\\nGuide.\\nIAM roles Use temporary credentials to Following the instructions in\\nsign programmatic requests Using temporary credentia\\nto the AWS CLI, AWS SDKs, or ls with AWS resources in the\\nAWS APIs. IAM User Guide.\\nWorkforce identity Use temporary credentials to Following the instructions for\\nsign programmatic requests the interface that you want to\\n(Users managed in IAM\\nto the AWS CLI, AWS SDKs, or use.\\nIdentity Center)\\nAWS APIs.\\n• For the AWS CLI, see\\nConfiguring the AWS\\nCLI to use AWS IAM\\nIdentity Center in the AWS\\nCommand Line Interface\\nUser Guide.\\nGet credentials to grant programmatic access 14\\nAmazon Bedrock User Guide\\nWhich principal needs To By\\nprogrammatic access?\\n• For AWS SDKs, tools, and\\nAWS APIs, see IAM Identity\\nCenter authentication in\\nthe AWS SDKs and Tools\\nReference Guide.\\n\"},\n",
       " {'question': 'Which Mistral AI model supports streaming inference?',\n",
       "  'ground_truth': 'All Mistral AI models listed (Mistral 7B, Mistral Large, Mistral Small, and Mixtral 8x7B) support streaming inference.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': 'Mistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI 7B istral-7b east-1\\nInstruct -\\nus-\\ninstruct\\nwest-2\\n-v0:2\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nSupported foundation models 66\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI Large istral-la east-1\\n(24.02) rge-2402-\\nus-\\nv1:0\\nwest-2\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nMistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI Large istral-la west-2\\n(24.07) rge-2407-\\nv1:0\\nSupported foundation models 67\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI Small istral- east-1\\n (24.02) sm\\nall-2402-\\nv1:0\\nMistral Mixtral mistral.m us- Text Text Yes Link N/A\\nAI 8x7B ixtral-8x east-1\\nInstruct 7b-\\nus-\\ninstru\\nwest-2\\nct-v0:1\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nSupported foundation models 68\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nStability SD3 stability us- Text, Image No Link N/A\\nAI Large .sd3- west-2 Image\\n1.0 large-\\nv1:0\\nStability Stable stability us- Text, Image No Link N/A\\nAI Diffusion .sd3-5- west-2 Image\\n3.5 large-\\nLarge v1:0\\nStability Stable stability us- Text Image No Link N/A\\nAI Image .stable- west-2\\nCore image-\\n1.0 core-\\nv1:0\\nStability Stable stability us- Text Image No Link N/A\\nAI Image .stable- west-2\\nCore image-\\n1.0 core-\\nv1:1\\nStability Stable stability us- Text Image No Link N/A\\nAI Image .stable- west-2\\nUltra image-\\n1.0 ultra-\\nv1:0\\n Stability Stable stability us- Text Image No Link N/A\\nAI Image .stable- west-2\\nUltra image-\\n1.0 ultra-\\nv1:1\\nSupported foundation models 69\\nAmazon Bedrock User Guide\\nNote\\n* Some models are accessible in some Regions only through cross-region inference. To learn\\nmore about cross-region inference, see Increase throughput with cross-region inference and\\nSupported Regions and models for inference profiles.\\nThe following table lists models that have a target date for deprecation. For more information, see\\nModel lifecycle:\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAI21 J2 ai21.j2- us- Text Text, No Link N/A\\nLabs Grande grande- east-1 Chat\\nInstruct instruct\\nAI21 J2 ai21.j2- us- Text Text, No Link N/A\\nLabs Jumbo jumbo- east-1 Chat\\nInstruct instruct\\nAI21 Jurassic- ai21.j2- us- Text Text, No Link N/A\\nLabs 2 Mid mid-v1 east-1 Chat\\nAI21 Jurassic- ai21.j2- us- Text Text, No Link N/A\\n'},\n",
       " {'question': 'How does the regional availability of Amazon Nova models compare to AI21 Labs models in Amazon Bedrock, and what implications might this have for developers choosing between these providers?',\n",
       "  'ground_truth': 'The regional availability of Amazon Nova models is more extensive compared to AI21 Labs models in Amazon Bedrock. Amazon Nova models (Lite, Micro, and Pro) are available in US East (N. Virginia), and have cross-region inference support in US East (Ohio) and US West (Oregon). In contrast, AI21 Labs models (Jamba 1.5 Large, Jamba 1.5 Mini, and Jamba-Instruct) are only available in US East (N. Virginia) with no cross-region inference support mentioned. This difference in availability implies that developers choosing Amazon Nova models have more flexibility in terms of geographical deployment and potentially lower latency for users in different regions. However, those requiring AI21 Labs models may face limitations in regional optimization and might need to consider potential latency issues for users outside the US East region.',\n",
       "  'question_type': 'complex',\n",
       "  'contexts': 'Stability Stable stability us- Text Image No Link N/A\\nAI Image .stable- west-2\\nUltra image-\\n1.0 ultra-\\nv1:1\\nSupported foundation models 69\\nAmazon Bedrock User Guide\\nNote\\n* Some models are accessible in some Regions only through cross-region inference. To learn\\nmore about cross-region inference, see Increase throughput with cross-region inference and\\nSupported Regions and models for inference profiles.\\nThe following table lists models that have a target date for deprecation. For more information, see\\nModel lifecycle:\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAI21 J2 ai21.j2- us- Text Text, No Link N/A\\nLabs Grande grande- east-1 Chat\\nInstruct instruct\\nAI21 J2 ai21.j2- us- Text Text, No Link N/A\\nLabs Jumbo jumbo- east-1 Chat\\nInstruct instruct\\nAI21 Jurassic- ai21.j2- us- Text Text, No Link N/A\\nLabs 2 Mid mid-v1 east-1 Chat\\nAI21 Jurassic- ai21.j2- us- Text Text, No Link N/A\\n Labs 2 Ultra ultra-v1 east-1 Chat\\nStability SDXL stability us- Text, Image No Link N/A\\nAI 1.0 .stable- east-1 Image\\nd\\nus-\\niffusion-\\nwest-2\\nxl-v1\\nSupported foundation models 70\\nAmazon Bedrock User Guide\\nModel support by AWS Region in Amazon Bedrock\\nFor a list of AWS Regions that support Amazon Bedrock, see Amazon Bedrock endpoints and\\nquotas. Amazon Bedrock foundation models differ in their regional support.\\nThe following table shows Region support by model:\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJamba\\n1.5\\nLarge\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJamba\\n1.5\\nMini\\nAI21\\n Yes No No No No No No No No No No No No No No No No\\nLabs\\nJamba-\\nIns\\ntruct\\nAmazon\\nYes No No No No No No No No No No No No No No No No\\nNova\\nCanvas\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nLite\\nModel support by Region 71\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nMicro\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nPro\\nAmazon\\nYes No No No No No No No No No No No No No No No No\\nNova\\nReel\\nAmazon\\nNo No Yes No No Yes No No No No Yes Yes No No No No No\\nRerank\\n1.0\\nAmazon\\nYes No Yes No No Yes No No No No No Yes No No No No No\\nTitan\\nEmbedding\\ns\\nG1\\n-\\nText\\nAmazon\\n'},\n",
       " {'question': 'How do you request access to Amazon Bedrock foundation models?',\n",
       "  'ground_truth': 'To request access to Amazon Bedrock foundation models, sign into the AWS Management Console, open the Amazon Bedrock console, go to Model access, choose Modify model access, select the models you want access to, review the terms, and submit your request.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': \"After setting up your Amazon Bedrock IAM role, you can sign into the Amazon Bedrock console and\\nrequest access to foundation models.\\nTo request access to an Amazon Bedrock FM\\n1. Sign into the AWS Management Console and switch to the Amazon Bedrock role that you set\\nup (or that was set up for you) by following the steps under To switch to a role (console) in\\nSwitching to a role (console).\\n2. Open the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/.\\n3. For the purposes of this tutorial, you should be in the US East (N. Virginia) (us-east-1) Region.\\nTo change regions, choose the Region name at the top right of the console, next to your IAM\\nrole. Then select US East (N. Virginia) (us-east-1).\\n4. Select Model access at the bottom of the left navigation pane.\\n5. On the Model access page, you can review the End User License Agreement (EULA) for models\\nin the EULA column in the Base models table.\\n6. Choose Modify model access.\\n7. Do one of the following:\\n • To request access to all models, choose Enable all models. On the page you're taken to,\\nthe checkboxes next to all the models will be filled.\\n• To request access to specific models, choose Enable specific models. On the page you're\\ntaken to, you have the following options:\\nRequest access to an Amazon Bedrock foundation model 9\\nAmazon Bedrock User Guide\\n• To request access to all models by a provider, select the checkbox next to the provider\\nname.\\n• To request access to one model, select the checkbox next to the model name.\\n8. For the purposes of the following tutorials, you should minimally request access to the\\nAmazon Titan Text G1 - Express and Amazon Titan Image Generator G1 V1 models. Then\\nchoose Next.\\n9. Review the models that you're requesting access to and the Terms. When you're ready, choose\\nSubmit to request access.\\n10. Access may take several minutes to complete. When access is granted to a model, the Access\\nstatus for that model willbecome Access granted.\\n (Optional tutorials) Explore Amazon Bedrock features through\\nthe console or API\\nAfter requesting access to the foundation models that you want to use, you'll be ready to explore\\nthe different capabilities offered by Amazon Bedrock.\\nIf you want to familiarize yourself more with Amazon Bedrock first, you can continue to the\\nfollowing pages:\\n• To learn how to run basic prompts and generate model responses using the Playgrounds in the\\nAmazon Bedrock console, continue to Getting started in the Amazon Bedrock console.\\n• To learn how to set up access to Amazon Bedrock operations through the Amazon Bedrock API\\nand test out some API calls, continue to Getting started with the API.\\n• To learn about the software development kits (SDKs) supported by Amazon Bedrock, continue to\\nUsing Amazon Bedrock with an AWS SDK.\\nGetting started in the Amazon Bedrock console\\nThis section describes how to use the playgrounds in the AWS console to submit a text prompt to a\\n\"},\n",
       " {'question': 'How can Amazon Bedrock help optimize AI application performance, and what considerations should be taken into account when implementing these optimizations?',\n",
       "  'ground_truth': \"Amazon Bedrock offers several ways to optimize AI application performance. First, you can purchase Provisioned Throughput for foundation models to run inference more efficiently and at discounted rates. This is particularly useful for applications with consistent, high-volume usage. Second, Latency-optimized inference (currently in preview) can be used to achieve faster response times and improved responsiveness for AI applications. Additionally, you can adapt models to specific tasks and domains through fine-tuning or continued pre-training, which can improve performance for particular use cases. \\n\\nWhen implementing these optimizations, consider the following:\\n1. Cost implications: While Provisioned Throughput offers discounted rates, it requires upfront commitment. Evaluate your usage patterns to determine if it's cost-effective.\\n2. Regional availability: Check the supported AWS Regions for the features you plan to use, as not all features may be available in all regions.\\n3. Model selection: Use Amazon Bedrock's evaluation tools to determine the best model for your specific use case before optimizing.\\n4. Preview status: Be aware that some features, like Latency-optimized inference, are in preview and may change.\\n5. Guardrails: Implement appropriate safeguards to prevent inappropriate or unwanted content in your optimized AI applications.\\n\\nBy carefully considering these factors, you can effectively leverage Amazon Bedrock's optimization features to enhance your AI application's performance while managing costs and ensuring appropriate use.\",\n",
       "  'question_type': 'complex',\n",
       "  'contexts': \"• Create applications that reason through how to help a customer – Build agents that use\\nfoundation models, make API calls, and (optionally) query knowledge bases in order to reason\\nthrough and carry out tasks for your customers.\\n• Adapt models to specific tasks and domains with training data – Customize an Amazon\\nBedrock foundation model by providing training data for fine-tuning or continued-pretraining in\\norder to adjust a model's parameters and improve its performance on specific tasks or in certain\\ndomains.\\n• Improve your FM-based application's efficiency and output – Purchase Provisioned Throughput\\nfor a foundation model in order to run inference on models more efficiently and at discounted\\nrates.\\n• Determine the best model for your use case – Evaluate outputs of different models with built-in\\nor custom prompt datasets to determine the model that is best suited for your application.\\n• Prevent inappropriate or unwanted content – Use guardrails to implement safeguards for your\\n generative AI applications.\\n• Optimize your FM's latency – Get faster response times and improved responsiveness for AI\\napplications with Latency-optimized inference for foundation models.\\nNote\\nThe Latency Optimized Inference feature is in preview release for Amazon Bedrock and is\\nsubject to change.\\nTo learn about Regions that support Amazon Bedrock and the foundation models and features\\nthat Amazon Bedrock supports, see Supported foundation models in Amazon Bedrock and Feature\\nsupport by AWS Region in Amazon Bedrock.\\nHow do I get started with Amazon Bedrock?\\nWe recommend that you start with Amazon Bedrock by doing the following:\\n1. Familiarize yourself with the terms and concepts that Amazon Bedrock uses.\\n2. Understand how AWS charges you for using Amazon Bedrock.\\n3. Try the Getting started with Amazon Bedrock tutorials. In the tutorials, you learn how to use\\nthe playgrounds in Amazon Bedrock console. You also learn and how to use the AWS SDK to call\\nAmazon Bedrock API operations.\\n How do I get started with Amazon Bedrock? 2\\nAmazon Bedrock User Guide\\n4. Read the documentation for the features that you want to include in your application.\\nAmazon Bedrock pricing\\nWhen you sign up for AWS, your AWS account is automatically signed up for all services in AWS,\\nincluding Amazon Bedrock. However, you are charged only for the services that you use.\\nFor information about pricing for different Amazon Bedrock resources, see Amazon Bedrock\\nPricing.\\nTo see your bill, go to the Billing and Cost Management Dashboard in the AWS Billing and Cost\\nManagement console. To learn more about AWS account billing, see the AWS Billing User Guide. If\\nyou have questions concerning AWS billing and AWS accounts, contact AWS Support.\\nWith Amazon Bedrock, you pay to run inference on any of the third-party foundation models.\\nPricing is based on the volume of input tokens and output tokens, and on whether you have\\n\"},\n",
       " {'question': 'How can you list the foundation models available in Amazon Bedrock?',\n",
       "  'ground_truth': 'You can use the ListFoundationModels operation with an Amazon Bedrock client to list the foundation models available in Amazon Bedrock in your region.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': 'Run examples with a SageMaker AI notebook 24\\nAmazon Bedrock User Guide\\n\"Action\": \"sts:AssumeRole\"\\n},\\n{\\n\"Sid\": \"SagemakerTrust\",\\n\"Effect\": \"Allow\",\\n\"Principal\": {\\n\"Service\": \"sagemaker.amazonaws.com\"\\n},\\n\"Action\": \"sts:AssumeRole\"\\n}\\n]\\n}\\n2. Sign into the Amazon Bedrock role whose trust policy you just modified.\\n3. Follow the steps at Create an Amazon SageMaker AI Notebook Instance for the tutorial and\\nspecify the ARN of the Amazon Bedrock role that you created to create an SageMaker AI\\nnotebook instance.\\n4. When the Status of the notebook instance is InService, choose the instance and then choose\\nOpen JupyterLab.\\nAfter you open up your SageMaker AI notebook, you can try out the following examples:\\nTopics\\n• List the foundation models that Amazon Bedrock has to offer\\n• Submit a text prompt to a model and generate a response\\nList the foundation models that Amazon Bedrock has to offer\\nThe following example runs the ListFoundationModels operation using an Amazon Bedrock client.\\n ListFoundationModels lists the foundation models (FMs) that are available in Amazon Bedrock\\nin your region. Run the following SDK for Python script to create an Amazon Bedrock client and\\ntest the ListFoundationModels operation:\\n# Use the ListFoundationModels API to show the models that are available in your\\nregion.\\nimport boto3\\n# Create an &BR; client in the &region-us-east-1; Region.\\nbedrock = boto3.client(\\nRun examples with a SageMaker AI notebook 25\\nAmazon Bedrock User Guide\\nservice_name=\"bedrock\"\\n)\\nbedrock.list_foundation_models()\\nIf the script is successful, the response returns a list of foundation models that are available in\\nAmazon Bedrock.\\nSubmit a text prompt to a model and generate a response\\nThe following example runs the Converse operation using an Amazon Bedrock client. Converse\\nlets you submit a prompt to generate a model response. Run the following SDK for Python script to\\ncreate an Amazon Bedrock runtime client and test the Converse operation:\\n # Use the Conversation API to send a text message to Amazon Titan Text G1 - Express.\\nimport boto3\\nfrom botocore.exceptions import ClientError\\n# Create an Amazon Bedrock Runtime client.\\nbrt = boto3.client(\"bedrock-runtime\")\\n# Set the model ID, e.g., Amazon Titan Text G1 - Express.\\nmodel_id = \"amazon.titan-text-express-v1\"\\n# Start a conversation with the user message.\\nuser_message = \"Describe the purpose of a \\'hello world\\' program in one line.\"\\nconversation = [\\n{\\n\"role\": \"user\",\\n\"content\": [{\"text\": user_message}],\\n}\\n]\\ntry:\\n# Send the message to the model, using a basic inference configuration.\\nresponse = brt.converse(\\nmodelId=model_id,\\nmessages=conversation,\\ninferenceConfig={\"maxTokens\": 512, \"temperature\": 0.5, \"topP\": 0.9},\\n)\\n# Extract and print the response text.\\nRun examples with a SageMaker AI notebook 26\\nAmazon Bedrock User Guide\\nresponse_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\\nprint(response_text)\\nexcept (ClientError, Exception) as e:\\n'},\n",
       " {'question': 'What are the key steps for granting a user access to Amazon Bedrock foundation models, and how does the process differ for users within your AWS account versus users from other accounts?',\n",
       "  'ground_truth': 'The process for granting a user access to Amazon Bedrock foundation models involves several key steps:\\n\\n1. Add users to the Amazon Bedrock role:\\n   - For users in your account: Grant permissions to switch roles by following the \"Granting a user permissions to switch roles\" procedure, specifying the Amazon Bedrock role as the Resource.\\n   - For users from other accounts: Add them directly to the role.\\n\\n2. Provide users with the Amazon Bedrock role name and the account ID or alias.\\n\\n3. Guide users on how to switch to the role using the \"Providing information to the user\" instructions.\\n\\n4. Users must sign into the AWS Management Console and switch to the Amazon Bedrock role.\\n\\n5. In the Amazon Bedrock console, users need to:\\n   - Navigate to the Model access page\\n   - Review the End User License Agreement (EULA) for desired models\\n   - Choose \"Modify model access\"\\n   - Request access to specific models or all models\\n   - Submit the access request\\n\\n6. Wait for access to be granted, which may take several minutes.\\n\\nThe main difference in the process for users within your AWS account versus users from other accounts is in the initial step of adding them to the role. Internal users are granted permissions to switch roles, while external users are added directly to the role. Both types of users then follow the same steps to request and gain access to the foundation models.',\n",
       "  'question_type': 'complex',\n",
       "  'contexts': \"To add users to the Amazon Bedrock role\\n1. For users to access an IAM role, you must add them to the role. You can add both users in your\\naccount or from other accounts. To grant users permissions to switch to the Amazon Bedrock\\nrole that you created, follow the steps at Granting a user permissions to switch roles and\\nspecify the Amazon Bedrock role as the Resource.\\nI already have an AWS account 8\\nAmazon Bedrock User Guide\\nNote\\nIf you need to create more users in your account so that you can give them access\\nto the Amazon Bedrock role, follow the steps in Creating an IAM user in your AWS\\naccount.\\n2. After you've granted a user permissions to use the Amazon Bedrock role, provide the user\\nwith role name and ID or alias of the account to which the role belongs. Then, guide the user\\nthrough how to switch to the role by following the instructions at Providing information to the\\nuser.\\nRequest access to an Amazon Bedrock foundation model\\n After setting up your Amazon Bedrock IAM role, you can sign into the Amazon Bedrock console and\\nrequest access to foundation models.\\nTo request access to an Amazon Bedrock FM\\n1. Sign into the AWS Management Console and switch to the Amazon Bedrock role that you set\\nup (or that was set up for you) by following the steps under To switch to a role (console) in\\nSwitching to a role (console).\\n2. Open the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/.\\n3. For the purposes of this tutorial, you should be in the US East (N. Virginia) (us-east-1) Region.\\nTo change regions, choose the Region name at the top right of the console, next to your IAM\\nrole. Then select US East (N. Virginia) (us-east-1).\\n4. Select Model access at the bottom of the left navigation pane.\\n5. On the Model access page, you can review the End User License Agreement (EULA) for models\\nin the EULA column in the Base models table.\\n6. Choose Modify model access.\\n7. Do one of the following:\\n • To request access to all models, choose Enable all models. On the page you're taken to,\\nthe checkboxes next to all the models will be filled.\\n• To request access to specific models, choose Enable specific models. On the page you're\\ntaken to, you have the following options:\\nRequest access to an Amazon Bedrock foundation model 9\\nAmazon Bedrock User Guide\\n• To request access to all models by a provider, select the checkbox next to the provider\\nname.\\n• To request access to one model, select the checkbox next to the model name.\\n8. For the purposes of the following tutorials, you should minimally request access to the\\nAmazon Titan Text G1 - Express and Amazon Titan Image Generator G1 V1 models. Then\\nchoose Next.\\n9. Review the models that you're requesting access to and the Terms. When you're ready, choose\\nSubmit to request access.\\n10. Access may take several minutes to complete. When access is granted to a model, the Access\\nstatus for that model willbecome Access granted.\\n\"},\n",
       " {'question': 'What are the two main prerequisites for running Amazon Bedrock examples?',\n",
       "  'ground_truth': 'The two main prerequisites are having an AWS account with necessary permissions for Amazon Bedrock, and requesting access to the Amazon Titan Text G1 - Express model.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': 'up properly. Before you run the following examples, you should check that you have fulfilled the\\nfollowing prerequisites:\\nPrerequisites\\n• You have an AWS account and have permissions to access a role with the necessary permissions\\nfor Amazon Bedrock. Otherwise, follow the steps at I already have an AWS account.\\n• You\\'ve requested access to the Amazon Titan Text G1 - Express model. Otherwise, follow the\\nsteps at Request access to an Amazon Bedrock foundation model.\\n• Carry out the following steps to set up IAM permissions for SageMaker AI and create a notebook:\\n1. Modify the trust policy of the Amazon Bedrock role that you set up in I already have an AWS\\naccount through the console, CLI, or API. Attach the following trust policy to the role to\\nallow both the Amazon Bedrock and SageMaker AI services to assume the Amazon Bedrock\\nrole:\\n{\\n\"Version\": \"2012-10-17\",\\n\"Statement\": [\\n{\\n\"Sid\": \"BedrockTrust\",\\n\"Effect\": \"Allow\",\\n\"Principal\": {\\n\"Service\": \"bedrock.amazonaws.com\"\\n},\\n Run examples with a SageMaker AI notebook 24\\nAmazon Bedrock User Guide\\n\"Action\": \"sts:AssumeRole\"\\n},\\n{\\n\"Sid\": \"SagemakerTrust\",\\n\"Effect\": \"Allow\",\\n\"Principal\": {\\n\"Service\": \"sagemaker.amazonaws.com\"\\n},\\n\"Action\": \"sts:AssumeRole\"\\n}\\n]\\n}\\n2. Sign into the Amazon Bedrock role whose trust policy you just modified.\\n3. Follow the steps at Create an Amazon SageMaker AI Notebook Instance for the tutorial and\\nspecify the ARN of the Amazon Bedrock role that you created to create an SageMaker AI\\nnotebook instance.\\n4. When the Status of the notebook instance is InService, choose the instance and then choose\\nOpen JupyterLab.\\nAfter you open up your SageMaker AI notebook, you can try out the following examples:\\nTopics\\n• List the foundation models that Amazon Bedrock has to offer\\n• Submit a text prompt to a model and generate a response\\nList the foundation models that Amazon Bedrock has to offer\\nThe following example runs the ListFoundationModels operation using an Amazon Bedrock client.\\n ListFoundationModels lists the foundation models (FMs) that are available in Amazon Bedrock\\nin your region. Run the following SDK for Python script to create an Amazon Bedrock client and\\ntest the ListFoundationModels operation:\\n# Use the ListFoundationModels API to show the models that are available in your\\nregion.\\nimport boto3\\n# Create an &BR; client in the &region-us-east-1; Region.\\nbedrock = boto3.client(\\nRun examples with a SageMaker AI notebook 25\\nAmazon Bedrock User Guide\\nservice_name=\"bedrock\"\\n)\\nbedrock.list_foundation_models()\\nIf the script is successful, the response returns a list of foundation models that are available in\\nAmazon Bedrock.\\nSubmit a text prompt to a model and generate a response\\nThe following example runs the Converse operation using an Amazon Bedrock client. Converse\\nlets you submit a prompt to generate a model response. Run the following SDK for Python script to\\ncreate an Amazon Bedrock runtime client and test the Converse operation:\\n'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_qa_dataset(chunks_with_metadata, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
