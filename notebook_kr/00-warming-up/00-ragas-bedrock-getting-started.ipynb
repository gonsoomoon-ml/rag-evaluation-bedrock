{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Bedrock 기반하에 RAGAS 사작 하기\n",
    "- [필수 사항] 이 노트북을 실행하기 이전에 setup/README.md 를 참고하여 \"가상환경\" 을 먼저 설치하시고, 이 가상 환경을 커널로 설정 후에 진행 하세요.\n",
    "- 참고 \n",
    "    - RAGAS Git Repo: [Supercharge Your LLM Application Evaluations](https://github.com/explodinggradients/ragas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 환경 확인\n",
    "- 아래와 같은 버전이 매칭 되어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain                0.3.17\n",
      "langchain-aws            0.2.11\n",
      "langchain-community      0.3.16\n",
      "langchain-core           0.3.33\n",
      "langchain-openai         0.3.3\n",
      "langchain-text-splitters 0.3.5\n",
      "pydantic                 2.10.6\n",
      "pydantic_core            2.27.2\n",
      "pydantic-settings        2.7.1\n",
      "ragas                    0.2.12\n"
     ]
    }
   ],
   "source": [
    " ! pip list | grep -E \"ragas|pydantic|langchain\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ragas 래핑 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from datasets import Dataset\n",
    "\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from ragas import evaluate\n",
    "\n",
    "\n",
    "from ragas.metrics import (\n",
    "    Faithfulness,\n",
    "    AnswerRelevancy,\n",
    "    ContextRecall,\n",
    "    ContextPrecision\n",
    ")\n",
    "\n",
    "# Bedrock 클라이언트 설정\n",
    "bedrock_client = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name='us-west-2'\n",
    ")\n",
    "\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(ChatBedrockConverse(\n",
    "    model=\"anthropic.claude-3-5-haiku-20241022-v1:0\", \n",
    "    client=bedrock_client,\n",
    "))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 랩핑 모델 테스트: 요약 정확도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data: \n",
      " user_input='summarise given text\\nThe company reported an 8% rise in Q3 2024, driven by strong performance in the Asian market. Sales in this region have significantly contributed to the overall growth. Analysts attribute this success to strategic marketing and product localization. The positive trend in the Asian market is expected to continue into the next quarter.' retrieved_contexts=None reference_contexts=None response='The company experienced an 8% increase in Q3 2024, largely due to effective marketing strategies and product adaptation, with expectations of continued growth in the coming quarter.' multi_responses=None reference=None rubrics=None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import SingleTurnSample\n",
    "from ragas.metrics import AspectCritic\n",
    "\n",
    "test_data = {\n",
    "    \"user_input\": \"summarise given text\\nThe company reported an 8% rise in Q3 2024, driven by strong performance in the Asian market. Sales in this region have significantly contributed to the overall growth. Analysts attribute this success to strategic marketing and product localization. The positive trend in the Asian market is expected to continue into the next quarter.\",\n",
    "    \"response\": \"The company experienced an 8% increase in Q3 2024, largely due to effective marketing strategies and product adaptation, with expectations of continued growth in the coming quarter.\",\n",
    "}\n",
    "\n",
    "metric = AspectCritic(name=\"summary_accuracy\",llm=evaluator_llm, definition=\"Verify if the summary is accurate.\")\n",
    "test_data = SingleTurnSample(**test_data)\n",
    "print(\"test_data: \\n\", test_data)\n",
    "await metric.single_turn_ascore(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ragas 래핑 임베딩 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "# from ragas.embeddings import LangchainEmbeddingWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "# Bedrock Embeddings 설정\n",
    "base_embeddings = BedrockEmbeddings(\n",
    "    client=bedrock_client,\n",
    "    model_id=\"amazon.titan-embed-text-v1\"  # 또는 다른 임베딩 모델\n",
    ")\n",
    "\n",
    "# RAGAS Wrapper로 감싸기\n",
    "embeddings_wrapper = LangchainEmbeddingsWrapper(base_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 288.05 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'ground_truth', 'answer', 'response', 'contexts'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_evaluation_dataset(examples):\n",
    "    return {\n",
    "        \"question\": examples[\"question\"],\n",
    "        \"answer\": examples[\"generated_answer\"],\n",
    "        \"response\": examples[\"generated_answer\"],  # response 컬럼 추가\n",
    "        \"contexts\": examples[\"retrieved_contexts\"],\n",
    "        \"ground_truth\": examples[\"ground_truth\"]\n",
    "    }\n",
    "\n",
    "data = [{\n",
    "    \"question\": \"파이썬이란 무엇인가요?\",\n",
    "    \"ground_truth\": \"파이썬은 쉽고 간결한 프로그래밍 언어입니다.\",\n",
    "    \"retrieved_contexts\": [\"파이썬은 프로그래밍 언어입니다.\", \"파이썬은 읽기 쉽고 간결합니다.\"],\n",
    "    \"generated_answer\": \"파이썬은 읽기 쉽고 간결한 프로그래밍 언어입니다.\"\n",
    "}]\n",
    "dataset = Dataset.from_list(data)\n",
    "\n",
    "# 2. RAGAS 평가용 데이터셋 포맷으로 변환\n",
    "eval_dataset = dataset.map(\n",
    "    prepare_evaluation_dataset,\n",
    "    remove_columns=dataset.column_names\n",
    ")\n",
    "eval_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:04<00:00,  1.16s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 1.0000, 'answer_relevancy': 0.9028, 'context_recall': 1.0000, 'context_precision': 1.0000}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 먼저 Faithfulness만 테스트\n",
    "try:\n",
    "    llm = evaluator_llm\n",
    "\n",
    "    metrics = [\n",
    "                Faithfulness(llm=llm),\n",
    "                 AnswerRelevancy(llm=llm, embeddings= embeddings_wrapper),\n",
    "                ContextRecall(llm=llm),\n",
    "                ContextPrecision(llm=llm),\n",
    "    ]\n",
    "    \n",
    "    # 평가 실행a\n",
    "    results = evaluate(\n",
    "        eval_dataset,\n",
    "        metrics=metrics,\n",
    "    )\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {str(e)}\")\n",
    "    print(f\"Error type: {type(e)}\")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
