{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Synthetic Test Datasets\n",
    "\n",
    "**Why use Synthetic Test Datasets?**\n",
    "\n",
    "Evaluating the performance of RAG (Retrieval-Augmented Generation) augmented pipelines is crucial.\n",
    "\n",
    "However, manually creating hundreds of QA (Question-Answer-Context) samples from documents can be time-consuming and labor-intensive. Additionally, human-generated questions may struggle to reach the level of complexity needed for thorough evaluation, ultimately affecting the quality of the assessment.\n",
    "\n",
    "Using synthetic data generation can reduce developer time in the data aggregation process **by up to 90%**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting pdfminer.six==20231228 (from pdfplumber)\n",
      "  Using cached pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in /opt/conda/lib/python3.11/site-packages (from pdfplumber) (10.4.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.11/site-packages (from pdfminer.six==20231228->pdfplumber) (44.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.11/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
      "Downloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
      "Using cached pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
      "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.5 pypdfium2-4.30.1\n"
     ]
    }
   ],
   "source": [
    "! pip install pdfplumber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class PDFLoader:\n",
    "    def __init__(self, file_path: str, start_page: int = None, end_page: int = None):\n",
    "        self.file_path = file_path\n",
    "        self.start_page = start_page\n",
    "        self.end_page = end_page\n",
    "\n",
    "    def load(self) -> Dict[str, Any]:\n",
    "        combined_text = \"\"\n",
    "        metadata = {}\n",
    "\n",
    "        with pdfplumber.open(self.file_path) as pdf:\n",
    "            total_pages = len(pdf.pages)\n",
    "\n",
    "            start = (self.start_page or 1) - 1\n",
    "            end = min(self.end_page or total_pages, total_pages)\n",
    "\n",
    "            for page_num in range(start, end):\n",
    "                page = pdf.pages[page_num]\n",
    "                text = page.extract_text()\n",
    "                combined_text += text + \"\\n\"\n",
    "\n",
    "            metadata = {\n",
    "                \"source\": self.file_path,\n",
    "                \"filename\": self.file_path,\n",
    "                \"total_pages\": total_pages,\n",
    "                \"extracted_pages\": f\"{start + 1}-{end}\"\n",
    "            }\n",
    "\n",
    "            for key, value in pdf.metadata.items():\n",
    "                if isinstance(value, (str, int)):\n",
    "                    metadata[key] = value\n",
    "\n",
    "        return {\n",
    "            \"page_content\": combined_text.strip(),\n",
    "            \"metadata\": metadata\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Used for Practice\n",
    "\n",
    "Amazon Bedrock Manual Documentation (https://docs.aws.amazon.com/bedrock/latest/userguide/)\n",
    "\n",
    "- Link: https://d1jp7kj5nqor8j.cloudfront.net/bedrock-manual.pdf\n",
    "- File name: `bedrock-manual.pdf`\n",
    "\n",
    "_Please copy the downloaded file to the data folder for the practice session_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PDFLoader(\"data/bedrock-ug.pdf\", start_page=19, end_page=100)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Optional\n",
    "\n",
    "def split_text(text: str, chunk_size: int = 1000, chunk_overlap: int = 100, separators: Optional[List[str]] = None) -> List[str]:\n",
    "    separators = separators or [\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "\n",
    "    def _split_text_recursive(text: str, separators: List[str]) -> List[str]:\n",
    "        if not separators:\n",
    "            return [text]\n",
    "\n",
    "        separator = separators[0]\n",
    "        splits = re.split(f\"({re.escape(separator)})\", text)\n",
    "        splits = [\"\".join(splits[i:i+2]) for i in range(0, len(splits), 2)]\n",
    "\n",
    "        final_chunks = []\n",
    "        current_chunk = \"\"\n",
    "\n",
    "        for split in splits:\n",
    "            if len(current_chunk) + len(split) <= chunk_size:\n",
    "                current_chunk += split\n",
    "            else:\n",
    "                if current_chunk:\n",
    "                    final_chunks.append(current_chunk)\n",
    "                if len(split) > chunk_size:\n",
    "                    subsplits = _split_text_recursive(split, separators[1:])\n",
    "                    final_chunks.extend(subsplits)\n",
    "                else:\n",
    "                    current_chunk = split\n",
    "\n",
    "        if current_chunk:\n",
    "            final_chunks.append(current_chunk)\n",
    "\n",
    "        return final_chunks\n",
    "\n",
    "    chunks = _split_text_recursive(text, separators)\n",
    "\n",
    "    if chunk_overlap > 0:\n",
    "        overlapped_chunks = []\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            if i == 0:\n",
    "                overlapped_chunks.append(chunk)\n",
    "            else:\n",
    "                overlap_text = chunks[i-1][-chunk_overlap:]\n",
    "                overlapped_chunks.append(overlap_text + chunk)\n",
    "        chunks = overlapped_chunks\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = split_text(docs['page_content'], 1000, 0)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_with_metadata = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunks_with_metadata.append({\n",
    "        'content': chunk,\n",
    "        'metadata': {\n",
    "            'chunk_id': i,\n",
    "            'filename': docs['metadata'].get('filename', 'unknown')\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"Amazon Bedrock User Guide\\nWhat is Amazon Bedrock?\\nAmazon Bedrock is a fully managed service that makes high-performing foundation models (FMs)\\nfrom leading AI companies and Amazon available for your use through a unified API. You can\\nchoose from a wide range of foundation models to find the model that is best suited for your use\\ncase. Amazon Bedrock also offers a broad set of capabilities to build generative AI applications with\\nsecurity, privacy, and responsible AI. Using Amazon Bedrock, you can easily experiment with and\\nevaluate top foundation models for your use cases, privately customize them with your data using\\ntechniques such as fine-tuning and Retrieval Augmented Generation (RAG), and build agents that\\nexecute tasks using your enterprise systems and data sources.\\nWith Amazon Bedrock's serverless experience, you can get started quickly, privately customize\\nfoundation models with your own data, and easily and securely integrate and deploy them into\\n\",\n",
       " 'metadata': {'chunk_id': 0, 'filename': 'data/bedrock-ug.pdf'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_with_metadata[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Q&A Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.config import Config\n",
    "\n",
    "region = 'us-west-2'\n",
    "retry_config = Config(\n",
    "    region_name=region,\n",
    "    retries={\"max_attempts\": 10, \"mode\": \"standard\"}\n",
    ")\n",
    "boto3_client = boto3.client(\"bedrock-runtime\", region_name=region, config=retry_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from time import sleep\n",
    "\n",
    "def converse_with_bedrock(model_id, sys_prompt, usr_prompt):\n",
    "    temperature = 0.5\n",
    "    top_p = 0.9\n",
    "    inference_config = {\"temperature\": temperature, \"topP\": top_p}\n",
    "    response = boto3_client.converse(\n",
    "        modelId=model_id,\n",
    "        messages=usr_prompt, \n",
    "        system=sys_prompt,\n",
    "        inferenceConfig=inference_config,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def create_prompt(sys_template, user_template):\n",
    "    sys_prompt = [{\"text\": sys_template}]\n",
    "    usr_prompt = [{\"role\": \"user\", \"content\": [{\"text\": user_template}]}]\n",
    "    return sys_prompt, usr_prompt\n",
    "\n",
    "def get_context_chunks(chunks_with_metadata, start_id):\n",
    "    context_chunks = [\n",
    "        chunks_with_metadata[start_id]['content'],\n",
    "        chunks_with_metadata[start_id + 1]['content'],\n",
    "        chunks_with_metadata[start_id + 2]['content']\n",
    "    ]\n",
    "    return \" \".join(context_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Use \n",
    "\n",
    "LLM will generate Q&A dataset that conforms to the schema description in the tooluse config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_config = {\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"QuestionAnswerGenerator\",\n",
    "                \"description\": \"Generates questions and answers based on the given context.\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"question\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The generated question\"\n",
    "                            },\n",
    "                            \"answer\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The answer to the generated question\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"question\", \"answer\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converse_with_bedrock_tools(sys_prompt, usr_prompt, tool_config):\n",
    "    temperature = 0.0\n",
    "    top_p = 0.1\n",
    "    top_k = 1\n",
    "    inference_config = {\"temperature\": temperature, \"topP\": top_p}\n",
    "    additional_model_fields = {\"top_k\": top_k}\n",
    "    response = boto3_client.converse(\n",
    "        modelId=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "        messages=usr_prompt,\n",
    "        system=sys_prompt,\n",
    "        inferenceConfig=inference_config,\n",
    "        additionalModelRequestFields=additional_model_fields,\n",
    "        toolConfig=tool_config\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def parse_tool_use(message):\n",
    "    stop_reason = message['stopReason']\n",
    "\n",
    "    if stop_reason == 'tool_use':\n",
    "        tool_requests = message['output']['message']['content']\n",
    "        for tool_request in tool_requests:\n",
    "            if 'toolUse' in tool_request:\n",
    "                tool = tool_request['toolUse']\n",
    "\n",
    "                if tool['name'] == 'QuestionAnswerGenerator':\n",
    "                    return tool['input']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A Dataset Generation Instruction\n",
    "\n",
    "- `simple`: directly answerable questions from the given context\n",
    "- `complex`: reasoning questions and answers.\n",
    "\n",
    "_Modify the system/user prompts tailored to your dataset_\n",
    "\n",
    "Generated Q&A pair will be stored in `data/qa_dataset.jsonl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_dataset(chunks, num_pairs=5, output_file=\"data/sample_qa_dataset.jsonl\"):\n",
    "    total_chunks = len(chunks)\n",
    "    dataset = []\n",
    "\n",
    "    for i in range(num_pairs):\n",
    "        start_id = random.randint(0, total_chunks - 3)\n",
    "        context = get_context_chunks(chunks_with_metadata, start_id)\n",
    "\n",
    "        if i % 2 == 0:\n",
    "            sys_template = \"\"\"\n",
    "            You are an expert at generating practical questions based on given documentation.\n",
    "            Your task is to generate complex, reasoning questions and answers.\n",
    "\n",
    "            Follow these rules:\n",
    "            1. Generate questions that reflect real user information needs related to the document's subject matter (e.g., technical docs : feature availability, implementation details)\n",
    "            2. Ensure questions are relevant, concise, preferably under 25 words, and fully answerable with the provided information\n",
    "            3. Focus on extracting key information that users are likely to seek, while avoiding narrow or less important questions.\n",
    "            4. When provided with code blocks, focus on understanding the overall functionality rather than the specific syntax or variables. Feel free to request examples of how to use key APIs or features.\n",
    "            5. Do not use phrases like 'based on the provided context' or 'according to the context'.\n",
    "            \"\"\"\n",
    "            question_type = \"complex\"\n",
    "        else:\n",
    "            sys_template = \"\"\"\n",
    "            You are an expert at generating practical questions based on given documentation.\n",
    "            Your task is to create simple, directly answerable questions from the given context.\n",
    "\n",
    "            Follow these rules:\n",
    "            1. Generate questions that reflect real user information needs related to the document's subject matter (e.g., technical docs : feature availability, implementation details)\n",
    "            2. Ensure questions are relevant, concise, preferably under 10 words, and fully answerable with the provided information\n",
    "            3. Focus on extracting key information that users are likely to seek, while avoiding narrow or less important questions.\n",
    "            4. When provided with code blocks, focus on understanding the overall functionality rather than the specific syntax or variables. Feel free to request examples of how to use key APIs or features.\n",
    "            5. Do not use phrases like 'based on the provided context' or 'according to the context'.\n",
    "            \"\"\"\n",
    "            question_type = \"simple\"\n",
    "\n",
    "        user_template = f\"\"\"\n",
    "        Generate a {question_type} question and its answer based on the following context:\n",
    "\n",
    "        Context: {context}\n",
    "\n",
    "        Use the QuestionAnswerGenerator tool to provide the output.\n",
    "        \"\"\"\n",
    "\n",
    "        sys_prompt, user_prompt = create_prompt(sys_template, user_template)\n",
    "        response = converse_with_bedrock_tools(sys_prompt, user_prompt, tool_config)\n",
    "        qa_data = parse_tool_use(response)\n",
    "\n",
    "        if qa_data:\n",
    "            qa_item = {\n",
    "                \"question\": qa_data[\"question\"],\n",
    "                \"ground_truth\": qa_data[\"answer\"],\n",
    "                \"question_type\": question_type,\n",
    "                \"contexts\": context\n",
    "            }\n",
    "\n",
    "            print(qa_item)\n",
    "\n",
    "            with open(output_file, 'a') as f:\n",
    "                json.dump(qa_item, f)\n",
    "                f.write('\\n')\n",
    "\n",
    "            dataset.append(qa_item)\n",
    "\n",
    "        sleep(5)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'question': 'What command lists available foundation models in Amazon Bedrock?', \n",
    "'ground_truth': 'The command to list available foundation models in Amazon Bedrock is: aws bedrock list-foundation-models --region us-east-1', \n",
    "'question_type': 'simple', \n",
    "'contexts': 'This section guides you through trying out some common operations in Amazon Bedrock using the\\nAWS CLI to test that your permissions and authentication are set up properly. Before you run the\\nfollowing examples, you should check that you have fulfilled the following prerequisites:\\nPrerequisites\\n• You have an AWS account and a user or role with authentication set up and the necessary\\npermissions for Amazon Bedrock. Otherwise, follow the steps at Getting started with the API.\\n• You\\'ve requested access to the Amazon Titan Text G1 - Express model. Otherwise, follow the\\nsteps at Request access to an Amazon Bedrock foundation model.\\nRequest access to Amazon Bedrock models 18\\nAmazon Bedrock User Guide\\n• You\\'ve installed and set up authentication for the AWS CLI. To install the CLI, follow the steps at\\nInstall or update to the latest version of the AWS CLI. Verify that you\\'ve set up your credentials to\\nuse the CLI by following the steps at Get credentials to grant programmatic access.\\n Test that your permissions are set up properly for Amazon Bedrock, using a user or role that you set\\nup with the proper permissions.\\nTopics\\n• List the foundation models that Amazon Bedrock has to offer\\n• Submit a text prompt to a model and generate a text response with InvokeModel\\n• Submit a text prompt to a model and generate a text response with Converse\\nList the foundation models that Amazon Bedrock has to offer\\nThe following example runs the ListFoundationModels operation using an Amazon Bedrock\\nendpoint. ListFoundationModels lists the foundation models (FMs) that are available in\\nAmazon Bedrock in your region. In a terminal, run the following command:\\naws bedrock list-foundation-models --region us-east-1\\nIf the command is successful, the response returns a list of foundation models that are available in\\nAmazon Bedrock.\\nSubmit a text prompt to a model and generate a text response with InvokeModel\\nThe following example runs the InvokeModel operation using an Amazon Bedrock runtime\\n endpoint. InvokeModel lets you submit a prompt to generate a model response. In a terminal, run\\nthe following command:\\naws bedrock-runtime invoke-model \\\\\\n--model-id amazon.titan-text-express-v1 \\\\\\n--body \\'{\"inputText\": \"Describe the purpose of a \\\\\"hello world\\\\\" program in one line.\",\\n\"textGenerationConfig\" : {\"maxTokenCount\": 512, \"temperature\": 0.5, \"topP\": 0.9}}\\' \\\\\\n--cli-binary-format raw-in-base64-out \\\\\\ninvoke-model-output-text.txt\\nRun examples with the AWS CLI 19\\nAmazon Bedrock User Guide\\nIf the command is successful, the response generated by the model is written to the invoke-\\nmodel-output-text.txt file. The text response is returned in the outputText field, alongside\\naccompanying information.\\nSubmit a text prompt to a model and generate a text response with Converse\\nThe following example runs the Converse operation using an Amazon Bedrock runtime endpoint.\\nConverse lets you submit a prompt to generate a model response. We recommend using\\n'}\n",
    "\n",
    "'question': 'What are the key steps to set up and manage access for Amazon Bedrock in an existing AWS account, and how does this process differ from setting up access for a new administrative user?', \n",
    "'ground_truth': 'For an existing AWS account, the key steps to set up and manage access for Amazon Bedrock are:\\n\\n1. Create an IAM role with the AmazonBedrockFullAccess managed policy.\\n2. Create a custom policy to manage access to Amazon Bedrock models, including marketplace actions like ViewSubscriptions, Unsubscribe, and Subscribe.\\n3. Attach the custom policy to the Amazon Bedrock role.\\n4. Add users to the Amazon Bedrock role and grant them permissions to switch to this role.\\n\\nThis process differs from setting up access for a new administrative user in the following ways:\\n- For new users, you would configure access using the default IAM Identity Center directory.\\n- New administrative users receive a sign-in URL for the AWS access portal.\\n- Existing account setup focuses on creating and managing IAM roles, while new user setup involves creating IAM Identity Center users.\\n- The existing account method provides more granular control over permissions through custom policies, whereas the new user method relies more on predefined access levels within IAM Identity Center.', \n",
    "'question_type': 'complex', \n",
    "'contexts': 'Configure user access with the default IAM Identity Center directory in the AWS IAM Identity\\nCenter User Guide.\\nSign in as the user with administrative access\\n• To sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email\\naddress when you created the IAM Identity Center user.\\nFor help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in\\nthe AWS Sign-In User Guide.\\nTo learn more about IAM, see Identity and access management for Amazon Bedrock and the IAM\\nUser Guide.\\nAfter you have created an administrative user, proceed to I already have an AWS account to set up\\npermissions for Amazon Bedrock.\\nI already have an AWS account\\nUse IAM to create a role for with the necessary permissions to use Amazon Bedrock. You can then\\nadd users to this role to grant the permissions.\\nI already have an AWS account 7\\nAmazon Bedrock User Guide\\nTo create an Amazon Bedrock role\\n 1. Create a role with a name of your choice by following the steps at Creating a role to delegate\\npermissions to an IAM user in the IAM User Guide. When you reach the step to attach a policy\\nto the role, attach the AmazonBedrockFullAccess AWS managed policy.\\n2. Create a new policy to allow your role to manage access to Amazon Bedrock models. From the\\nfollowing list, select the link that corresponds to your method of choice and follow the steps.\\nUse the following JSON object as the policy.\\n• Creating IAM policies (console)\\n• Creating IAM policies (AWS CLI)\\n• Creating IAM policies (AWS API)\\n{\\n\"Version\": \"2012-10-17\",\\n\"Statement\": [\\n{\\n\"Sid\": \"MarketplaceBedrock\",\\n\"Effect\": \"Allow\",\\n\"Action\": [\\n\"aws-marketplace:ViewSubscriptions\",\\n\"aws-marketplace:Unsubscribe\",\\n\"aws-marketplace:Subscribe\"\\n],\\n\"Resource\": \"*\"\\n}\\n]\\n}\\n3. Attach the policy that you created in the last step to your Amazon Bedrock role by following\\nthe steps at Adding and removing IAM identity permissions.\\n To add users to the Amazon Bedrock role\\n1. For users to access an IAM role, you must add them to the role. You can add both users in your\\naccount or from other accounts. To grant users permissions to switch to the Amazon Bedrock\\nrole that you created, follow the steps at Granting a user permissions to switch roles and\\nspecify the Amazon Bedrock role as the Resource.\\nI already have an AWS account 8\\nAmazon Bedrock User Guide\\nNote\\nIf you need to create more users in your account so that you can give them access\\nto the Amazon Bedrock role, follow the steps in Creating an IAM user in your AWS\\naccount.\\n2. After you\\'ve granted a user permissions to use the Amazon Bedrock role, provide the user\\nwith role name and ID or alias of the account to which the role belongs. Then, guide the user\\nthrough how to switch to the role by following the instructions at Providing information to the\\nuser.\\nRequest access to an Amazon Bedrock foundation model\\n'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What are the key steps to set up and manage access for Amazon Bedrock in an existing AWS account, and how does this process differ from setting up access for a new administrative user?', 'ground_truth': 'For an existing AWS account, the key steps to set up and manage access for Amazon Bedrock are:\\n\\n1. Create an IAM role with the AmazonBedrockFullAccess managed policy.\\n2. Create a custom policy to manage access to Amazon Bedrock models, including marketplace actions like ViewSubscriptions, Unsubscribe, and Subscribe.\\n3. Attach the custom policy to the Amazon Bedrock role.\\n4. Add users to the Amazon Bedrock role and grant them permissions to switch to this role.\\n\\nThis process differs from setting up access for a new administrative user in the following ways:\\n- For new users, you would configure access using the default IAM Identity Center directory.\\n- New administrative users receive a sign-in URL for the AWS access portal.\\n- Existing account setup focuses on creating and managing IAM roles, while new user setup involves creating IAM Identity Center users.\\n- The existing account method provides more granular control over permissions through custom policies, whereas the new user method relies more on predefined access levels within IAM Identity Center.', 'question_type': 'complex', 'contexts': 'Configure user access with the default IAM Identity Center directory in the AWS IAM Identity\\nCenter User Guide.\\nSign in as the user with administrative access\\n• To sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email\\naddress when you created the IAM Identity Center user.\\nFor help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in\\nthe AWS Sign-In User Guide.\\nTo learn more about IAM, see Identity and access management for Amazon Bedrock and the IAM\\nUser Guide.\\nAfter you have created an administrative user, proceed to I already have an AWS account to set up\\npermissions for Amazon Bedrock.\\nI already have an AWS account\\nUse IAM to create a role for with the necessary permissions to use Amazon Bedrock. You can then\\nadd users to this role to grant the permissions.\\nI already have an AWS account 7\\nAmazon Bedrock User Guide\\nTo create an Amazon Bedrock role\\n 1. Create a role with a name of your choice by following the steps at Creating a role to delegate\\npermissions to an IAM user in the IAM User Guide. When you reach the step to attach a policy\\nto the role, attach the AmazonBedrockFullAccess AWS managed policy.\\n2. Create a new policy to allow your role to manage access to Amazon Bedrock models. From the\\nfollowing list, select the link that corresponds to your method of choice and follow the steps.\\nUse the following JSON object as the policy.\\n• Creating IAM policies (console)\\n• Creating IAM policies (AWS CLI)\\n• Creating IAM policies (AWS API)\\n{\\n\"Version\": \"2012-10-17\",\\n\"Statement\": [\\n{\\n\"Sid\": \"MarketplaceBedrock\",\\n\"Effect\": \"Allow\",\\n\"Action\": [\\n\"aws-marketplace:ViewSubscriptions\",\\n\"aws-marketplace:Unsubscribe\",\\n\"aws-marketplace:Subscribe\"\\n],\\n\"Resource\": \"*\"\\n}\\n]\\n}\\n3. Attach the policy that you created in the last step to your Amazon Bedrock role by following\\nthe steps at Adding and removing IAM identity permissions.\\n To add users to the Amazon Bedrock role\\n1. For users to access an IAM role, you must add them to the role. You can add both users in your\\naccount or from other accounts. To grant users permissions to switch to the Amazon Bedrock\\nrole that you created, follow the steps at Granting a user permissions to switch roles and\\nspecify the Amazon Bedrock role as the Resource.\\nI already have an AWS account 8\\nAmazon Bedrock User Guide\\nNote\\nIf you need to create more users in your account so that you can give them access\\nto the Amazon Bedrock role, follow the steps in Creating an IAM user in your AWS\\naccount.\\n2. After you\\'ve granted a user permissions to use the Amazon Bedrock role, provide the user\\nwith role name and ID or alias of the account to which the role belongs. Then, guide the user\\nthrough how to switch to the role by following the instructions at Providing information to the\\nuser.\\nRequest access to an Amazon Bedrock foundation model\\n'}\n",
      "{'question': 'What command lists available foundation models in Amazon Bedrock?', 'ground_truth': 'The command to list available foundation models in Amazon Bedrock is: aws bedrock list-foundation-models --region us-east-1', 'question_type': 'simple', 'contexts': 'This section guides you through trying out some common operations in Amazon Bedrock using the\\nAWS CLI to test that your permissions and authentication are set up properly. Before you run the\\nfollowing examples, you should check that you have fulfilled the following prerequisites:\\nPrerequisites\\n• You have an AWS account and a user or role with authentication set up and the necessary\\npermissions for Amazon Bedrock. Otherwise, follow the steps at Getting started with the API.\\n• You\\'ve requested access to the Amazon Titan Text G1 - Express model. Otherwise, follow the\\nsteps at Request access to an Amazon Bedrock foundation model.\\nRequest access to Amazon Bedrock models 18\\nAmazon Bedrock User Guide\\n• You\\'ve installed and set up authentication for the AWS CLI. To install the CLI, follow the steps at\\nInstall or update to the latest version of the AWS CLI. Verify that you\\'ve set up your credentials to\\nuse the CLI by following the steps at Get credentials to grant programmatic access.\\n Test that your permissions are set up properly for Amazon Bedrock, using a user or role that you set\\nup with the proper permissions.\\nTopics\\n• List the foundation models that Amazon Bedrock has to offer\\n• Submit a text prompt to a model and generate a text response with InvokeModel\\n• Submit a text prompt to a model and generate a text response with Converse\\nList the foundation models that Amazon Bedrock has to offer\\nThe following example runs the ListFoundationModels operation using an Amazon Bedrock\\nendpoint. ListFoundationModels lists the foundation models (FMs) that are available in\\nAmazon Bedrock in your region. In a terminal, run the following command:\\naws bedrock list-foundation-models --region us-east-1\\nIf the command is successful, the response returns a list of foundation models that are available in\\nAmazon Bedrock.\\nSubmit a text prompt to a model and generate a text response with InvokeModel\\nThe following example runs the InvokeModel operation using an Amazon Bedrock runtime\\n endpoint. InvokeModel lets you submit a prompt to generate a model response. In a terminal, run\\nthe following command:\\naws bedrock-runtime invoke-model \\\\\\n--model-id amazon.titan-text-express-v1 \\\\\\n--body \\'{\"inputText\": \"Describe the purpose of a \\\\\"hello world\\\\\" program in one line.\",\\n\"textGenerationConfig\" : {\"maxTokenCount\": 512, \"temperature\": 0.5, \"topP\": 0.9}}\\' \\\\\\n--cli-binary-format raw-in-base64-out \\\\\\ninvoke-model-output-text.txt\\nRun examples with the AWS CLI 19\\nAmazon Bedrock User Guide\\nIf the command is successful, the response generated by the model is written to the invoke-\\nmodel-output-text.txt file. The text response is returned in the outputText field, alongside\\naccompanying information.\\nSubmit a text prompt to a model and generate a text response with Converse\\nThe following example runs the Converse operation using an Amazon Bedrock runtime endpoint.\\nConverse lets you submit a prompt to generate a model response. We recommend using\\n'}\n",
      "{'question': \"How does Amazon Bedrock's pricing model work, and what factors should a developer consider when estimating costs for a project that involves heavy use of foundation models?\", 'ground_truth': \"Amazon Bedrock's pricing model is based on the volume of input and output tokens processed during model inference. Developers should consider several factors when estimating costs:\\n\\n1. Model selection: Different foundation models have varying pricing structures.\\n2. Usage volume: Costs are directly related to the number of tokens processed.\\n3. Provisioned Throughput: Purchasing this can affect pricing and should be considered for high-volume applications.\\n4. Input vs. Output tokens: Pricing may differ for input and output tokens.\\n5. Model access: Developers must request access to foundation models before use, which may impact project timelines.\\n6. Use case complexity: More complex prompts or tasks may require more tokens, increasing costs.\\n\\nTo accurately estimate costs, developers should review the specific pricing for each model on the Model providers page in the Amazon Bedrock console, consider their application's expected usage patterns, and potentially explore Provisioned Throughput options for high-volume scenarios. They should also factor in the potential need for multiple model types if their project requires varied AI capabilities (text generation, image generation, embeddings, etc.).\", 'question_type': 'complex', 'contexts': \"How do I get started with Amazon Bedrock? 2\\nAmazon Bedrock User Guide\\n4. Read the documentation for the features that you want to include in your application.\\nAmazon Bedrock pricing\\nWhen you sign up for AWS, your AWS account is automatically signed up for all services in AWS,\\nincluding Amazon Bedrock. However, you are charged only for the services that you use.\\nFor information about pricing for different Amazon Bedrock resources, see Amazon Bedrock\\nPricing.\\nTo see your bill, go to the Billing and Cost Management Dashboard in the AWS Billing and Cost\\nManagement console. To learn more about AWS account billing, see the AWS Billing User Guide. If\\nyou have questions concerning AWS billing and AWS accounts, contact AWS Support.\\nWith Amazon Bedrock, you pay to run inference on any of the third-party foundation models.\\nPricing is based on the volume of input tokens and output tokens, and on whether you have\\n purchased Provisioned Throughput for the model. For more information, see the Model providers\\npage in the Amazon Bedrock console. For each model, pricing is listed following the model version.\\nFor more information about purchasing Provisioned Throughput, see Increase model invocation\\ncapacity with Provisioned Throughput in Amazon Bedrock.\\nKey terminology\\nThis chapter explains terminology that will help you understand what Amazon Bedrock offers\\nand how it works. Read through the following list to understand generative AI terminology and\\nAmazon Bedrock's fundamental capabilities:\\n• Foundation model (FM) – An AI model with a large number of parameters and trained on a\\nmassive amount of diverse data. A foundation model can generate a variety of responses for a\\nwide range of use cases. Foundation models can generate text or image, and can also convert\\ninput into embeddings. Before you can use an Amazon Bedrock foundation model, you must\\n request access. For more information about foundation models, see Supported foundation\\nmodels in Amazon Bedrock.\\n• Base model – A foundation model that is packaged by a provider and ready to use. Amazon\\nBedrock offers a variety of industry-leading foundation models from leading providers. For more\\ninformation, see Supported foundation models in Amazon Bedrock.\\nAmazon Bedrock pricing 3\\nAmazon Bedrock User Guide\\n• Model inference – The process of a foundation model generating an output (response) from a\\ngiven input (prompt). For more information, see Submit prompts and generate responses with\\nmodel inference.\\n• Prompt – An input provided to a model to guide it to generate an appropriate response or\\noutput for the input. For example, a text prompt can consist of a single line for the model\\nto respond to, or it can detail instructions or a task for the model to perform. The prompt\\ncan contain the context of the task, examples of outputs, or text for a model to use in its\\n\"}\n",
      "{'question': 'Which regions support the Cohere Command model?', 'ground_truth': 'The Cohere Command model is supported in US East (N. Virginia) and US West (Oregon) regions.', 'question_type': 'simple', 'contexts': 'East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nR\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nEnglish\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nMultiling\\nual\\nCohere\\nNo No Yes No No Yes No No No No Yes Yes No No No No No\\nRerank\\n3.5\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n8B\\nInstruct\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n70B\\nInstruct\\nModel support by Region 76\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nMeta\\nYes* Yes* Yes No No No No No No No No No No No No No No\\nLlama\\n3.1\\n8B\\nInstruct\\nMeta\\nYes* Yes* Yes No No No No No No No No No No No No No No\\nLlama\\n3.1\\n70B\\nInstruct\\nMeta\\nNo Yes* Yes No No No No No No No No No No No No No No\\nLlama\\n3.1\\n405B\\nInstruct\\nMeta\\nYes* Yes* Yes* No No No No No No No No Yes* No GatedNo Yes* No\\nLlama\\n3.2\\n1B\\nInstruct\\nMeta\\nYes* Yes* Yes* No No No No No No No No Yes* No GatedNo Yes* No\\nLlama\\n3.2\\n3B\\nInstruct\\nModel support by Region 77\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n (N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nMeta\\nYes* Yes* Yes* No No No No No No No No No No No No No No\\nLlama\\n3.2\\n11B\\nInstruct\\nMeta\\nYes* Yes* Yes* No No No No No No No No No No No No No No\\nLlama\\n3.2\\n90B\\nInstruct\\nMeta\\nYes* Yes Yes* No No No No No No No No No No No No No No\\nLlama\\n3.3\\n70B\\nInstruct\\nMistral\\nYes No Yes No No No No Yes No Yes Yes No No GatedYes Yes Yes\\nAI\\nMistral\\n7B\\nInstruct\\nMistral\\nYes No Yes No No No No Yes No Yes Yes No No GatedYes Yes Yes\\nAI\\nMistral\\nLarge\\n(24.02)\\nModel support by Region 78\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nMistral\\nNo No Yes No No No No No No No No No No No No No No\\n'}\n",
      "{'question': 'What are the key steps and security measures involved in setting up a new AWS account, and why is it crucial to differentiate between root user and administrative access?', 'ground_truth': \"Setting up a new AWS account involves several key steps and security measures. First, you sign up at https://portal.aws.amazon.com/billing/signup, which includes phone verification. This process creates an AWS account root user. However, it's crucial to differentiate between root user and administrative access for security reasons. As a best practice, you should only use the root user for tasks that specifically require root access. Instead, you should create a separate user with administrative privileges for day-to-day management. Additionally, it's essential to secure the root user by enabling multi-factor authentication (MFA). This adds an extra layer of security to prevent unauthorized access. Finally, for programmatic access to AWS services outside the console, you need to obtain the appropriate credentials, which vary depending on the type of user (IAM user, etc.) and the interface you're using (AWS CLI, SDKs, or APIs). These steps collectively ensure a secure foundation for your AWS account, minimizing the risk of unauthorized access and following the principle of least privilege.\", 'question_type': 'complex', 'contexts': \"sections pertain to you, expand them and follow the instructions. Otherwise, proceed through the\\nremaining sections.\\nI'm new to AWS\\nIf you do not have an AWS account, complete the following steps to create one.\\nTo sign up for an AWS account\\n1. Open https://portal.aws.amazon.com/billing/signup.\\n2. Follow the online instructions.\\nPart of the sign-up procedure involves receiving a phone call and entering a verification code\\non the phone keypad.\\nWhen you sign up for an AWS account, an AWS account root user is created. The root user\\nhas access to all AWS services and resources in the account. As a security best practice, assign\\nadministrative access to a user, and use only the root user to perform tasks that require root\\nuser access.\\nGetting started with the API 12\\nAmazon Bedrock User Guide\\nAWS sends you a confirmation email after the sign-up process isn complete. At any time, you can\\nview your current account activity and manage your account by going to https://aws.amazon.com/\\n and choosing My Account.\\nSecure your AWS account root user\\n1. Sign in to the AWS Management Console as the account owner by choosing Root user and\\nentering your AWS account email address. On the next page, enter your password.\\nFor help signing in by using root user, see Signing in as the root user in the AWS Sign-In User\\nGuide.\\n2. Turn on multi-factor authentication (MFA) for your root user.\\nFor instructions, see Enable a virtual MFA device for your AWS account root user (console) in\\nthe IAM User Guide.\\nI need to install the AWS CLI or an AWS SDK\\nTo install the AWS CLI, follow the steps at Install or update to the latest version of the AWS CLI.\\nTo install an AWS SDK, select the tab that corresponds to the programming language that you\\nwant to use at Tools to Build on AWS. AWS software development kits (SDKs) are available\\nfor many popular programming languages. Each SDK provides an API, code examples, and\\n documentation that make it easier for developers to build applications in their preferred language.\\nSDKs automatically perform useful tasks for you, such as:\\n• Cryptographically sign your service requests\\n• Retry requests\\n• Handle error responses\\nGet credentials to grant programmatic access\\nUsers need programmatic access if they want to interact with AWS outside of the AWS\\nManagement Console. The way to grant programmatic access depends on the type of user that's\\naccessing AWS.\\nTo grant users programmatic access, choose one of the following options.\\nGet credentials to grant programmatic access 13\\nAmazon Bedrock User Guide\\nWhich principal needs To By\\nprogrammatic access?\\nIAM users Limit the duration of long- Following the instructions for\\nterm credentials to sign the interface that you want to\\nprogrammatic requests to the use.\\nAWS CLI, AWS SDKs, or AWS\\n• For the AWS CLI, see\\nAPIs.\\nAuthenticating using IAM\\nuser credentials in the AWS\\nCommand Line Interface\\nUser Guide.\\n\"}\n",
      "{'question': 'Which region supports the Stability AI SDXL 1.0 model?', 'ground_truth': 'The Stability AI SDXL 1.0 model is supported in the US East (N. Virginia) and US West (Oregon) regions.', 'question_type': 'simple', 'contexts': 'No No Yes No No No No No No No No No No No No No No\\nAI\\nStable\\nImage\\nUltra\\n1.0\\nStability\\nNo No Yes No No No No No No No No No No No No No No\\nAI\\nStable\\nImage\\nUltra\\n1.0\\nModel support by Region 80\\nAmazon Bedrock User Guide\\nNote\\n* Some models are accessible in some Regions only through cross-region inference. To learn\\nmore about cross-region inference, see Increase throughput with cross-region inference and\\nSupported Regions and models for inference profiles.\\nThe following table shows Region support for models that have a target date for deprecation. For\\nmore information, see Model lifecycle.\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJ2\\n Grande\\nInstruct\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJ2\\nJumbo\\nInstruct\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJurassic-\\n2\\nMid\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJurassic-\\nModel support by Region 81\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\n2\\nUltra\\nStability\\nYes No Yes No No No No No No No No No No No No No No\\nAI\\nSDXL\\n1.0\\nTo learn more about Region and model support for specific features, see the following links:\\n• Converse API\\n• Batch inference\\n• Inference profiles\\n• Latency optimization\\n• Prompt management\\n• Prompt management\\n• Prompt optimization\\n• Amazon Bedrock Guardrails\\n• Model evaluation\\n • RAG evaluation\\n• Amazon Bedrock Knowledge Bases\\n• Rerank\\n• Amazon Bedrock Agents\\n• Amazon Bedrock Flows\\n• Model customization\\n• Amazon Bedrock Custom Model Import\\n• Provisioned Throughput\\n• Amazon Bedrock Studio\\nModel support by Region 82'}\n",
      "{'question': \"How does the availability of streaming support and input/output modalities differ between AI21 Labs' Jurassic models and Amazon's Nova models in Amazon Bedrock, and what implications might this have for developers choosing between them?\", 'ground_truth': \"The AI21 Labs' Jurassic models (Jamba 1.5 Large, Jamba 1.5 Mini, and Jamba-Instruct) and Amazon's Nova models (Nova and Nova Lite) have distinct differences in streaming support and input/output modalities:\\n\\n1. Streaming support:\\n   - AI21 Labs models: All support streaming\\n   - Amazon Nova: Does not support streaming\\n   - Amazon Nova Lite: Supports streaming\\n\\n2. Input modalities:\\n   - AI21 Labs models: Text only\\n   - Amazon Nova: Text and Image\\n   - Amazon Nova Lite: Text, Image, and Video\\n\\n3. Output modalities:\\n   - AI21 Labs models: Text and Chat\\n   - Amazon Nova: Image only\\n   - Amazon Nova Lite: Text\\n\\nThese differences have several implications for developers:\\n\\n1. Real-time applications: AI21 Labs models and Nova Lite are more suitable for real-time, interactive applications due to their streaming support.\\n\\n2. Multimodal capabilities: Amazon's Nova models offer more versatility in handling different types of input data, making them better suited for applications that need to process images or videos alongside text.\\n\\n3. Output format: AI21 Labs models are more appropriate for text-generation tasks, while Nova is specialized for image generation. Nova Lite offers a balance with text output capabilities.\\n\\n4. Use case specificity: Developers need to carefully consider their application requirements when choosing between these models, as they have distinct strengths in different areas (e.g., text processing vs. image processing).\\n\\n5. API integration: The differences in input/output modalities and streaming support may require different API integration approaches for each model family.\\n\\nBy understanding these differences, developers can select the most appropriate model for their specific use case, considering factors such as real-time requirements, input data types, and desired output formats.\", 'question_type': 'complex', 'contexts': \"• Model support by AWS Region in Amazon Bedrock\\n• Feature support by AWS Region in Amazon Bedrock\\n• Model support by feature\\n• Inference request parameters and response fields for foundation models\\n• Custom model hyperparameters\\n• Model lifecycle\\n36\\nAmazon Bedrock User Guide\\nGet information about foundation models\\nIn the Amazon Bedrock console, you can find overarching information about Amazon Bedrock\\nfoundation model providers and the models they provide in the Providers and Base models\\nsections.\\nUse the API to retrieve information about Amazon Bedrock foundation model, including its\\nARN, model ID, modalities and features it supports, and whether it is deprecated or not, in a\\nFoundationModelSummary object.\\n• To return information about all the foundation models that Amazon Bedrock provides, send a\\nListFoundationModels request.\\nNote\\nThe response also returns model IDs that aren't in the base model ID or base model IDs\\n for Provisioned Throughput charts. These model IDs are deprecated or for backwards\\ncompability.\\n• To return information about a specific foundation model, send a GetFoundationModel request,\\nspecifying the model ID.\\nChoose a tab to see code examples in an interface or language.\\nAWS CLI\\nList the Amazon Bedrock foundation models.\\naws bedrock list-foundation-models\\nGet information about Anthropic Claude v2.\\naws bedrock get-foundation-model --model-identifier anthropic.claude-v2\\nPython\\nList the Amazon Bedrock foundation models.\\nimport boto3\\nbedrock = boto3.client(service_name='bedrock')\\nGet model information 37\\nAmazon Bedrock User Guide\\nbedrock.list_foundation_models()\\nGet information about Anthropic Claude v2.\\nimport boto3\\nbedrock = boto3.client(service_name='bedrock')\\nbedrock.get_foundation_model(modelIdentifier='anthropic.claude-v2')\\nSupported foundation models in Amazon Bedrock\\nAmazon Bedrock supports foundation models (FMs) from multiple providers.\\n The following table lists each model alongside the ID that you can use to make on-demand API\\ncalls, the AWS Regions that support it, its capabilities, and links to relevant documentation:\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAI21 Jamba ai21.jamb us- Text Text, Yes Link N/A\\nLabs 1.5 a-1-5- east-1 Chat\\nLarge large-\\nv1:0\\nAI21 Jamba ai21.jamb us- Text Text, Yes Link N/A\\nLabs 1.5 Mini a-1-5- east-1 Chat\\nmini-\\nv1:0\\nAI21 Jamba- ai21.jamb us- Text Text, Yes Link N/A\\nLabs Instruct a- east-1 Chat\\ninstruc\\nt-v1:0\\nAmazon Nova amazon.no us- Text, Image No Link Link\\nCanvas va- east-1 Image\\nSupported foundation models 38\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\ncanvas-\\nv1:0\\nAmazon Nova amazon.no us- Text, Text Yes Link Link\\nLite va-lite- east-1 Image,\\nv1:0 Video\\nus-\\neast-2*\\n\"}\n",
      "{'question': 'What is a token in the context of foundation models?', 'ground_truth': 'A token is a sequence of characters that a model can interpret or predict as a single unit of meaning. It could be a word, part of a word with grammatical meaning, a punctuation mark, or a common phrase.', 'question_type': 'simple', 'contexts': 'request access. For more information about foundation models, see Supported foundation\\nmodels in Amazon Bedrock.\\n• Base model – A foundation model that is packaged by a provider and ready to use. Amazon\\nBedrock offers a variety of industry-leading foundation models from leading providers. For more\\ninformation, see Supported foundation models in Amazon Bedrock.\\nAmazon Bedrock pricing 3\\nAmazon Bedrock User Guide\\n• Model inference – The process of a foundation model generating an output (response) from a\\ngiven input (prompt). For more information, see Submit prompts and generate responses with\\nmodel inference.\\n• Prompt – An input provided to a model to guide it to generate an appropriate response or\\noutput for the input. For example, a text prompt can consist of a single line for the model\\nto respond to, or it can detail instructions or a task for the model to perform. The prompt\\ncan contain the context of the task, examples of outputs, or text for a model to use in its\\n response. Prompts can be used to carry out tasks such as classification, question answering, code\\ngeneration, creative writing, and more. For more information, see Prompt engineering concepts.\\n• Token – A sequence of characters that a model can interpret or predict as a single unit of\\nmeaning. For example, with text models, a token could correspond not just to a word, but also to\\na part of a word with grammatical meaning (such as \"-ed\"), a punctuation mark (such as \"?\"), or a\\ncommon phrase (such as \"a lot\").\\n• Model parameters – Values that define a model and its behavior in interpreting input and\\ngenerating responses. Model parameters are controlled and updated by providers. You can also\\nupdate model parameters to create a new model through the process of model customization.\\n• Inference parameters – Values that can be adjusted during model inference to influence a\\nresponse. Inference parameters can affect how varied responses are and can also limit the length\\n of a response or the occurrence of specified sequences. For more information and definitions of\\nspecific inference parameters, see Influence response generation with inference parameters.\\n• Playground – A user-friendly graphical interface in the AWS Management Console in which\\nyou can experiment with running model inference to familiarize yourself with Amazon Bedrock.\\nUse the playground to test out the effects of different models, configurations, and inference\\nparameters on the responses generated for different prompts that you enter. For more\\ninformation, see Generate responses in the console using playgrounds.\\n• Embedding – The process of condensing information by transforming input into a vector\\nof numerical values, known as the embeddings, in order to compare the similarity between\\ndifferent objects by using a shared numerical representation. For example, sentences can be\\ncompared to determine the similarity in meaning, images can be compared to determine visual\\n'}\n",
      "{'question': 'How does Amazon Bedrock manage access to different foundation models, and what unique considerations exist for Amazon Titan, Mistral AI, and Meta Llama 3 Instruct models?', 'ground_truth': 'Amazon Bedrock manages access to foundation models through a request-based system. Users must request access to specific models before using them, and this access is granted at the AWS account level. However, Amazon Titan, Mistral AI, and Meta Llama 3 Instruct models are exceptions to this rule. These models are always accessible, but their usage can be restricted using IAM policies. To control access to other models, administrators can use the Amazon Bedrock console to modify model access, selecting or deselecting models as needed. Additionally, IAM policies can be used to control who can request access to models, using the \"aws-marketplace:Subscribe\" action and specifying product IDs in the policy conditions.', 'question_type': 'complex', 'contexts': 'Anthropic Claude Instant b0eb9475-3a2c-43d1-94d3-56756fd43737\\nAnthropic Claude 3 Sonnet prod-6dw3qvchef7zy\\nAnthropic Claude 3.5 Sonnet prod-m5ilt4siql27k\\nAnthropic Claude 3.5 Sonnet v2 prod-cx7ovbu5wex7g\\nAnthropic Claude 3 Haiku prod-ozonys2hmmpeu\\nAnthropic Claude 3.5 Haiku prod-5oba7y7jpji56\\nAnthropic Claude 3 Opus prod-fm3feywmwerog\\nGrant permissions to request access to foundation models 30\\nAmazon Bedrock User Guide\\nModel Product ID\\nCohere Command a61c46fe-1747-41aa-9af0-2e0ae8a9ce05\\nCohere Command Light 216b69fd-07d5-4c7b-866b-936456d68311\\nCohere Command R prod-tukx4z3hrewle\\nCohere Command R+ prod-nb4wqmplze2pm\\nCohere Embed (English) b7568428-a1ab-46d8-bab3-37def50f6f6a\\nCohere Embed (Multilingual) 38e55671-c3fe-4a44-9783-3584906e7cad\\nCohere Rerank 3.5 prod-2o5bej62oxkbi\\nStable Diffusion XL 1.0 prod-2lvuzn4iy6n6o\\nStable Image Core 1.0 prod-eacdrmv7zfc5e\\nStable Diffusion 3 Large 1.0 prod-cqfmszl26sxu4\\nStable Image Ultra 1.0 prod-7boen2z2wnxrg\\n{\\n\"Version\": \"2012-10-17\",\\n \"Statement\": [\\n{\\n\"Effect\": \"Allow|Deny\",\\n\"Action\": [\\n\"aws-marketplace:Subscribe\"\\n],\\n\"Resource\": \"*\",\\n\"Condition\": {\\n\"ForAnyValue:StringEquals\": {\\n\"aws-marketplace:ProductId\": [\\nmodel-product-id-1,\\nmodel-product-id-2,\\n...\\n]\\n}\\nGrant permissions to request access to foundation models 31\\nAmazon Bedrock User Guide\\n}\\n},\\n{\\n\"Effect\": \"Allow|Deny\",\\n\"Action\": [\\n\"aws-marketplace:Unsubscribe\"\\n\"aws-marketplace:ViewSubscriptions\"\\n],\\n\"Resource\": \"*\"\\n}\\n]\\n}\\nTo see an example policy, refer to Allow access to third-party model subscriptions.\\nAdd or remove access to Amazon Bedrock foundation models\\nBefore you can use a foundation model in Amazon Bedrock, you must request access to it. If you no\\nlonger need access to a model, you can remove access from it.\\nNote\\nYou can\\'t remove request access from the Amazon Titan, Mistral AI, and Meta Llama 3\\nInstruct models. You can prevent users from making inference calls to these models by\\n using an IAM policy and specifying the model ID. For more information, see Deny access for\\ninference of foundation models.\\nOnce access is provided to a model, it is available for all users in the AWS account.\\nTo add or remove access to foundation models\\n1. Make sure you have permissions to request access, or modify access, to Amazon Bedrock\\nfoundation models.\\n2. Sign into the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/.\\n3. In the left navigation pane, under Bedrock configurations, choose Model access.\\n4. On the Model access page, choose Modify model access.\\n5. Select the models that you want the account to have access to and unselect the models that\\nyou don\\'t want the account to have access to. You have the following options:\\nAdd or remove access to foundation models 32\\nAmazon Bedrock User Guide\\nBe sure to review the End User License Agreement (EULA) for terms and conditions of using a\\nmodel before requesting access to it.\\n'}\n",
      "{'question': 'Which Claude model supports both text and image input?', 'ground_truth': 'Claude 3 Haiku, Claude 3 Opus, Claude 3 Sonnet, Claude 3.5 Haiku, Claude 3.5 Sonnet, and Claude 3.5 Sonnet v2 all support both text and image input according to the information provided.', 'question_type': 'simple', 'contexts': 'l-1\\nAnthropic Claude anthropic us- Text Text, Yes Link N/A\\n2 .claude- east-1 Chat\\nv2\\nus-\\nwest-2\\nap-\\nsouthe\\nast-1\\n(Gated)\\neu-\\ncentra\\nl-1\\nSupported foundation models 48\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n3 Haiku .claude-3 east-1 Image Chat\\n-\\nus-\\nhaiku-20\\neast-2*\\n240307-\\nv1:0\\nus-\\nwest-2\\nus-gov-\\neast-1*\\nus-gov-\\nwest-1\\nap-\\nnorthe\\nast-1\\nap-\\nnorthe\\nast-2\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-1\\n(Gated)\\nap-\\nsouthe\\nast-1\\n(Gated)\\nSupported foundation models 49\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\ncentra\\nl-1\\neu-\\ncentra\\nl-2\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n 3 Opus .claude-3 east-1* Image Chat\\n-\\nus-\\nopus-202\\nwest-2\\n40229-\\nv1:0\\nSupported foundation models 50\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n3 .claude-3 east-1 Image Chat\\nSonnet -\\nus-\\nsonnet-2\\nwest-2\\n0240229-\\nv1:0\\nap-\\nnorthe\\nast-1*\\nap-\\nnorthe\\nast-2*\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-1\\n(Gated)*\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\ncentra\\nl-1\\nSupported foundation models 51\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n3.5 .claude-3 east-1* Image Chat\\nHaiku -5-\\nus-\\nhaiku-\\neast-2*\\n20241022-\\nv1:0\\nus-\\nwest-2\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n 3.5 .claude-3 east-1* Image Chat\\nSonnet -5-\\nus-\\nv2 sonnet\\nwest-2\\n-20241022\\n-v2:0\\nSupported foundation models 52\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n3.5 .claude-3 east-1 Image Chat\\nSonnet -5-\\nus-\\nsonnet\\neast-2*\\n-20240620\\n-v1:0\\nus-\\nwest-2\\nus-gov-\\neast-1*\\nus-gov-\\nwest-1\\nap-\\nnorthe\\nast-1\\nap-\\nnorthe\\nast-2\\nap-\\nsouth-\\n1*\\nap-\\nsouthe\\nast-1\\n(Gated)\\nap-\\nsouthe\\nSupported foundation models 53\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nast-1\\n(Gated)\\nap-\\nsouthe\\nast-2*\\neu-\\ncentra\\nl-1\\neu-\\ncentra\\nl-2\\neu-\\nwest-1\\n(Gated)*\\neu-\\nwest-3*\\nSupported foundation models 54\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\n'}\n",
      "{'question': \"How does Amazon Bedrock's pricing structure work, and what factors should a developer consider when estimating costs for a project that involves heavy use of foundation models?\", 'ground_truth': \"Amazon Bedrock's pricing structure is based on the volume of input and output tokens processed during model inference. Developers should consider several factors when estimating costs:\\n\\n1. Model selection: Different foundation models have varying pricing rates.\\n2. Usage volume: Costs are directly related to the amount of data processed.\\n3. Provisioned Throughput: Purchasing this option can affect pricing.\\n4. Input vs. Output tokens: Pricing distinguishes between these, so the ratio in your application matters.\\n5. Model access: Before using a model, access must be requested, which may impact project timeline and costs.\\n6. Use case complexity: More complex prompts or tasks may require more tokens, increasing costs.\\n\\nTo manage and estimate costs effectively, developers should:\\n- Regularly check the Billing and Cost Management Dashboard\\n- Review the specific pricing for each model on the Model providers page in the Amazon Bedrock console\\n- Consider purchasing Provisioned Throughput for high-volume applications\\n- Optimize prompts to reduce unnecessary token usage\\n\\nBy carefully considering these factors, developers can better estimate and control costs for projects heavily utilizing foundation models in Amazon Bedrock.\", 'question_type': 'complex', 'contexts': \"How do I get started with Amazon Bedrock? 2\\nAmazon Bedrock User Guide\\n4. Read the documentation for the features that you want to include in your application.\\nAmazon Bedrock pricing\\nWhen you sign up for AWS, your AWS account is automatically signed up for all services in AWS,\\nincluding Amazon Bedrock. However, you are charged only for the services that you use.\\nFor information about pricing for different Amazon Bedrock resources, see Amazon Bedrock\\nPricing.\\nTo see your bill, go to the Billing and Cost Management Dashboard in the AWS Billing and Cost\\nManagement console. To learn more about AWS account billing, see the AWS Billing User Guide. If\\nyou have questions concerning AWS billing and AWS accounts, contact AWS Support.\\nWith Amazon Bedrock, you pay to run inference on any of the third-party foundation models.\\nPricing is based on the volume of input tokens and output tokens, and on whether you have\\n purchased Provisioned Throughput for the model. For more information, see the Model providers\\npage in the Amazon Bedrock console. For each model, pricing is listed following the model version.\\nFor more information about purchasing Provisioned Throughput, see Increase model invocation\\ncapacity with Provisioned Throughput in Amazon Bedrock.\\nKey terminology\\nThis chapter explains terminology that will help you understand what Amazon Bedrock offers\\nand how it works. Read through the following list to understand generative AI terminology and\\nAmazon Bedrock's fundamental capabilities:\\n• Foundation model (FM) – An AI model with a large number of parameters and trained on a\\nmassive amount of diverse data. A foundation model can generate a variety of responses for a\\nwide range of use cases. Foundation models can generate text or image, and can also convert\\ninput into embeddings. Before you can use an Amazon Bedrock foundation model, you must\\n request access. For more information about foundation models, see Supported foundation\\nmodels in Amazon Bedrock.\\n• Base model – A foundation model that is packaged by a provider and ready to use. Amazon\\nBedrock offers a variety of industry-leading foundation models from leading providers. For more\\ninformation, see Supported foundation models in Amazon Bedrock.\\nAmazon Bedrock pricing 3\\nAmazon Bedrock User Guide\\n• Model inference – The process of a foundation model generating an output (response) from a\\ngiven input (prompt). For more information, see Submit prompts and generate responses with\\nmodel inference.\\n• Prompt – An input provided to a model to guide it to generate an appropriate response or\\noutput for the input. For example, a text prompt can consist of a single line for the model\\nto respond to, or it can detail instructions or a task for the model to perform. The prompt\\ncan contain the context of the task, examples of outputs, or text for a model to use in its\\n\"}\n",
      "{'question': 'Which AWS Region supports all listed Amazon Titan models?', 'ground_truth': 'US East (N. Virginia) supports all listed Amazon Titan models, including Titan Embeddings, Titan Image Generator, Titan Multimodal Embeddings, Titan Text Embeddings, and Titan Text Express.', 'question_type': 'simple', 'contexts': 'Labs 2 Ultra ultra-v1 east-1 Chat\\nStability SDXL stability us- Text, Image No Link N/A\\nAI 1.0 .stable- east-1 Image\\nd\\nus-\\niffusion-\\nwest-2\\nxl-v1\\nSupported foundation models 70\\nAmazon Bedrock User Guide\\nModel support by AWS Region in Amazon Bedrock\\nFor a list of AWS Regions that support Amazon Bedrock, see Amazon Bedrock endpoints and\\nquotas. Amazon Bedrock foundation models differ in their regional support.\\nThe following table shows Region support by model:\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJamba\\n1.5\\nLarge\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJamba\\n1.5\\nMini\\nAI21\\n Yes No No No No No No No No No No No No No No No No\\nLabs\\nJamba-\\nIns\\ntruct\\nAmazon\\nYes No No No No No No No No No No No No No No No No\\nNova\\nCanvas\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nLite\\nModel support by Region 71\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nMicro\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nPro\\nAmazon\\nYes No No No No No No No No No No No No No No No No\\nNova\\nReel\\nAmazon\\nNo No Yes No No Yes No No No No Yes Yes No No No No No\\nRerank\\n1.0\\nAmazon\\nYes No Yes No No Yes No No No No No Yes No No No No No\\nTitan\\nEmbedding\\ns\\nG1\\n-\\nText\\nAmazon\\n Yes No Yes No No No No No No No No No No No No No No\\nTitan\\nImage\\nGenerator\\nG1\\nv2\\nModel support by Region 72\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAmazon\\nYes No Yes No No No No Yes No No No No No GatedYes No No\\nTitan\\nImage\\nGenerator\\nG1\\nAmazon\\nYes No Yes No No No No Yes No Yes Yes Yes No GatedYes Yes Yes\\nTitan\\nMultimoda\\nl\\nEmbedding\\ns\\nG1\\nAmazon\\nYes Yes Yes Yes Yes Yes Yes Yes No Yes Yes Yes Yes No Yes Yes Yes\\nTitan\\nText\\nEmbedding\\ns\\nV2\\nAmazon\\nYes No Yes No Yes Yes No Yes No Yes Yes Yes No GatedYes Yes Yes\\nTitan\\nText\\nG1\\n-\\nExpress\\nModel support by Region 73\\nAmazon Bedrock User Guide\\n'}\n",
      "{'question': 'What are the key steps to set up and manage access for Amazon Bedrock in an existing AWS account, and how does this process differ from setting up access with IAM Identity Center?', 'ground_truth': \"To set up and manage access for Amazon Bedrock in an existing AWS account, the key steps are:\\n\\n1. Create an IAM role with the AmazonBedrockFullAccess managed policy.\\n2. Create a custom policy to manage access to Amazon Bedrock models, including marketplace actions like ViewSubscriptions, Unsubscribe, and Subscribe.\\n3. Attach the custom policy to the Amazon Bedrock role.\\n4. Add users to the Amazon Bedrock role and grant them permissions to switch to this role.\\n\\nThis process differs from setting up access with IAM Identity Center in several ways:\\n1. It uses traditional IAM roles and policies instead of the centralized identity management provided by IAM Identity Center.\\n2. Users need to switch to the specific Amazon Bedrock role to access the service, rather than using a single sign-on process.\\n3. The setup requires more manual steps, including creating custom policies and managing role assignments, compared to the more streamlined user management in IAM Identity Center.\\n4. There's no mention of a sign-in URL or access portal, which are typically used with IAM Identity Center for user authentication.\", 'question_type': 'complex', 'contexts': 'Configure user access with the default IAM Identity Center directory in the AWS IAM Identity\\nCenter User Guide.\\nSign in as the user with administrative access\\n• To sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email\\naddress when you created the IAM Identity Center user.\\nFor help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in\\nthe AWS Sign-In User Guide.\\nTo learn more about IAM, see Identity and access management for Amazon Bedrock and the IAM\\nUser Guide.\\nAfter you have created an administrative user, proceed to I already have an AWS account to set up\\npermissions for Amazon Bedrock.\\nI already have an AWS account\\nUse IAM to create a role for with the necessary permissions to use Amazon Bedrock. You can then\\nadd users to this role to grant the permissions.\\nI already have an AWS account 7\\nAmazon Bedrock User Guide\\nTo create an Amazon Bedrock role\\n 1. Create a role with a name of your choice by following the steps at Creating a role to delegate\\npermissions to an IAM user in the IAM User Guide. When you reach the step to attach a policy\\nto the role, attach the AmazonBedrockFullAccess AWS managed policy.\\n2. Create a new policy to allow your role to manage access to Amazon Bedrock models. From the\\nfollowing list, select the link that corresponds to your method of choice and follow the steps.\\nUse the following JSON object as the policy.\\n• Creating IAM policies (console)\\n• Creating IAM policies (AWS CLI)\\n• Creating IAM policies (AWS API)\\n{\\n\"Version\": \"2012-10-17\",\\n\"Statement\": [\\n{\\n\"Sid\": \"MarketplaceBedrock\",\\n\"Effect\": \"Allow\",\\n\"Action\": [\\n\"aws-marketplace:ViewSubscriptions\",\\n\"aws-marketplace:Unsubscribe\",\\n\"aws-marketplace:Subscribe\"\\n],\\n\"Resource\": \"*\"\\n}\\n]\\n}\\n3. Attach the policy that you created in the last step to your Amazon Bedrock role by following\\nthe steps at Adding and removing IAM identity permissions.\\n To add users to the Amazon Bedrock role\\n1. For users to access an IAM role, you must add them to the role. You can add both users in your\\naccount or from other accounts. To grant users permissions to switch to the Amazon Bedrock\\nrole that you created, follow the steps at Granting a user permissions to switch roles and\\nspecify the Amazon Bedrock role as the Resource.\\nI already have an AWS account 8\\nAmazon Bedrock User Guide\\nNote\\nIf you need to create more users in your account so that you can give them access\\nto the Amazon Bedrock role, follow the steps in Creating an IAM user in your AWS\\naccount.\\n2. After you\\'ve granted a user permissions to use the Amazon Bedrock role, provide the user\\nwith role name and ID or alias of the account to which the role belongs. Then, guide the user\\nthrough how to switch to the role by following the instructions at Providing information to the\\nuser.\\nRequest access to an Amazon Bedrock foundation model\\n'}\n",
      "{'question': 'How can you get information about a specific foundation model in Amazon Bedrock?', 'ground_truth': 'You can send a GetFoundationModel request, specifying the model ID.', 'question_type': 'simple', 'contexts': \"for Provisioned Throughput charts. These model IDs are deprecated or for backwards\\ncompability.\\n• To return information about a specific foundation model, send a GetFoundationModel request,\\nspecifying the model ID.\\nChoose a tab to see code examples in an interface or language.\\nAWS CLI\\nList the Amazon Bedrock foundation models.\\naws bedrock list-foundation-models\\nGet information about Anthropic Claude v2.\\naws bedrock get-foundation-model --model-identifier anthropic.claude-v2\\nPython\\nList the Amazon Bedrock foundation models.\\nimport boto3\\nbedrock = boto3.client(service_name='bedrock')\\nGet model information 37\\nAmazon Bedrock User Guide\\nbedrock.list_foundation_models()\\nGet information about Anthropic Claude v2.\\nimport boto3\\nbedrock = boto3.client(service_name='bedrock')\\nbedrock.get_foundation_model(modelIdentifier='anthropic.claude-v2')\\nSupported foundation models in Amazon Bedrock\\nAmazon Bedrock supports foundation models (FMs) from multiple providers.\\n The following table lists each model alongside the ID that you can use to make on-demand API\\ncalls, the AWS Regions that support it, its capabilities, and links to relevant documentation:\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAI21 Jamba ai21.jamb us- Text Text, Yes Link N/A\\nLabs 1.5 a-1-5- east-1 Chat\\nLarge large-\\nv1:0\\nAI21 Jamba ai21.jamb us- Text Text, Yes Link N/A\\nLabs 1.5 Mini a-1-5- east-1 Chat\\nmini-\\nv1:0\\nAI21 Jamba- ai21.jamb us- Text Text, Yes Link N/A\\nLabs Instruct a- east-1 Chat\\ninstruc\\nt-v1:0\\nAmazon Nova amazon.no us- Text, Image No Link Link\\nCanvas va- east-1 Image\\nSupported foundation models 38\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\ncanvas-\\nv1:0\\nAmazon Nova amazon.no us- Text, Text Yes Link Link\\nLite va-lite- east-1 Image,\\nv1:0 Video\\nus-\\neast-2*\\n us-\\nwest-2*\\nAmazon Nova amazon.no us- Text Text Yes Link Link\\nMicro va- east-1\\nmicro-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2*\\nAmazon Nova amazon.no us- Text, Text Yes Link Link\\nPro va-pro- east-1 Image,\\nv1:0 Video\\nus-\\neast-2*\\nus-\\nwest-2*\\nAmazon Nova amazon.no us- Text, Video No Link Link\\nReel va-reel- east-1 Image\\nv1:0\\nSupported foundation models 39\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAmazon Rerank amazon.re us- Text Text No N/A N/A\\n1.0 rank- west-2\\nv1:0\\nap-\\nnorthe\\nast-1\\nca-\\ncentra\\nl-1\\neu-\\ncentra\\nl-1\\nAmazon Titan amazon.ti us- Text EmbeddingNo Link N/A\\nEmbeddingt an- east-1\\ns G1 - embed-\\nus-\\nText text-v1\\nwest-2\\nap-\\nnorthe\\nast-1\\neu-\\ncentra\\nl-1\\nAmazon Titan amazon.ti us- Text, Image No Link Link\\nImage tan- east-1 Image\\nGenerator image-\\nus-\\nG1 v2 generato\\nwest-2\\nr-v2:0\\nSupported foundation models 40\\nAmazon Bedrock User Guide\\n\"}\n",
      "{'question': 'Which AI model provider offers the most comprehensive regional coverage, and how does its availability compare to other providers in key global markets like Asia Pacific and Europe?', 'ground_truth': 'Based on the provided information, Anthropic\\'s Claude 3.5 Sonnet v2 offers the most comprehensive regional coverage among the listed AI models. It is available in most regions, including US East, US West, Asia Pacific (Tokyo, Seoul, Mumbai, Singapore, Sydney), and Europe (Frankfurt, Ireland, London, Paris). \\n\\nComparing it to other providers:\\n1. In Asia Pacific: Claude 3.5 Sonnet v2 is available in all listed Asian regions, while most other models have limited or no presence. For example, Cohere\\'s models are mostly unavailable in Asia, and Meta\\'s Llama models are only available in some regions.\\n\\n2. In Europe: Claude 3.5 Sonnet v2 is available in all listed European regions, whereas many other models have limited availability. For instance, Cohere\\'s Command models are not available in Europe, and Meta\\'s Llama models have limited availability, with only some versions available in certain European regions.\\n\\n3. Global presence: Claude 3.5 Sonnet v2 is also available in other key markets like Canada Central and South America (São Paulo), where many other models are not present.\\n\\nIt\\'s worth noting that availability is often marked with an asterisk (*) or as \"Gated\" for Claude 3.5 Sonnet v2 in some regions, which might indicate some restrictions or special access requirements. Despite this, it still offers the widest regional coverage among the models listed in the context.', 'question_type': 'complex', 'contexts': 'East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAnthropic\\nYes No Yes No No Yes* Yes* Yes GatedYes Yes Yes No GatedYes Yes Yes\\nClaude\\n3\\nSonnet\\nAnthropic\\nYes* Yes* Yes No No No No No No No No No No No No No No\\nClaude\\n3.5\\nHaiku\\nAnthropic\\nYes* No Yes No No No No No No No No No No No No No No\\nClaude\\n3.5\\nSonnet\\nv2\\nAnthropic\\nYes Yes* Yes Yes* Yes Yes Yes Yes* GatedYes* No Yes Yes GatedNo Yes* No\\nClaude\\n3.5\\nSonnet\\nAnthropic\\nYes No Yes No No Yes No No GatedNo No Yes No No No No No\\nClaude\\nInstant\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nLight\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nR+\\nModel support by Region 75\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nR\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nEnglish\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nMultiling\\nual\\nCohere\\nNo No Yes No No Yes No No No No Yes Yes No No No No No\\nRerank\\n3.5\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n8B\\nInstruct\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n70B\\nInstruct\\nModel support by Region 76\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nMeta\\nYes* Yes* Yes No No No No No No No No No No No No No No\\nLlama\\n3.1\\n8B\\nInstruct\\nMeta\\nYes* Yes* Yes No No No No No No No No No No No No No No\\nLlama\\n3.1\\n70B\\nInstruct\\nMeta\\nNo Yes* Yes No No No No No No No No No No No No No No\\nLlama\\n3.1\\n405B\\nInstruct\\nMeta\\nYes* Yes* Yes* No No No No No No No No Yes* No GatedNo Yes* No\\nLlama\\n3.2\\n1B\\nInstruct\\nMeta\\nYes* Yes* Yes* No No No No No No No No Yes* No GatedNo Yes* No\\nLlama\\n3.2\\n3B\\nInstruct\\nModel support by Region 77\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n'}\n",
      "{'question': 'What are the two main prerequisites for running Amazon Bedrock examples?', 'ground_truth': 'The two main prerequisites are having an AWS account with necessary permissions for Amazon Bedrock, and requesting access to the Amazon Titan Text G1 - Express model.', 'question_type': 'simple', 'contexts': 'up properly. Before you run the following examples, you should check that you have fulfilled the\\nfollowing prerequisites:\\nPrerequisites\\n• You have an AWS account and have permissions to access a role with the necessary permissions\\nfor Amazon Bedrock. Otherwise, follow the steps at I already have an AWS account.\\n• You\\'ve requested access to the Amazon Titan Text G1 - Express model. Otherwise, follow the\\nsteps at Request access to an Amazon Bedrock foundation model.\\n• Carry out the following steps to set up IAM permissions for SageMaker AI and create a notebook:\\n1. Modify the trust policy of the Amazon Bedrock role that you set up in I already have an AWS\\naccount through the console, CLI, or API. Attach the following trust policy to the role to\\nallow both the Amazon Bedrock and SageMaker AI services to assume the Amazon Bedrock\\nrole:\\n{\\n\"Version\": \"2012-10-17\",\\n\"Statement\": [\\n{\\n\"Sid\": \"BedrockTrust\",\\n\"Effect\": \"Allow\",\\n\"Principal\": {\\n\"Service\": \"bedrock.amazonaws.com\"\\n},\\n Run examples with a SageMaker AI notebook 24\\nAmazon Bedrock User Guide\\n\"Action\": \"sts:AssumeRole\"\\n},\\n{\\n\"Sid\": \"SagemakerTrust\",\\n\"Effect\": \"Allow\",\\n\"Principal\": {\\n\"Service\": \"sagemaker.amazonaws.com\"\\n},\\n\"Action\": \"sts:AssumeRole\"\\n}\\n]\\n}\\n2. Sign into the Amazon Bedrock role whose trust policy you just modified.\\n3. Follow the steps at Create an Amazon SageMaker AI Notebook Instance for the tutorial and\\nspecify the ARN of the Amazon Bedrock role that you created to create an SageMaker AI\\nnotebook instance.\\n4. When the Status of the notebook instance is InService, choose the instance and then choose\\nOpen JupyterLab.\\nAfter you open up your SageMaker AI notebook, you can try out the following examples:\\nTopics\\n• List the foundation models that Amazon Bedrock has to offer\\n• Submit a text prompt to a model and generate a response\\nList the foundation models that Amazon Bedrock has to offer\\nThe following example runs the ListFoundationModels operation using an Amazon Bedrock client.\\n ListFoundationModels lists the foundation models (FMs) that are available in Amazon Bedrock\\nin your region. Run the following SDK for Python script to create an Amazon Bedrock client and\\ntest the ListFoundationModels operation:\\n# Use the ListFoundationModels API to show the models that are available in your\\nregion.\\nimport boto3\\n# Create an &BR; client in the &region-us-east-1; Region.\\nbedrock = boto3.client(\\nRun examples with a SageMaker AI notebook 25\\nAmazon Bedrock User Guide\\nservice_name=\"bedrock\"\\n)\\nbedrock.list_foundation_models()\\nIf the script is successful, the response returns a list of foundation models that are available in\\nAmazon Bedrock.\\nSubmit a text prompt to a model and generate a response\\nThe following example runs the Converse operation using an Amazon Bedrock client. Converse\\nlets you submit a prompt to generate a model response. Run the following SDK for Python script to\\ncreate an Amazon Bedrock runtime client and test the Converse operation:\\n'}\n",
      "{'question': 'How does the regional availability of Amazon Nova models compare to AI21 Labs models in Amazon Bedrock, and what implications might this have for developers choosing between these providers?', 'ground_truth': 'The regional availability of Amazon Nova models is broader compared to AI21 Labs models in Amazon Bedrock. Amazon Nova models (Lite, Micro, and Pro) are available in US East (N. Virginia), and have cross-region inference support in US East (Ohio) and US West (Oregon). In contrast, AI21 Labs models (Jamba 1.5 Large, Jamba 1.5 Mini, and Jamba-Instruct) are only available in US East (N. Virginia) with no cross-region inference support mentioned. This difference in availability implies that developers choosing Amazon Nova models have more flexibility in terms of geographical deployment and potentially lower latency for users in different regions. However, those requiring AI21 Labs models may face limitations if they need to serve users outside the US East region efficiently.', 'question_type': 'complex', 'contexts': 'Stability Stable stability us- Text Image No Link N/A\\nAI Image .stable- west-2\\nUltra image-\\n1.0 ultra-\\nv1:1\\nSupported foundation models 69\\nAmazon Bedrock User Guide\\nNote\\n* Some models are accessible in some Regions only through cross-region inference. To learn\\nmore about cross-region inference, see Increase throughput with cross-region inference and\\nSupported Regions and models for inference profiles.\\nThe following table lists models that have a target date for deprecation. For more information, see\\nModel lifecycle:\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAI21 J2 ai21.j2- us- Text Text, No Link N/A\\nLabs Grande grande- east-1 Chat\\nInstruct instruct\\nAI21 J2 ai21.j2- us- Text Text, No Link N/A\\nLabs Jumbo jumbo- east-1 Chat\\nInstruct instruct\\nAI21 Jurassic- ai21.j2- us- Text Text, No Link N/A\\nLabs 2 Mid mid-v1 east-1 Chat\\nAI21 Jurassic- ai21.j2- us- Text Text, No Link N/A\\n Labs 2 Ultra ultra-v1 east-1 Chat\\nStability SDXL stability us- Text, Image No Link N/A\\nAI 1.0 .stable- east-1 Image\\nd\\nus-\\niffusion-\\nwest-2\\nxl-v1\\nSupported foundation models 70\\nAmazon Bedrock User Guide\\nModel support by AWS Region in Amazon Bedrock\\nFor a list of AWS Regions that support Amazon Bedrock, see Amazon Bedrock endpoints and\\nquotas. Amazon Bedrock foundation models differ in their regional support.\\nThe following table shows Region support by model:\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJamba\\n1.5\\nLarge\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJamba\\n1.5\\nMini\\nAI21\\n Yes No No No No No No No No No No No No No No No No\\nLabs\\nJamba-\\nIns\\ntruct\\nAmazon\\nYes No No No No No No No No No No No No No No No No\\nNova\\nCanvas\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nLite\\nModel support by Region 71\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nMicro\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nPro\\nAmazon\\nYes No No No No No No No No No No No No No No No No\\nNova\\nReel\\nAmazon\\nNo No Yes No No Yes No No No No Yes Yes No No No No No\\nRerank\\n1.0\\nAmazon\\nYes No Yes No No Yes No No No No No Yes No No No No No\\nTitan\\nEmbedding\\ns\\nG1\\n-\\nText\\nAmazon\\n'}\n",
      "{'question': 'Which Meta Llama model supports both text and image input?', 'ground_truth': 'The Meta Llama 3.2 11B and 90B Instruct models support both text and image input.', 'question_type': 'simple', 'contexts': 'Provider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nCohere Rerank cohere.re us- Text Text No Link N/A\\n3.5 rank- west-2\\nv3-5:0\\nap-\\nnorthe\\nast-1\\nca-\\ncentra\\nl-1\\neu-\\ncentra\\nl-1\\nSupported foundation models 60\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3 8B a3-8b- east-1 Chat\\nInstruct ins\\nus-\\ntruct-\\nwest-2\\nv1:0\\nus-gov-\\nwest-1\\nap-\\nsouth-1\\nca-\\ncentra\\nl-1\\neu-\\nwest-2\\nSupported foundation models 61\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3 70B a3-70b- east-1 Chat\\nInstruct in\\nus-\\nstruct-\\nwest-2\\nv1:0\\nus-gov-\\nwest-1\\nap-\\nsouth-1\\nca-\\n centra\\nl-1\\neu-\\nwest-2\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 8B a3-1-8b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 70B a3-1-70b- east-1* Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2\\nSupported foundation models 62\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 a3-1-405b east-2* Chat\\n405B -\\nus-\\nInstruct instruct\\nwest-2\\n-v1:0\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.2 1B a3-2-1b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2*\\neu-\\ncentra\\nl-1*\\neu-\\nwest-1\\n(Gated)*\\neu-\\nwest-3*\\nSupported foundation models 63\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\n Meta Llama meta.llam us- Text Text, Yes Link N/A\\n3.2 3B a3-2-3b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2*\\neu-\\ncentra\\nl-1*\\neu-\\nwest-1\\n(Gated)*\\neu-\\nwest-3*\\nMeta Llama meta.llam us- Text, Text, Yes Link N/A\\n3.2 11B a3-2-11b- east-1* Image Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2*\\nSupported foundation models 64\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text, Text, Yes Link N/A\\n3.2 90B a3-2-90b- east-1* Image Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2*\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.3 70B a3-3-70b- east-1* Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2\\nus-\\nwest-2*\\nSupported foundation models 65\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\n'}\n",
      "{'question': 'What are the key steps for granting a user access to Amazon Bedrock foundation models, and how does the process differ for users within your AWS account versus those from other accounts?', 'ground_truth': 'The process for granting user access to Amazon Bedrock foundation models involves several key steps:\\n\\n1. Add users to the Amazon Bedrock role:\\n   - For users in your account: Grant permissions to switch roles by following the \"Granting a user permissions to switch roles\" procedure.\\n   - For users from other accounts: Add them directly to the Amazon Bedrock role.\\n\\n2. Provide users with the Amazon Bedrock role name and the account ID or alias.\\n\\n3. Guide users on how to switch to the role using the \"Providing information to the user\" instructions.\\n\\n4. Users must sign into the AWS Management Console and switch to the Amazon Bedrock role.\\n\\n5. In the Amazon Bedrock console, users need to:\\n   - Navigate to the Model access page\\n   - Review the End User License Agreement (EULA) for desired models\\n   - Choose \"Modify model access\"\\n   - Request access to specific models or all models\\n   - Submit the access request\\n\\n6. Wait for access to be granted, which may take several minutes.\\n\\nThe main difference in the process for users within your AWS account versus those from other accounts is in the initial step of adding them to the role. Internal users are granted permissions to switch roles, while external users are added directly to the role. The subsequent steps for requesting access to foundation models remain the same for both types of users.', 'question_type': 'complex', 'contexts': \"To add users to the Amazon Bedrock role\\n1. For users to access an IAM role, you must add them to the role. You can add both users in your\\naccount or from other accounts. To grant users permissions to switch to the Amazon Bedrock\\nrole that you created, follow the steps at Granting a user permissions to switch roles and\\nspecify the Amazon Bedrock role as the Resource.\\nI already have an AWS account 8\\nAmazon Bedrock User Guide\\nNote\\nIf you need to create more users in your account so that you can give them access\\nto the Amazon Bedrock role, follow the steps in Creating an IAM user in your AWS\\naccount.\\n2. After you've granted a user permissions to use the Amazon Bedrock role, provide the user\\nwith role name and ID or alias of the account to which the role belongs. Then, guide the user\\nthrough how to switch to the role by following the instructions at Providing information to the\\nuser.\\nRequest access to an Amazon Bedrock foundation model\\n After setting up your Amazon Bedrock IAM role, you can sign into the Amazon Bedrock console and\\nrequest access to foundation models.\\nTo request access to an Amazon Bedrock FM\\n1. Sign into the AWS Management Console and switch to the Amazon Bedrock role that you set\\nup (or that was set up for you) by following the steps under To switch to a role (console) in\\nSwitching to a role (console).\\n2. Open the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/.\\n3. For the purposes of this tutorial, you should be in the US East (N. Virginia) (us-east-1) Region.\\nTo change regions, choose the Region name at the top right of the console, next to your IAM\\nrole. Then select US East (N. Virginia) (us-east-1).\\n4. Select Model access at the bottom of the left navigation pane.\\n5. On the Model access page, you can review the End User License Agreement (EULA) for models\\nin the EULA column in the Base models table.\\n6. Choose Modify model access.\\n7. Do one of the following:\\n • To request access to all models, choose Enable all models. On the page you're taken to,\\nthe checkboxes next to all the models will be filled.\\n• To request access to specific models, choose Enable specific models. On the page you're\\ntaken to, you have the following options:\\nRequest access to an Amazon Bedrock foundation model 9\\nAmazon Bedrock User Guide\\n• To request access to all models by a provider, select the checkbox next to the provider\\nname.\\n• To request access to one model, select the checkbox next to the model name.\\n8. For the purposes of the following tutorials, you should minimally request access to the\\nAmazon Titan Text G1 - Express and Amazon Titan Image Generator G1 V1 models. Then\\nchoose Next.\\n9. Review the models that you're requesting access to and the Terms. When you're ready, choose\\nSubmit to request access.\\n10. Access may take several minutes to complete. When access is granted to a model, the Access\\nstatus for that model willbecome Access granted.\\n\"}\n",
      "{'question': 'Which Meta Llama model supports both text and image input?', 'ground_truth': 'The Meta Llama 3.2 11B and 90B Instruct models support both text and image input.', 'question_type': 'simple', 'contexts': 'Provider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nCohere Rerank cohere.re us- Text Text No Link N/A\\n3.5 rank- west-2\\nv3-5:0\\nap-\\nnorthe\\nast-1\\nca-\\ncentra\\nl-1\\neu-\\ncentra\\nl-1\\nSupported foundation models 60\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3 8B a3-8b- east-1 Chat\\nInstruct ins\\nus-\\ntruct-\\nwest-2\\nv1:0\\nus-gov-\\nwest-1\\nap-\\nsouth-1\\nca-\\ncentra\\nl-1\\neu-\\nwest-2\\nSupported foundation models 61\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3 70B a3-70b- east-1 Chat\\nInstruct in\\nus-\\nstruct-\\nwest-2\\nv1:0\\nus-gov-\\nwest-1\\nap-\\nsouth-1\\nca-\\n centra\\nl-1\\neu-\\nwest-2\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 8B a3-1-8b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 70B a3-1-70b- east-1* Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2\\nSupported foundation models 62\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 a3-1-405b east-2* Chat\\n405B -\\nus-\\nInstruct instruct\\nwest-2\\n-v1:0\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.2 1B a3-2-1b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2*\\neu-\\ncentra\\nl-1*\\neu-\\nwest-1\\n(Gated)*\\neu-\\nwest-3*\\nSupported foundation models 63\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\n Meta Llama meta.llam us- Text Text, Yes Link N/A\\n3.2 3B a3-2-3b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2*\\neu-\\ncentra\\nl-1*\\neu-\\nwest-1\\n(Gated)*\\neu-\\nwest-3*\\nMeta Llama meta.llam us- Text, Text, Yes Link N/A\\n3.2 11B a3-2-11b- east-1* Image Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2*\\nSupported foundation models 64\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text, Text, Yes Link N/A\\n3.2 90B a3-2-90b- east-1* Image Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2*\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.3 70B a3-3-70b- east-1* Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2\\nus-\\nwest-2*\\nSupported foundation models 65\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\n'}\n",
      "{'question': 'What are the key differences between using the InvokeModel and Converse operations in Amazon Bedrock, and in what scenario might you prefer one over the other?', 'ground_truth': \"The key differences between InvokeModel and Converse operations in Amazon Bedrock are:\\n\\n1. Unification: Converse unifies the inference request across Amazon Bedrock models, while InvokeModel is model-specific.\\n2. Multi-turn conversations: Converse simplifies the management of multi-turn conversations, which is not mentioned for InvokeModel.\\n3. Input format: InvokeModel uses a 'body' parameter with JSON content, while Converse uses 'messages' and 'inference-config' parameters.\\n4. Recommendation: Amazon Bedrock recommends using Converse over InvokeModel when supported.\\n\\nYou might prefer Converse when:\\n1. Working with multiple models and wanting a consistent interface.\\n2. Managing multi-turn conversations.\\n3. Seeking a more streamlined approach to generating responses.\\n\\nInvokeModel might be preferred when:\\n1. Working with a specific model that doesn't support Converse.\\n2. Needing more fine-grained control over the input format for certain models.\\n3. Maintaining compatibility with existing systems that use the InvokeModel format.\", 'question_type': 'complex', 'contexts': 'Test that your permissions are set up properly for Amazon Bedrock, using a user or role that you set\\nup with the proper permissions.\\nTopics\\n• List the foundation models that Amazon Bedrock has to offer\\n• Submit a text prompt to a model and generate a text response with InvokeModel\\n• Submit a text prompt to a model and generate a text response with Converse\\nList the foundation models that Amazon Bedrock has to offer\\nThe following example runs the ListFoundationModels operation using an Amazon Bedrock\\nendpoint. ListFoundationModels lists the foundation models (FMs) that are available in\\nAmazon Bedrock in your region. In a terminal, run the following command:\\naws bedrock list-foundation-models --region us-east-1\\nIf the command is successful, the response returns a list of foundation models that are available in\\nAmazon Bedrock.\\nSubmit a text prompt to a model and generate a text response with InvokeModel\\nThe following example runs the InvokeModel operation using an Amazon Bedrock runtime\\n endpoint. InvokeModel lets you submit a prompt to generate a model response. In a terminal, run\\nthe following command:\\naws bedrock-runtime invoke-model \\\\\\n--model-id amazon.titan-text-express-v1 \\\\\\n--body \\'{\"inputText\": \"Describe the purpose of a \\\\\"hello world\\\\\" program in one line.\",\\n\"textGenerationConfig\" : {\"maxTokenCount\": 512, \"temperature\": 0.5, \"topP\": 0.9}}\\' \\\\\\n--cli-binary-format raw-in-base64-out \\\\\\ninvoke-model-output-text.txt\\nRun examples with the AWS CLI 19\\nAmazon Bedrock User Guide\\nIf the command is successful, the response generated by the model is written to the invoke-\\nmodel-output-text.txt file. The text response is returned in the outputText field, alongside\\naccompanying information.\\nSubmit a text prompt to a model and generate a text response with Converse\\nThe following example runs the Converse operation using an Amazon Bedrock runtime endpoint.\\nConverse lets you submit a prompt to generate a model response. We recommend using\\n Converse operation over InvokeModel when supported, because it unifies the inference request\\nacross Amazon Bedrock models and simplifies the management of multi-turn conversations. In a\\nterminal, run the following command:\\naws bedrock-runtime converse \\\\\\n--model-id amazon.titan-text-express-v1 \\\\\\n--messages \\'[{\"role\": \"user\", \"content\": [{\"text\": \"Describe the purpose of a \\\\\"hello\\nworld\\\\\" program in one line.\"}]}]\\' \\\\\\n--inference-config \\'{\"maxTokens\": 512, \"temperature\": 0.5, \"topP\": 0.9}\\'\\nIf the command is successful, the response generated by the model is returned in the text field,\\nalongside accompanying information.\\nRun example Amazon Bedrock API requests through the AWS SDK for\\nPython (Boto3)\\nThis section guides you through trying out some common operations in Amazon Bedrock with the\\nAWS Python to test that your permissions and authentication are set up properly. Before you run\\nthe following examples, you should check that you have fulfilled the following prerequisites:\\n'}\n",
      "{'question': 'What command lists the foundation models available in Amazon Bedrock?', 'ground_truth': 'The command to list foundation models available in Amazon Bedrock is: aws bedrock list-foundation-models --region us-east-1', 'question_type': 'simple', 'contexts': 'Test that your permissions are set up properly for Amazon Bedrock, using a user or role that you set\\nup with the proper permissions.\\nTopics\\n• List the foundation models that Amazon Bedrock has to offer\\n• Submit a text prompt to a model and generate a text response with InvokeModel\\n• Submit a text prompt to a model and generate a text response with Converse\\nList the foundation models that Amazon Bedrock has to offer\\nThe following example runs the ListFoundationModels operation using an Amazon Bedrock\\nendpoint. ListFoundationModels lists the foundation models (FMs) that are available in\\nAmazon Bedrock in your region. In a terminal, run the following command:\\naws bedrock list-foundation-models --region us-east-1\\nIf the command is successful, the response returns a list of foundation models that are available in\\nAmazon Bedrock.\\nSubmit a text prompt to a model and generate a text response with InvokeModel\\nThe following example runs the InvokeModel operation using an Amazon Bedrock runtime\\n endpoint. InvokeModel lets you submit a prompt to generate a model response. In a terminal, run\\nthe following command:\\naws bedrock-runtime invoke-model \\\\\\n--model-id amazon.titan-text-express-v1 \\\\\\n--body \\'{\"inputText\": \"Describe the purpose of a \\\\\"hello world\\\\\" program in one line.\",\\n\"textGenerationConfig\" : {\"maxTokenCount\": 512, \"temperature\": 0.5, \"topP\": 0.9}}\\' \\\\\\n--cli-binary-format raw-in-base64-out \\\\\\ninvoke-model-output-text.txt\\nRun examples with the AWS CLI 19\\nAmazon Bedrock User Guide\\nIf the command is successful, the response generated by the model is written to the invoke-\\nmodel-output-text.txt file. The text response is returned in the outputText field, alongside\\naccompanying information.\\nSubmit a text prompt to a model and generate a text response with Converse\\nThe following example runs the Converse operation using an Amazon Bedrock runtime endpoint.\\nConverse lets you submit a prompt to generate a model response. We recommend using\\n Converse operation over InvokeModel when supported, because it unifies the inference request\\nacross Amazon Bedrock models and simplifies the management of multi-turn conversations. In a\\nterminal, run the following command:\\naws bedrock-runtime converse \\\\\\n--model-id amazon.titan-text-express-v1 \\\\\\n--messages \\'[{\"role\": \"user\", \"content\": [{\"text\": \"Describe the purpose of a \\\\\"hello\\nworld\\\\\" program in one line.\"}]}]\\' \\\\\\n--inference-config \\'{\"maxTokens\": 512, \"temperature\": 0.5, \"topP\": 0.9}\\'\\nIf the command is successful, the response generated by the model is returned in the text field,\\nalongside accompanying information.\\nRun example Amazon Bedrock API requests through the AWS SDK for\\nPython (Boto3)\\nThis section guides you through trying out some common operations in Amazon Bedrock with the\\nAWS Python to test that your permissions and authentication are set up properly. Before you run\\nthe following examples, you should check that you have fulfilled the following prerequisites:\\n'}\n",
      "{'question': 'How do the capabilities and regional availability of Claude 3 Opus compare to Claude 3.5 Sonnet, and what implications might this have for developers choosing between these models?', 'ground_truth': 'Claude 3 Opus and Claude 3.5 Sonnet have some key differences in capabilities and regional availability. Claude 3 Opus is available in fewer regions (only us-east-1 and us-west-2) compared to Claude 3.5 Sonnet, which is available in multiple regions across the Americas, Europe, and Asia Pacific. Both models support text and image input, and text chat output with streaming inference. However, Claude 3.5 Sonnet has two versions (v1 and v2) while Opus has only one. This suggests that Sonnet might be more actively updated. The wider availability of Sonnet could make it more suitable for global applications or those requiring lower latency in specific regions. Developers might choose Opus for potentially more advanced capabilities in supported regions, while Sonnet offers broader geographical flexibility and possibly more frequent updates. The choice would depend on the specific requirements of the application, such as performance needs, data residency requirements, and target user locations.', 'question_type': 'complex', 'contexts': 'l-1\\nAnthropic Claude anthropic us- Text Text, Yes Link N/A\\n2 .claude- east-1 Chat\\nv2\\nus-\\nwest-2\\nap-\\nsouthe\\nast-1\\n(Gated)\\neu-\\ncentra\\nl-1\\nSupported foundation models 48\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n3 Haiku .claude-3 east-1 Image Chat\\n-\\nus-\\nhaiku-20\\neast-2*\\n240307-\\nv1:0\\nus-\\nwest-2\\nus-gov-\\neast-1*\\nus-gov-\\nwest-1\\nap-\\nnorthe\\nast-1\\nap-\\nnorthe\\nast-2\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-1\\n(Gated)\\nap-\\nsouthe\\nast-1\\n(Gated)\\nSupported foundation models 49\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\ncentra\\nl-1\\neu-\\ncentra\\nl-2\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n 3 Opus .claude-3 east-1* Image Chat\\n-\\nus-\\nopus-202\\nwest-2\\n40229-\\nv1:0\\nSupported foundation models 50\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n3 .claude-3 east-1 Image Chat\\nSonnet -\\nus-\\nsonnet-2\\nwest-2\\n0240229-\\nv1:0\\nap-\\nnorthe\\nast-1*\\nap-\\nnorthe\\nast-2*\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-1\\n(Gated)*\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\ncentra\\nl-1\\nSupported foundation models 51\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n3.5 .claude-3 east-1* Image Chat\\nHaiku -5-\\nus-\\nhaiku-\\neast-2*\\n20241022-\\nv1:0\\nus-\\nwest-2\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n 3.5 .claude-3 east-1* Image Chat\\nSonnet -5-\\nus-\\nv2 sonnet\\nwest-2\\n-20241022\\n-v2:0\\nSupported foundation models 52\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n3.5 .claude-3 east-1 Image Chat\\nSonnet -5-\\nus-\\nsonnet\\neast-2*\\n-20240620\\n-v1:0\\nus-\\nwest-2\\nus-gov-\\neast-1*\\nus-gov-\\nwest-1\\nap-\\nnorthe\\nast-1\\nap-\\nnorthe\\nast-2\\nap-\\nsouth-\\n1*\\nap-\\nsouthe\\nast-1\\n(Gated)\\nap-\\nsouthe\\nSupported foundation models 53\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nast-1\\n(Gated)\\nap-\\nsouthe\\nast-2*\\neu-\\ncentra\\nl-1\\neu-\\ncentra\\nl-2\\neu-\\nwest-1\\n(Gated)*\\neu-\\nwest-3*\\nSupported foundation models 54\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\n'}\n",
      "{'question': 'How do AWS GovCloud (US) customers enable model access for Amazon Bedrock?', 'ground_truth': 'AWS GovCloud (US) customers first use their standard AWS account ID to enable model access in the Amazon Bedrock console in us-east-1 or us-west-2. Then, they log into their AWS GovCloud (US) account and follow the same model access sign-up steps in us-gov-west-1 to gain regional entitlement for accessing models in that region.', 'question_type': 'simple', 'contexts': \"• AWS GovCloud (US) customers use their standard AWS account ID (which is linked to\\ntheir AWS GovCloud (US) account ID) to first enable model access. Navigate to the model\\naccess page on Amazon Bedrock console in either us-east-1 or us-west-2. Select the\\nmodel(s) that you want to enable. Select Request model access and follow the step-by-\\nstep subscription flow.\\n• Log into your AWS GovCloud (US) account and navigate to Amazon Bedrock in us-gov-\\nwest-1 and follow the same model access sign-up steps. This will grant you a regional\\nentitlement to access the models in us-gov-west-1.\\n• The model will be accessible to the linked AWS GovCloud (US) account on us-gov-\\nwest-1.\\nIf you don't have permissions to request access to a model, an error banner appears. Contact\\nyour account administrator to ask them to request access to the model for you or to provide you\\npermissions to request access to the model.\\nAdd or remove access to foundation models 34\\nAmazon Bedrock User Guide\\n Amazon Bedrock foundation model information\\nA foundation model is an Artificial Intellgence model with a large number of parameters and\\ntrained on a massive amount of diverse data. A foundation model can generate a variety of\\nresponses for a wide range of use cases. Foundation models can generate text or image, and can\\nalso convert input into embeddings. This section provides information about the foundation models\\n(FM) that you can use in Amazon Bedrock, such as the features that models support and the AWS\\nregions in which models are available. For information about the foundation models that Amazon\\nBedrock supports, see Supported foundation models in Amazon Bedrock.\\nYou must request access to a model before you can use it. After doing so, you can then use FMs in\\nthe following ways.\\n• Run inference by sending prompts to a model and generating responses. The playgrounds offer\\na user-friendly interface in the AWS Management Console for generating text, images, or chats.\\n See the Output modality column to determine the models you can use in each playground.\\nNote\\nThe console playgrounds don't support running inference on embeddings models. Use\\nthe API to run inference on embeddings models.\\n• Evaluate models to compare outputs and determine the best model for your use-case.\\n• Set up a knowledge base with the help of an embeddings model. Then use a text model to\\ngenerate responses to queries.\\n• Create an agent and use a model to run inference on prompts to carry out orchestration.\\n• Customize a model by feeding training and validation data to adjust model parameters for your\\nuse-case. To use a customized model, you must purchase Provisioned Throughput for it.\\n• Purchase Provisioned Throughput for a model to increase throughput for it.\\nTo use an FM with the Amazon Bedrock API, you need to determine the appropriate model ID to\\nuse. Refer to the following table to determine where to find the model ID that you need to use.\\nUse case How to find the model ID\\n\"}\n",
      "{'question': \"How does Amazon Bedrock's pricing model work, and what factors should a developer consider when estimating costs for a project that involves heavy use of foundation models?\", 'ground_truth': \"Amazon Bedrock's pricing model is based on the volume of input and output tokens processed during model inference. Developers should consider several factors when estimating costs:\\n\\n1. Model selection: Different foundation models have varying pricing structures.\\n2. Input/output volume: Costs are directly related to the amount of data processed.\\n3. Provisioned Throughput: Purchasing this can affect pricing and is beneficial for high-volume use cases.\\n4. Use case complexity: More complex prompts or tasks may require more tokens, increasing costs.\\n5. Model access: Some models require requesting access before use.\\n\\nTo estimate costs accurately, developers should:\\n- Review the specific pricing for each model on the Model providers page in the Amazon Bedrock console.\\n- Consider the potential benefits of Provisioned Throughput for high-volume applications.\\n- Monitor usage through the AWS Billing and Cost Management console.\\n- Factor in the possibility of costs changing as they only pay for services used.\\n\\nBy carefully considering these aspects, developers can better predict and optimize their Amazon Bedrock expenses for projects involving extensive use of foundation models.\", 'question_type': 'complex', 'contexts': \"How do I get started with Amazon Bedrock? 2\\nAmazon Bedrock User Guide\\n4. Read the documentation for the features that you want to include in your application.\\nAmazon Bedrock pricing\\nWhen you sign up for AWS, your AWS account is automatically signed up for all services in AWS,\\nincluding Amazon Bedrock. However, you are charged only for the services that you use.\\nFor information about pricing for different Amazon Bedrock resources, see Amazon Bedrock\\nPricing.\\nTo see your bill, go to the Billing and Cost Management Dashboard in the AWS Billing and Cost\\nManagement console. To learn more about AWS account billing, see the AWS Billing User Guide. If\\nyou have questions concerning AWS billing and AWS accounts, contact AWS Support.\\nWith Amazon Bedrock, you pay to run inference on any of the third-party foundation models.\\nPricing is based on the volume of input tokens and output tokens, and on whether you have\\n purchased Provisioned Throughput for the model. For more information, see the Model providers\\npage in the Amazon Bedrock console. For each model, pricing is listed following the model version.\\nFor more information about purchasing Provisioned Throughput, see Increase model invocation\\ncapacity with Provisioned Throughput in Amazon Bedrock.\\nKey terminology\\nThis chapter explains terminology that will help you understand what Amazon Bedrock offers\\nand how it works. Read through the following list to understand generative AI terminology and\\nAmazon Bedrock's fundamental capabilities:\\n• Foundation model (FM) – An AI model with a large number of parameters and trained on a\\nmassive amount of diverse data. A foundation model can generate a variety of responses for a\\nwide range of use cases. Foundation models can generate text or image, and can also convert\\ninput into embeddings. Before you can use an Amazon Bedrock foundation model, you must\\n request access. For more information about foundation models, see Supported foundation\\nmodels in Amazon Bedrock.\\n• Base model – A foundation model that is packaged by a provider and ready to use. Amazon\\nBedrock offers a variety of industry-leading foundation models from leading providers. For more\\ninformation, see Supported foundation models in Amazon Bedrock.\\nAmazon Bedrock pricing 3\\nAmazon Bedrock User Guide\\n• Model inference – The process of a foundation model generating an output (response) from a\\ngiven input (prompt). For more information, see Submit prompts and generate responses with\\nmodel inference.\\n• Prompt – An input provided to a model to guide it to generate an appropriate response or\\noutput for the input. For example, a text prompt can consist of a single line for the model\\nto respond to, or it can detail instructions or a task for the model to perform. The prompt\\ncan contain the context of the task, examples of outputs, or text for a model to use in its\\n\"}\n",
      "{'question': 'Which AI model is available in the most AWS regions?', 'ground_truth': 'Based on the information provided, Claude 3 Sonnet by Anthropic appears to be available in the most AWS regions, with \"Yes\" or \"Yes*\" entries for many regions including US East, US West, various parts of Europe, Asia, and South America.', 'question_type': 'simple', 'contexts': 'ModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAmazon\\nYes No Yes No No No No Yes No Yes Yes Yes No GatedYes Yes Yes\\nTitan\\nText\\nG1\\n-\\nLite\\nAmazon\\nYes No No No No No No No No No No No No No No No No\\nTitan\\nText\\nG1\\n-\\nPremier\\nAnthropic\\nYes No Yes No No Yes No No No No No Yes No No No No No\\nClaude\\n2.1\\nAnthropic\\nYes No Yes No No No No No GatedNo No Yes No No No No No\\nClaude\\n2\\nAnthropic\\nYes Yes* Yes Yes* Yes Yes Yes Yes GatedYes Yes Yes Yes GatedYes Yes Yes\\nClaude\\n3\\nHaiku\\nAnthropic\\nYes* No Yes No No No No No No No No No No No No No No\\nClaude\\n3\\nOpus\\nModel support by Region 74\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAnthropic\\nYes No Yes No No Yes* Yes* Yes GatedYes Yes Yes No GatedYes Yes Yes\\nClaude\\n3\\nSonnet\\nAnthropic\\nYes* Yes* Yes No No No No No No No No No No No No No No\\nClaude\\n3.5\\nHaiku\\nAnthropic\\nYes* No Yes No No No No No No No No No No No No No No\\nClaude\\n3.5\\nSonnet\\nv2\\nAnthropic\\nYes Yes* Yes Yes* Yes Yes Yes Yes* GatedYes* No Yes Yes GatedNo Yes* No\\nClaude\\n3.5\\nSonnet\\nAnthropic\\nYes No Yes No No Yes No No GatedNo No Yes No No No No No\\nClaude\\nInstant\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nLight\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nR+\\nModel support by Region 75\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nR\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nEnglish\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nMultiling\\nual\\nCohere\\nNo No Yes No No Yes No No No No Yes Yes No No No No No\\nRerank\\n3.5\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n8B\\nInstruct\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n70B\\nInstruct\\nModel support by Region 76\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n'}\n",
      "{'question': \"How does the availability of AI21 Labs models compare to Stability AI's SDXL 1.0 model across AWS regions, and what implications might this have for developers choosing between these options?\", 'ground_truth': \"AI21 Labs models (J2 Grande Instruct, J2 Jumbo Instruct, Jurassic-2 Mid, and Jurassic-2 Ultra) are only available in the US East (N. Virginia) region, while Stability AI's SDXL 1.0 model is available in both US East (N. Virginia) and US West (Oregon) regions. This limited availability of AI21 Labs models compared to SDXL 1.0 may impact developers' choices, as those requiring multi-region deployment or specific to the US West region would find SDXL 1.0 more suitable. However, developers focused on the US East region have access to a wider variety of AI21 Labs models, potentially offering more specialized options for their applications.\", 'question_type': 'complex', 'contexts': 'No No Yes No No No No No No No No No No No No No No\\nAI\\nStable\\nImage\\nUltra\\n1.0\\nStability\\nNo No Yes No No No No No No No No No No No No No No\\nAI\\nStable\\nImage\\nUltra\\n1.0\\nModel support by Region 80\\nAmazon Bedrock User Guide\\nNote\\n* Some models are accessible in some Regions only through cross-region inference. To learn\\nmore about cross-region inference, see Increase throughput with cross-region inference and\\nSupported Regions and models for inference profiles.\\nThe following table shows Region support for models that have a target date for deprecation. For\\nmore information, see Model lifecycle.\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJ2\\n Grande\\nInstruct\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJ2\\nJumbo\\nInstruct\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJurassic-\\n2\\nMid\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJurassic-\\nModel support by Region 81\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\n2\\nUltra\\nStability\\nYes No Yes No No No No No No No No No No No No No No\\nAI\\nSDXL\\n1.0\\nTo learn more about Region and model support for specific features, see the following links:\\n• Converse API\\n• Batch inference\\n• Inference profiles\\n• Latency optimization\\n• Prompt management\\n• Prompt management\\n• Prompt optimization\\n• Amazon Bedrock Guardrails\\n• Model evaluation\\n • RAG evaluation\\n• Amazon Bedrock Knowledge Bases\\n• Rerank\\n• Amazon Bedrock Agents\\n• Amazon Bedrock Flows\\n• Model customization\\n• Amazon Bedrock Custom Model Import\\n• Provisioned Throughput\\n• Amazon Bedrock Studio\\nModel support by Region 82'}\n",
      "{'question': 'How can you send a text message to Amazon Titan Text G1 - Express?', 'ground_truth': 'You can send a text message to Amazon Titan Text G1 - Express using the Conversation API with Amazon Bedrock Runtime client.', 'question_type': 'simple', 'contexts': '# Use the Conversation API to send a text message to Amazon Titan Text G1 - Express.\\nimport boto3\\nfrom botocore.exceptions import ClientError\\n# Create an Amazon Bedrock Runtime client.\\nbrt = boto3.client(\"bedrock-runtime\")\\n# Set the model ID, e.g., Amazon Titan Text G1 - Express.\\nmodel_id = \"amazon.titan-text-express-v1\"\\n# Start a conversation with the user message.\\nuser_message = \"Describe the purpose of a \\'hello world\\' program in one line.\"\\nconversation = [\\n{\\n\"role\": \"user\",\\n\"content\": [{\"text\": user_message}],\\n}\\n]\\ntry:\\n# Send the message to the model, using a basic inference configuration.\\nresponse = brt.converse(\\nmodelId=model_id,\\nmessages=conversation,\\ninferenceConfig={\"maxTokens\": 512, \"temperature\": 0.5, \"topP\": 0.9},\\n)\\n# Extract and print the response text.\\nRun examples with a SageMaker AI notebook 26\\nAmazon Bedrock User Guide\\nresponse_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\\nprint(response_text)\\nexcept (ClientError, Exception) as e:\\n print(f\"ERROR: Can\\'t invoke \\'{model_id}\\'. Reason: {e}\")\\nexit(1)\\nIf the command is successful, the response returns the text generated by the model in response to\\nthe prompt.\\nUsing Amazon Bedrock with an AWS SDK\\nAWS software development kits (SDKs) are available for many popular programming languages.\\nEach SDK provides an API, code examples, and documentation that make it easier for developers to\\nbuild applications in their preferred language.\\nSDK documentation Code examples\\nAWS SDK for C++ AWS SDK for C++ code examples\\nAWS CLI AWS CLI code examples\\nAWS SDK for Go AWS SDK for Go code examples\\nAWS SDK for Java AWS SDK for Java code examples\\nAWS SDK for JavaScript AWS SDK for JavaScript code examples\\nAWS SDK for Kotlin AWS SDK for Kotlin code examples\\nAWS SDK for .NET AWS SDK for .NET code examples\\nAWS SDK for PHP AWS SDK for PHP code examples\\nAWS Tools for PowerShell Tools for PowerShell code examples\\nAWS SDK for Python (Boto3) AWS SDK for Python (Boto3) code examples\\n AWS SDK for Ruby AWS SDK for Ruby code examples\\nAWS SDK for Rust AWS SDK for Rust code examples\\nWorking with AWS SDKs 27\\nAmazon Bedrock User Guide\\nSDK documentation Code examples\\nAWS SDK for SAP ABAP AWS SDK for SAP ABAP code examples\\nAWS SDK for Swift AWS SDK for Swift code examples\\nExample availability\\nCan\\'t find what you need? Request a code example by using the Provide feedback link at\\nthe bottom of this page.\\nWorking with AWS SDKs 28\\nAmazon Bedrock User Guide\\nAccess Amazon Bedrock foundation models\\nAccess to Amazon Bedrock foundation models isn\\'t granted by default. You can request access, or\\nmodify access, to foundation models only by using the Amazon Bedrock console.\\nNote\\nIf you\\'re new to Amazon Bedrock and this is your first time requesting model access, follow\\nthe steps at Getting started with Amazon Bedrock instead.\\nTo request or modify access, first, make sure the IAM role that you use has sufficent IAM\\n'}\n",
      "{'question': \"How might Amazon Bedrock's features enable a company to develop a more efficient and cost-effective AI-powered customer service chatbot compared to building one from scratch?\", 'ground_truth': \"Amazon Bedrock offers several features that can help a company develop an efficient and cost-effective AI-powered customer service chatbot:\\n\\n1. Access to pre-trained foundation models: Companies can experiment with various high-performing models through a unified API, saving time and resources on model development.\\n\\n2. Retrieval Augmented Generation (RAG): By creating knowledge bases with company-specific data, the chatbot can provide more accurate and contextual responses without extensive custom training.\\n\\n3. Agent capabilities: Bedrock allows building agents that can reason through tasks and make API calls, enabling the chatbot to perform complex actions and integrate with existing systems.\\n\\n4. Fine-tuning and customization: Companies can adapt models to their specific domain and tasks, improving performance without starting from scratch.\\n\\n5. Provisioned Throughput: This feature allows for more efficient and cost-effective inference, particularly beneficial for high-volume customer service operations.\\n\\n6. Model evaluation tools: Companies can determine the best model for their use case, ensuring optimal performance.\\n\\n7. Guardrails: These help prevent inappropriate content, crucial for maintaining a professional customer service interaction.\\n\\n8. Serverless experience: This reduces infrastructure management overhead, allowing the company to focus on improving the chatbot's functionality.\\n\\nBy leveraging these features, a company can quickly develop a sophisticated, customized, and scalable customer service chatbot while minimizing development time, costs, and infrastructure management compared to building one from scratch.\", 'question_type': 'complex', 'contexts': \"Amazon Bedrock User Guide\\nWhat is Amazon Bedrock?\\nAmazon Bedrock is a fully managed service that makes high-performing foundation models (FMs)\\nfrom leading AI companies and Amazon available for your use through a unified API. You can\\nchoose from a wide range of foundation models to find the model that is best suited for your use\\ncase. Amazon Bedrock also offers a broad set of capabilities to build generative AI applications with\\nsecurity, privacy, and responsible AI. Using Amazon Bedrock, you can easily experiment with and\\nevaluate top foundation models for your use cases, privately customize them with your data using\\ntechniques such as fine-tuning and Retrieval Augmented Generation (RAG), and build agents that\\nexecute tasks using your enterprise systems and data sources.\\nWith Amazon Bedrock's serverless experience, you can get started quickly, privately customize\\nfoundation models with your own data, and easily and securely integrate and deploy them into\\n your applications using AWS tools without having to manage any infrastructure.\\nTopics\\n• What can I do with Amazon Bedrock?\\n• How do I get started with Amazon Bedrock?\\n• Amazon Bedrock pricing\\n• Key terminology\\nWhat can I do with Amazon Bedrock?\\nYou can use Amazon Bedrock to do the following:\\n• Experiment with prompts and configurations – Submit prompts and generate responses with\\nmodel inference by sending prompts using different configurations and foundation models to\\ngenerate responses. You can use the API or the text, image, and chat playgrounds in the console\\nto experiment in a graphical interface. When you're ready, set up your application to make\\nrequests to the InvokeModel APIs.\\n• Augment response generation with information from your data sources – Create knowledge\\nbases by uploading data sources to be queried in order to augment a foundation model's\\ngeneration of responses.\\nWhat can I do with Amazon Bedrock? 1\\nAmazon Bedrock User Guide\\n • Create applications that reason through how to help a customer – Build agents that use\\nfoundation models, make API calls, and (optionally) query knowledge bases in order to reason\\nthrough and carry out tasks for your customers.\\n• Adapt models to specific tasks and domains with training data – Customize an Amazon\\nBedrock foundation model by providing training data for fine-tuning or continued-pretraining in\\norder to adjust a model's parameters and improve its performance on specific tasks or in certain\\ndomains.\\n• Improve your FM-based application's efficiency and output – Purchase Provisioned Throughput\\nfor a foundation model in order to run inference on models more efficiently and at discounted\\nrates.\\n• Determine the best model for your use case – Evaluate outputs of different models with built-in\\nor custom prompt datasets to determine the model that is best suited for your application.\\n• Prevent inappropriate or unwanted content – Use guardrails to implement safeguards for your\\n\"}\n",
      "{'question': 'How can users access an IAM role for Amazon Bedrock?', 'ground_truth': 'Users can be added to the Amazon Bedrock role. To grant users permissions to switch to the role, follow the steps in \"Granting a user permissions to switch roles\" and specify the Amazon Bedrock role as the Resource.', 'question_type': 'simple', 'contexts': 'Configure user access with the default IAM Identity Center directory in the AWS IAM Identity\\nCenter User Guide.\\nSign in as the user with administrative access\\n• To sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email\\naddress when you created the IAM Identity Center user.\\nFor help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in\\nthe AWS Sign-In User Guide.\\nTo learn more about IAM, see Identity and access management for Amazon Bedrock and the IAM\\nUser Guide.\\nAfter you have created an administrative user, proceed to I already have an AWS account to set up\\npermissions for Amazon Bedrock.\\nI already have an AWS account\\nUse IAM to create a role for with the necessary permissions to use Amazon Bedrock. You can then\\nadd users to this role to grant the permissions.\\nI already have an AWS account 7\\nAmazon Bedrock User Guide\\nTo create an Amazon Bedrock role\\n 1. Create a role with a name of your choice by following the steps at Creating a role to delegate\\npermissions to an IAM user in the IAM User Guide. When you reach the step to attach a policy\\nto the role, attach the AmazonBedrockFullAccess AWS managed policy.\\n2. Create a new policy to allow your role to manage access to Amazon Bedrock models. From the\\nfollowing list, select the link that corresponds to your method of choice and follow the steps.\\nUse the following JSON object as the policy.\\n• Creating IAM policies (console)\\n• Creating IAM policies (AWS CLI)\\n• Creating IAM policies (AWS API)\\n{\\n\"Version\": \"2012-10-17\",\\n\"Statement\": [\\n{\\n\"Sid\": \"MarketplaceBedrock\",\\n\"Effect\": \"Allow\",\\n\"Action\": [\\n\"aws-marketplace:ViewSubscriptions\",\\n\"aws-marketplace:Unsubscribe\",\\n\"aws-marketplace:Subscribe\"\\n],\\n\"Resource\": \"*\"\\n}\\n]\\n}\\n3. Attach the policy that you created in the last step to your Amazon Bedrock role by following\\nthe steps at Adding and removing IAM identity permissions.\\n To add users to the Amazon Bedrock role\\n1. For users to access an IAM role, you must add them to the role. You can add both users in your\\naccount or from other accounts. To grant users permissions to switch to the Amazon Bedrock\\nrole that you created, follow the steps at Granting a user permissions to switch roles and\\nspecify the Amazon Bedrock role as the Resource.\\nI already have an AWS account 8\\nAmazon Bedrock User Guide\\nNote\\nIf you need to create more users in your account so that you can give them access\\nto the Amazon Bedrock role, follow the steps in Creating an IAM user in your AWS\\naccount.\\n2. After you\\'ve granted a user permissions to use the Amazon Bedrock role, provide the user\\nwith role name and ID or alias of the account to which the role belongs. Then, guide the user\\nthrough how to switch to the role by following the instructions at Providing information to the\\nuser.\\nRequest access to an Amazon Bedrock foundation model\\n'}\n",
      "{'question': 'How can a developer efficiently retrieve information about multiple Amazon Bedrock foundation models, including their support for Provisioned Throughput, and what are the key differences in using custom models versus base models?', 'ground_truth': 'To efficiently retrieve information about multiple Amazon Bedrock foundation models, a developer can use the ListFoundationModels API request, which returns FoundationModelSummary objects containing details such as ARNs, model IDs, supported modalities, features, and deprecation status. For specific model information, they can use the GetFoundationModel request with a particular model ID.\\n\\nKey differences in using custom models versus base models include:\\n\\n1. Model ID lookup: Base model IDs are found in the base model IDs chart, while custom models use their name or ARN as the model ID.\\n\\n2. Provisioned Throughput: For base models, look up the ID in the model IDs for Provisioned Throughput chart and use it in the CreateProvisionedModelThroughput request. For custom models, use the model name or ARN directly in the request.\\n\\n3. Usage after Provisioned Throughput: Both types return a provisionedModelArn, which becomes the model ID for subsequent use.\\n\\n4. Flexibility: Custom models may offer more tailored functionality but might require additional steps, such as purchasing Provisioned Throughput before use.\\n\\nDevelopers should note that the ListFoundationModels response may include deprecated or backwards-compatible model IDs not found in the standard charts, requiring careful consideration when selecting models for implementation.', 'question_type': 'complex', 'contexts': \"Use a base model Look up the ID in the base model IDs chart\\n35\\nAmazon Bedrock User Guide\\nUse case How to find the model ID\\nPurchase Provisioned Throughput for a base Look up the ID in the model IDs for Provision\\nmodel ed Throughput chart and use it as the\\nmodelId in the CreateProvisionedModelThrou\\nghput request.\\nPurchase Provisioned Throughput for a Use the name of the custom model or its ARN\\ncustom model as the modelId in the CreateProvisionedM\\nodelThroughput request.\\nUse a provisioned model After you create a Provisioned Throughput,\\nit returns a provisionedModelArn . This\\nARN is the model ID.\\nUse a custom model Purchase Provisioned Throughput for\\nthe custom model and use the returned\\nprovisionedModelArn as the model ID.\\nFor example code, see the documentation for the feature you are using and also Code examples for\\nAmazon Bedrock using AWS SDKs.\\nTopics\\n• Get information about foundation models\\n• Supported foundation models in Amazon Bedrock\\n • Model support by AWS Region in Amazon Bedrock\\n• Feature support by AWS Region in Amazon Bedrock\\n• Model support by feature\\n• Inference request parameters and response fields for foundation models\\n• Custom model hyperparameters\\n• Model lifecycle\\n36\\nAmazon Bedrock User Guide\\nGet information about foundation models\\nIn the Amazon Bedrock console, you can find overarching information about Amazon Bedrock\\nfoundation model providers and the models they provide in the Providers and Base models\\nsections.\\nUse the API to retrieve information about Amazon Bedrock foundation model, including its\\nARN, model ID, modalities and features it supports, and whether it is deprecated or not, in a\\nFoundationModelSummary object.\\n• To return information about all the foundation models that Amazon Bedrock provides, send a\\nListFoundationModels request.\\nNote\\nThe response also returns model IDs that aren't in the base model ID or base model IDs\\n for Provisioned Throughput charts. These model IDs are deprecated or for backwards\\ncompability.\\n• To return information about a specific foundation model, send a GetFoundationModel request,\\nspecifying the model ID.\\nChoose a tab to see code examples in an interface or language.\\nAWS CLI\\nList the Amazon Bedrock foundation models.\\naws bedrock list-foundation-models\\nGet information about Anthropic Claude v2.\\naws bedrock get-foundation-model --model-identifier anthropic.claude-v2\\nPython\\nList the Amazon Bedrock foundation models.\\nimport boto3\\nbedrock = boto3.client(service_name='bedrock')\\nGet model information 37\\nAmazon Bedrock User Guide\\nbedrock.list_foundation_models()\\nGet information about Anthropic Claude v2.\\nimport boto3\\nbedrock = boto3.client(service_name='bedrock')\\nbedrock.get_foundation_model(modelIdentifier='anthropic.claude-v2')\\nSupported foundation models in Amazon Bedrock\\nAmazon Bedrock supports foundation models (FMs) from multiple providers.\\n\"}\n",
      "{'question': 'What are the two main prerequisites for running Amazon Bedrock examples?', 'ground_truth': 'The two main prerequisites are having an AWS account with necessary permissions for Amazon Bedrock, and requesting access to the Amazon Titan Text G1 - Express model.', 'question_type': 'simple', 'contexts': 'up properly. Before you run the following examples, you should check that you have fulfilled the\\nfollowing prerequisites:\\nPrerequisites\\n• You have an AWS account and have permissions to access a role with the necessary permissions\\nfor Amazon Bedrock. Otherwise, follow the steps at I already have an AWS account.\\n• You\\'ve requested access to the Amazon Titan Text G1 - Express model. Otherwise, follow the\\nsteps at Request access to an Amazon Bedrock foundation model.\\n• Carry out the following steps to set up IAM permissions for SageMaker AI and create a notebook:\\n1. Modify the trust policy of the Amazon Bedrock role that you set up in I already have an AWS\\naccount through the console, CLI, or API. Attach the following trust policy to the role to\\nallow both the Amazon Bedrock and SageMaker AI services to assume the Amazon Bedrock\\nrole:\\n{\\n\"Version\": \"2012-10-17\",\\n\"Statement\": [\\n{\\n\"Sid\": \"BedrockTrust\",\\n\"Effect\": \"Allow\",\\n\"Principal\": {\\n\"Service\": \"bedrock.amazonaws.com\"\\n},\\n Run examples with a SageMaker AI notebook 24\\nAmazon Bedrock User Guide\\n\"Action\": \"sts:AssumeRole\"\\n},\\n{\\n\"Sid\": \"SagemakerTrust\",\\n\"Effect\": \"Allow\",\\n\"Principal\": {\\n\"Service\": \"sagemaker.amazonaws.com\"\\n},\\n\"Action\": \"sts:AssumeRole\"\\n}\\n]\\n}\\n2. Sign into the Amazon Bedrock role whose trust policy you just modified.\\n3. Follow the steps at Create an Amazon SageMaker AI Notebook Instance for the tutorial and\\nspecify the ARN of the Amazon Bedrock role that you created to create an SageMaker AI\\nnotebook instance.\\n4. When the Status of the notebook instance is InService, choose the instance and then choose\\nOpen JupyterLab.\\nAfter you open up your SageMaker AI notebook, you can try out the following examples:\\nTopics\\n• List the foundation models that Amazon Bedrock has to offer\\n• Submit a text prompt to a model and generate a response\\nList the foundation models that Amazon Bedrock has to offer\\nThe following example runs the ListFoundationModels operation using an Amazon Bedrock client.\\n ListFoundationModels lists the foundation models (FMs) that are available in Amazon Bedrock\\nin your region. Run the following SDK for Python script to create an Amazon Bedrock client and\\ntest the ListFoundationModels operation:\\n# Use the ListFoundationModels API to show the models that are available in your\\nregion.\\nimport boto3\\n# Create an &BR; client in the &region-us-east-1; Region.\\nbedrock = boto3.client(\\nRun examples with a SageMaker AI notebook 25\\nAmazon Bedrock User Guide\\nservice_name=\"bedrock\"\\n)\\nbedrock.list_foundation_models()\\nIf the script is successful, the response returns a list of foundation models that are available in\\nAmazon Bedrock.\\nSubmit a text prompt to a model and generate a response\\nThe following example runs the Converse operation using an Amazon Bedrock client. Converse\\nlets you submit a prompt to generate a model response. Run the following SDK for Python script to\\ncreate an Amazon Bedrock runtime client and test the Converse operation:\\n'}\n",
      "{'question': 'Which AI model has the most widespread availability across different AWS regions, and what unique pattern does its availability follow compared to other models?', 'ground_truth': 'The AI model with the most widespread availability across different AWS regions is Anthropic\\'s Claude 3 Sonnet. It has a unique availability pattern compared to other models, being available in 11 out of the 17 listed regions. What makes its pattern distinct is that it\\'s the only model available in some regions where others aren\\'t, such as AWS GovCloud (US-West), and it has \"Gated\" access in regions like Asia Pacific (Mumbai) and Europe (Frankfurt). Additionally, it\\'s marked with asterisks (*) in several regions, indicating potential limitations or special conditions for its use in those areas.', 'question_type': 'complex', 'contexts': 'ModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAmazon\\nYes No Yes No No No No Yes No Yes Yes Yes No GatedYes Yes Yes\\nTitan\\nText\\nG1\\n-\\nLite\\nAmazon\\nYes No No No No No No No No No No No No No No No No\\nTitan\\nText\\nG1\\n-\\nPremier\\nAnthropic\\nYes No Yes No No Yes No No No No No Yes No No No No No\\nClaude\\n2.1\\nAnthropic\\nYes No Yes No No No No No GatedNo No Yes No No No No No\\nClaude\\n2\\nAnthropic\\nYes Yes* Yes Yes* Yes Yes Yes Yes GatedYes Yes Yes Yes GatedYes Yes Yes\\nClaude\\n3\\nHaiku\\nAnthropic\\nYes* No Yes No No No No No No No No No No No No No No\\nClaude\\n3\\nOpus\\nModel support by Region 74\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAnthropic\\nYes No Yes No No Yes* Yes* Yes GatedYes Yes Yes No GatedYes Yes Yes\\nClaude\\n3\\nSonnet\\nAnthropic\\nYes* Yes* Yes No No No No No No No No No No No No No No\\nClaude\\n3.5\\nHaiku\\nAnthropic\\nYes* No Yes No No No No No No No No No No No No No No\\nClaude\\n3.5\\nSonnet\\nv2\\nAnthropic\\nYes Yes* Yes Yes* Yes Yes Yes Yes* GatedYes* No Yes Yes GatedNo Yes* No\\nClaude\\n3.5\\nSonnet\\nAnthropic\\nYes No Yes No No Yes No No GatedNo No Yes No No No No No\\nClaude\\nInstant\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nLight\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nR+\\nModel support by Region 75\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nR\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nEnglish\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nMultiling\\nual\\nCohere\\nNo No Yes No No Yes No No No No Yes Yes No No No No No\\nRerank\\n3.5\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n8B\\nInstruct\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n70B\\nInstruct\\nModel support by Region 76\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n'}\n",
      "{'question': 'Which Llama 3.2 model supports both text and image input?', 'ground_truth': 'The Llama 3.2 11B and 90B models support both text and image input modalities.', 'question_type': 'simple', 'contexts': 'centra\\nl-1\\neu-\\nwest-2\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 8B a3-1-8b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 70B a3-1-70b- east-1* Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2\\nSupported foundation models 62\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 a3-1-405b east-2* Chat\\n405B -\\nus-\\nInstruct instruct\\nwest-2\\n-v1:0\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.2 1B a3-2-1b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2*\\neu-\\ncentra\\nl-1*\\neu-\\nwest-1\\n(Gated)*\\neu-\\nwest-3*\\nSupported foundation models 63\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\n Meta Llama meta.llam us- Text Text, Yes Link N/A\\n3.2 3B a3-2-3b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2*\\neu-\\ncentra\\nl-1*\\neu-\\nwest-1\\n(Gated)*\\neu-\\nwest-3*\\nMeta Llama meta.llam us- Text, Text, Yes Link N/A\\n3.2 11B a3-2-11b- east-1* Image Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2*\\nSupported foundation models 64\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text, Text, Yes Link N/A\\n3.2 90B a3-2-90b- east-1* Image Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2*\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.3 70B a3-3-70b- east-1* Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2\\nus-\\nwest-2*\\nSupported foundation models 65\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\n Mistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI 7B istral-7b east-1\\nInstruct -\\nus-\\ninstruct\\nwest-2\\n-v0:2\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nSupported foundation models 66\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI Large istral-la east-1\\n(24.02) rge-2402-\\nus-\\nv1:0\\nwest-2\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nMistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI Large istral-la west-2\\n(24.07) rge-2407-\\nv1:0\\nSupported foundation models 67\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI Small istral- east-1\\n'}\n",
      "{'question': 'What are the key steps and considerations when requesting access to specific Amazon Bedrock foundation models, and how does the process differ for requesting access to all models?', 'ground_truth': 'When requesting access to specific Amazon Bedrock foundation models, users should first sign into the AWS Management Console and switch to their Amazon Bedrock IAM role. They then need to open the Amazon Bedrock console, ensure they\\'re in the US East (N. Virginia) region, and select \"Model access\" from the navigation pane. After reviewing the EULAs, users choose \"Modify model access\" and select \"Enable specific models.\" They can then request access to individual models or all models from a specific provider by selecting the appropriate checkboxes. For tutorials, it\\'s recommended to request access to at least Amazon Titan Text G1 - Express and Amazon Titan Image Generator G1 V1 models. The process differs for requesting access to all models by simply choosing \"Enable all models\" instead of \"Enable specific models.\" In both cases, users must review the selected models and terms before submitting the request. Access may take several minutes to be granted, and the status will change to \"Access granted\" once approved.', 'question_type': 'complex', 'contexts': \"After setting up your Amazon Bedrock IAM role, you can sign into the Amazon Bedrock console and\\nrequest access to foundation models.\\nTo request access to an Amazon Bedrock FM\\n1. Sign into the AWS Management Console and switch to the Amazon Bedrock role that you set\\nup (or that was set up for you) by following the steps under To switch to a role (console) in\\nSwitching to a role (console).\\n2. Open the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/.\\n3. For the purposes of this tutorial, you should be in the US East (N. Virginia) (us-east-1) Region.\\nTo change regions, choose the Region name at the top right of the console, next to your IAM\\nrole. Then select US East (N. Virginia) (us-east-1).\\n4. Select Model access at the bottom of the left navigation pane.\\n5. On the Model access page, you can review the End User License Agreement (EULA) for models\\nin the EULA column in the Base models table.\\n6. Choose Modify model access.\\n7. Do one of the following:\\n • To request access to all models, choose Enable all models. On the page you're taken to,\\nthe checkboxes next to all the models will be filled.\\n• To request access to specific models, choose Enable specific models. On the page you're\\ntaken to, you have the following options:\\nRequest access to an Amazon Bedrock foundation model 9\\nAmazon Bedrock User Guide\\n• To request access to all models by a provider, select the checkbox next to the provider\\nname.\\n• To request access to one model, select the checkbox next to the model name.\\n8. For the purposes of the following tutorials, you should minimally request access to the\\nAmazon Titan Text G1 - Express and Amazon Titan Image Generator G1 V1 models. Then\\nchoose Next.\\n9. Review the models that you're requesting access to and the Terms. When you're ready, choose\\nSubmit to request access.\\n10. Access may take several minutes to complete. When access is granted to a model, the Access\\nstatus for that model willbecome Access granted.\\n (Optional tutorials) Explore Amazon Bedrock features through\\nthe console or API\\nAfter requesting access to the foundation models that you want to use, you'll be ready to explore\\nthe different capabilities offered by Amazon Bedrock.\\nIf you want to familiarize yourself more with Amazon Bedrock first, you can continue to the\\nfollowing pages:\\n• To learn how to run basic prompts and generate model responses using the Playgrounds in the\\nAmazon Bedrock console, continue to Getting started in the Amazon Bedrock console.\\n• To learn how to set up access to Amazon Bedrock operations through the Amazon Bedrock API\\nand test out some API calls, continue to Getting started with the API.\\n• To learn about the software development kits (SDKs) supported by Amazon Bedrock, continue to\\nUsing Amazon Bedrock with an AWS SDK.\\nGetting started in the Amazon Bedrock console\\nThis section describes how to use the playgrounds in the AWS console to submit a text prompt to a\\n\"}\n",
      "{'question': 'Which Meta Llama model supports both text and image input?', 'ground_truth': 'The Meta Llama 3.2 11B and 90B Instruct models support both text and image input.', 'question_type': 'simple', 'contexts': 'Provider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nCohere Rerank cohere.re us- Text Text No Link N/A\\n3.5 rank- west-2\\nv3-5:0\\nap-\\nnorthe\\nast-1\\nca-\\ncentra\\nl-1\\neu-\\ncentra\\nl-1\\nSupported foundation models 60\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3 8B a3-8b- east-1 Chat\\nInstruct ins\\nus-\\ntruct-\\nwest-2\\nv1:0\\nus-gov-\\nwest-1\\nap-\\nsouth-1\\nca-\\ncentra\\nl-1\\neu-\\nwest-2\\nSupported foundation models 61\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3 70B a3-70b- east-1 Chat\\nInstruct in\\nus-\\nstruct-\\nwest-2\\nv1:0\\nus-gov-\\nwest-1\\nap-\\nsouth-1\\nca-\\n centra\\nl-1\\neu-\\nwest-2\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 8B a3-1-8b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 70B a3-1-70b- east-1* Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2\\nSupported foundation models 62\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 a3-1-405b east-2* Chat\\n405B -\\nus-\\nInstruct instruct\\nwest-2\\n-v1:0\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.2 1B a3-2-1b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2*\\neu-\\ncentra\\nl-1*\\neu-\\nwest-1\\n(Gated)*\\neu-\\nwest-3*\\nSupported foundation models 63\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\n Meta Llama meta.llam us- Text Text, Yes Link N/A\\n3.2 3B a3-2-3b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2*\\neu-\\ncentra\\nl-1*\\neu-\\nwest-1\\n(Gated)*\\neu-\\nwest-3*\\nMeta Llama meta.llam us- Text, Text, Yes Link N/A\\n3.2 11B a3-2-11b- east-1* Image Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2*\\nSupported foundation models 64\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text, Text, Yes Link N/A\\n3.2 90B a3-2-90b- east-1* Image Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2*\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.3 70B a3-3-70b- east-1* Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2\\nus-\\nwest-2*\\nSupported foundation models 65\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\n'}\n",
      "{'question': 'How do the capabilities of Claude 3 Haiku, Claude 3 Opus, and Claude 3 Sonnet differ in terms of input modalities, regional availability, and potential use cases based on their characteristics?', 'ground_truth': \"Claude 3 Haiku, Opus, and Sonnet have distinct capabilities:\\n\\n1. Input modalities:\\nAll three models support both text and image inputs.\\n\\n2. Regional availability:\\n- Claude 3 Haiku: Available in 19 regions, including various US, Asia Pacific, European, and South American regions.\\n- Claude 3 Opus: Limited availability in us-east-1 and us-west-2 regions.\\n- Claude 3 Sonnet: Available in 13 regions, covering US, Asia Pacific, European, and South American areas.\\n\\n3. Potential use cases based on characteristics:\\n- Claude 3 Haiku: Widest regional availability suggests it's suitable for global applications requiring broad geographic coverage.\\n- Claude 3 Opus: Limited regional availability might indicate it's a more specialized or powerful model, potentially for high-performance tasks in specific regions.\\n- Claude 3 Sonnet: Balanced regional availability, potentially for applications requiring good performance and wider geographic reach than Opus, but not as extensive as Haiku.\\n\\nThe differences in regional availability might impact latency, compliance requirements, and scalability of applications using these models. Users should choose the appropriate model based on their specific needs for performance, geographic reach, and potentially, cost considerations.\", 'question_type': 'complex', 'contexts': 'Provider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\neu-\\nwest-3\\nsa-\\neast-1\\nSupported foundation models 46\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAmazon Titan amazon.ti us- Text Text Yes Link Link\\nText G1 tan- east-1\\n- Lite text-\\nus-\\nlite-v1\\nwest-2\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\ncentra\\nl-1\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nSupported foundation models 47\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAmazon Titan amazon.ti us- Text Text Yes Link Link\\nText tan- east-1\\nG1 - text-\\nPremier premier-\\nv1:0\\nAnthropic Claude anthropic us- Text Text, Yes Link N/A\\n2.1 .claude- east-1 Chat\\nv2:1\\nus-\\nwest-2\\nap-\\nnorthe\\nast-1\\neu-\\ncentra\\n l-1\\nAnthropic Claude anthropic us- Text Text, Yes Link N/A\\n2 .claude- east-1 Chat\\nv2\\nus-\\nwest-2\\nap-\\nsouthe\\nast-1\\n(Gated)\\neu-\\ncentra\\nl-1\\nSupported foundation models 48\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n3 Haiku .claude-3 east-1 Image Chat\\n-\\nus-\\nhaiku-20\\neast-2*\\n240307-\\nv1:0\\nus-\\nwest-2\\nus-gov-\\neast-1*\\nus-gov-\\nwest-1\\nap-\\nnorthe\\nast-1\\nap-\\nnorthe\\nast-2\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-1\\n(Gated)\\nap-\\nsouthe\\nast-1\\n(Gated)\\nSupported foundation models 49\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\ncentra\\nl-1\\neu-\\ncentra\\nl-2\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n 3 Opus .claude-3 east-1* Image Chat\\n-\\nus-\\nopus-202\\nwest-2\\n40229-\\nv1:0\\nSupported foundation models 50\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n3 .claude-3 east-1 Image Chat\\nSonnet -\\nus-\\nsonnet-2\\nwest-2\\n0240229-\\nv1:0\\nap-\\nnorthe\\nast-1*\\nap-\\nnorthe\\nast-2*\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-1\\n(Gated)*\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\ncentra\\nl-1\\nSupported foundation models 51\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n3.5 .claude-3 east-1* Image Chat\\nHaiku -5-\\nus-\\nhaiku-\\neast-2*\\n20241022-\\nv1:0\\nus-\\nwest-2\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n'}\n",
      "{'question': 'How can you make IAM user access keys time-bound?', 'ground_truth': 'You can make IAM user access keys time-bound by creating an inline policy that specifies a date after which the keys will no longer be valid. This ensures that the credentials expire in case they are mishandled.', 'question_type': 'simple', 'contexts': \"• For AWS SDKs and tools,\\nsee Authenticate using\\nlong-term credentials in\\nthe AWS SDKs and Tools\\nReference Guide.\\n• For AWS APIs, see\\nManaging access keys for\\nIAM users in the IAM User\\nGuide.\\nIAM roles Use temporary credentials to Following the instructions in\\nsign programmatic requests Using temporary credentia\\nto the AWS CLI, AWS SDKs, or ls with AWS resources in the\\nAWS APIs. IAM User Guide.\\nWorkforce identity Use temporary credentials to Following the instructions for\\nsign programmatic requests the interface that you want to\\n(Users managed in IAM\\nto the AWS CLI, AWS SDKs, or use.\\nIdentity Center)\\nAWS APIs.\\n• For the AWS CLI, see\\nConfiguring the AWS\\nCLI to use AWS IAM\\nIdentity Center in the AWS\\nCommand Line Interface\\nUser Guide.\\nGet credentials to grant programmatic access 14\\nAmazon Bedrock User Guide\\nWhich principal needs To By\\nprogrammatic access?\\n• For AWS SDKs, tools, and\\nAWS APIs, see IAM Identity\\nCenter authentication in\\nthe AWS SDKs and Tools\\nReference Guide.\\n How to configure access keys for an IAM user\\nIf you decide to use access keys for an IAM user, AWS recommends that you set an expiration for\\nthe IAM user by including a restrictive inline policy.\\nImportant\\nHeed the following warnings:\\n• Do NOT use your account's root credentials to access AWS resources. These credentials\\nprovide unrestricted account access and are difficult to revoke.\\n• Do NOT put literal access keys or credential information in your application files. If you\\ndo, you create a risk of accidentally exposing your credentials if, for example, you upload\\nthe project to a public repository.\\n• Do NOT include files that contain credentials in your project area.\\n• Manage your access keys securely. Do not provide your access keys to unauthorized\\nparties, even to help find your account identifiers. By doing this, you might give someone\\npermanent access to your account.\\n• Be aware that any credentials stored in the shared AWS credentials file are stored in\\nplaintext.\\n For more details, see Best practices for managing AWS access keys in the AWS General Reference.\\nCreate an IAM user\\n1. On the AWS Management Console Home page, select the IAM service or navigate to the IAM\\nconsole at https://console.aws.amazon.com/iam/.\\nGet credentials to grant programmatic access 15\\nAmazon Bedrock User Guide\\n2. In the navigation pane, select Users and then select Create user.\\n3. Follow the guidance in the IAM console to set up a programmatic user (without access to the\\nAWS Management Console) and without permissions.\\nRestrict user access to a limited time window\\nAny IAM user access keys that you create are long-term credentials. To ensure that these\\ncredentials expire in case they are mishandled, you can make these credentials time-bound by\\ncreating an inline policy that specifies a date after which the keys will no longer be valid.\\n1. Open the IAM user that you just created. In the Permissions tab, choose Add permissions and\\nthen choose Create inline policy.\\n\"}\n",
      "{'question': 'How does the process of granting access to Anthropic models in Amazon Bedrock differ from other models, and what additional steps are required for AWS GovCloud (US) customers?', 'ground_truth': 'The process of granting access to Anthropic models in Amazon Bedrock requires additional steps compared to other models. After selecting the Anthropic models, users must describe their use case details by submitting a form. Access is then granted or denied based on the answers provided in this form.\\n\\nFor AWS GovCloud (US) customers, the process involves extra steps:\\n1. They must first locate their standard AWS account ID associated with their AWS GovCloud (US) account ID.\\n2. They need to navigate to the model access page on the Amazon Bedrock console.\\n3. Select the desired model(s) to enable.\\n4. Choose \"Request model access\" and follow the step-by-step subscription flow.\\n\\nThese additional requirements for Anthropic models and AWS GovCloud (US) customers ensure a more thorough vetting process and compliance with specific regulations, distinguishing them from the standard access granting procedure for other models in Amazon Bedrock.', 'question_type': 'complex', 'contexts': \"using an IAM policy and specifying the model ID. For more information, see Deny access for\\ninference of foundation models.\\nOnce access is provided to a model, it is available for all users in the AWS account.\\nTo add or remove access to foundation models\\n1. Make sure you have permissions to request access, or modify access, to Amazon Bedrock\\nfoundation models.\\n2. Sign into the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/.\\n3. In the left navigation pane, under Bedrock configurations, choose Model access.\\n4. On the Model access page, choose Modify model access.\\n5. Select the models that you want the account to have access to and unselect the models that\\nyou don't want the account to have access to. You have the following options:\\nAdd or remove access to foundation models 32\\nAmazon Bedrock User Guide\\nBe sure to review the End User License Agreement (EULA) for terms and conditions of using a\\nmodel before requesting access to it.\\n • Select the check box next to an individual model to check or uncheck it.\\n• Select the top check box to check or uncheck all models.\\n• Select how the models are grouped and then check or uncheck all the models in a group\\nby selecting the check box next to the group. For example, you can choose to Group by\\nprovider and then select the check box next to Cohere to check or uncheck all Cohere\\nmodels.\\n6. Choose Next.\\n7. If you add access to Anthropic models, you must describe your use case details. Choose Submit\\nuse case details, fill out the form, and then select Submit form. Notification of access is\\ngranted or denied based on your answers when completing the form for the provider.\\n8. Review the access changes you're making, and then read the Terms.\\nNote\\nYour use of Amazon Bedrock foundation models is subject to the seller's pricing terms,\\nEULA, and the AWS service terms.\\n9. If you agree with the terms, choose Submit. The changes can take several minutes to be\\nreflected in the console.\\n Note\\nIf you revoke access to a model, it can still be accessed through the API for some time\\nafter you complete this action while the changes propagate. To immediately remove\\naccess in the meantime, add an IAM policy to a role to deny access to the model.\\n10. If your request is successful, the Access status changes to Access granted or Available to\\nrequest.\\nNote\\nFor AWS GovCloud (US) customers, follow these steps to access models that are available in\\nAWS GovCloud (US):\\nAdd or remove access to foundation models 33\\nAmazon Bedrock User Guide\\n• AWS GovCloud (US) users must locate their standard AWS account ID associated with\\ntheir AWS GovCloud (US) account ID. AWS GovCloud (US) users can follow this guide\\nFinding your associated standard AWS account ID, if they don't already know their ID.\\nNavigate to the model access page on Amazon Bedrock console. Select the model(s)\\nthat you want to enable. Select Request model access and follow the step-by-step\\nsubscription flow.\\n\"}\n",
      "{'question': 'What is embedding in the context of Amazon Bedrock?', 'ground_truth': 'Embedding is the process of condensing information by transforming input into a vector of numerical values, known as embeddings, to compare similarity between different objects using a shared numerical representation. It can be used to compare sentences, images, or even text and images for relevance or similarity.', 'question_type': 'simple', 'contexts': \"of a response or the occurrence of specified sequences. For more information and definitions of\\nspecific inference parameters, see Influence response generation with inference parameters.\\n• Playground – A user-friendly graphical interface in the AWS Management Console in which\\nyou can experiment with running model inference to familiarize yourself with Amazon Bedrock.\\nUse the playground to test out the effects of different models, configurations, and inference\\nparameters on the responses generated for different prompts that you enter. For more\\ninformation, see Generate responses in the console using playgrounds.\\n• Embedding – The process of condensing information by transforming input into a vector\\nof numerical values, known as the embeddings, in order to compare the similarity between\\ndifferent objects by using a shared numerical representation. For example, sentences can be\\ncompared to determine the similarity in meaning, images can be compared to determine visual\\n similarity, or text and image can be compared to see if they're relevant to each other. You can\\nalso combine text and image inputs into an averaged embeddings vector if it's relevant to\\nyour use case. For more information, see Submit prompts and generate responses with model\\ninference and Retrieve data and generate AI responses with Amazon Bedrock Knowledge Bases.\\nKey terminology 4\\nAmazon Bedrock User Guide\\n• Orchestration – The process of coordinating between foundation models and enterprise data\\nand applications in order to carry out a task. For more information, see Automate tasks in your\\napplication using AI agents.\\n• Agent – An application that carry out orchestrations through cyclically interpreting inputs and\\nproducing outputs by using a foundation model. An agent can be used to carry out customer\\nrequests. For more information, see Automate tasks in your application using AI agents.\\n• Retrieval augmented generation (RAG) – The process of querying and retrieving information\\n from a data source in order to augment a generated response to a prompt. For more\\ninformation, see Retrieve data and generate AI responses with Amazon Bedrock Knowledge\\nBases.\\n• Model customization – The process of using training data to adjust the model parameter values\\nin a base model in order to create a custom model. Examples of model customization include\\nFine-tuning, which uses labeled data (inputs and corresponding outputs), and Continued\\nPre-training, which uses unlabeled data (inputs only) to adjust model parameters. For more\\ninformation about model customization techniques available in Amazon Bedrock, see Customize\\nyour model to improve its performance for your use case.\\n• Hyperparameters – Values that can be adjusted for model customization to control the training\\nprocess and, consequently, the output custom model. For more information and definitions of\\nspecific hyperparameters, see Custom model hyperparameters.\\n\"}\n",
      "{'question': 'Which AI model offers the most comprehensive global coverage, and how does its availability compare to other models in key regions like US East, Europe, and Asia Pacific?', 'ground_truth': 'Based on the information provided, Claude 3 Sonnet by Anthropic offers the most comprehensive global coverage. It is available in most regions, including US East (N. Virginia), Europe (Frankfurt, London, Paris), and multiple Asia Pacific locations. \\n\\nSpecifically:\\n- It\\'s available in US East (N. Virginia), US West (Oregon), and Canada.\\n- In Europe, it\\'s available in Frankfurt, London, and Paris.\\n- In Asia Pacific, it\\'s available in Tokyo, Seoul, Mumbai, Singapore, and Sydney.\\n- It\\'s also available in São Paulo (South America) and marked as \"Gated\" in AWS GovCloud.\\n\\nCompared to other models:\\n- Most Amazon Titan models have limited availability outside the US.\\n- Other Anthropic models like Claude 2 and Claude Instant have more limited regional availability.\\n- Cohere and Meta models are generally available in fewer regions.\\n\\nClaude 3 Sonnet stands out for its wide availability across North America, Europe, Asia Pacific, and South America, making it one of the most globally accessible AI models in the lineup.', 'question_type': 'complex', 'contexts': 'ModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAmazon\\nYes No Yes No No No No Yes No Yes Yes Yes No GatedYes Yes Yes\\nTitan\\nText\\nG1\\n-\\nLite\\nAmazon\\nYes No No No No No No No No No No No No No No No No\\nTitan\\nText\\nG1\\n-\\nPremier\\nAnthropic\\nYes No Yes No No Yes No No No No No Yes No No No No No\\nClaude\\n2.1\\nAnthropic\\nYes No Yes No No No No No GatedNo No Yes No No No No No\\nClaude\\n2\\nAnthropic\\nYes Yes* Yes Yes* Yes Yes Yes Yes GatedYes Yes Yes Yes GatedYes Yes Yes\\nClaude\\n3\\nHaiku\\nAnthropic\\nYes* No Yes No No No No No No No No No No No No No No\\nClaude\\n3\\nOpus\\nModel support by Region 74\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAnthropic\\nYes No Yes No No Yes* Yes* Yes GatedYes Yes Yes No GatedYes Yes Yes\\nClaude\\n3\\nSonnet\\nAnthropic\\nYes* Yes* Yes No No No No No No No No No No No No No No\\nClaude\\n3.5\\nHaiku\\nAnthropic\\nYes* No Yes No No No No No No No No No No No No No No\\nClaude\\n3.5\\nSonnet\\nv2\\nAnthropic\\nYes Yes* Yes Yes* Yes Yes Yes Yes* GatedYes* No Yes Yes GatedNo Yes* No\\nClaude\\n3.5\\nSonnet\\nAnthropic\\nYes No Yes No No Yes No No GatedNo No Yes No No No No No\\nClaude\\nInstant\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nLight\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nR+\\nModel support by Region 75\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nR\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nEnglish\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nMultiling\\nual\\nCohere\\nNo No Yes No No Yes No No No No Yes Yes No No No No No\\nRerank\\n3.5\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n8B\\nInstruct\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n70B\\nInstruct\\nModel support by Region 76\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n'}\n",
      "{'question': 'Which regions support the Cohere Command model?', 'ground_truth': 'The Cohere Command model is supported in US East (N. Virginia) and US West (Oregon) regions.', 'question_type': 'simple', 'contexts': 'East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nR\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nEnglish\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nMultiling\\nual\\nCohere\\nNo No Yes No No Yes No No No No Yes Yes No No No No No\\nRerank\\n3.5\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n8B\\nInstruct\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n70B\\nInstruct\\nModel support by Region 76\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nMeta\\nYes* Yes* Yes No No No No No No No No No No No No No No\\nLlama\\n3.1\\n8B\\nInstruct\\nMeta\\nYes* Yes* Yes No No No No No No No No No No No No No No\\nLlama\\n3.1\\n70B\\nInstruct\\nMeta\\nNo Yes* Yes No No No No No No No No No No No No No No\\nLlama\\n3.1\\n405B\\nInstruct\\nMeta\\nYes* Yes* Yes* No No No No No No No No Yes* No GatedNo Yes* No\\nLlama\\n3.2\\n1B\\nInstruct\\nMeta\\nYes* Yes* Yes* No No No No No No No No Yes* No GatedNo Yes* No\\nLlama\\n3.2\\n3B\\nInstruct\\nModel support by Region 77\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n (N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nMeta\\nYes* Yes* Yes* No No No No No No No No No No No No No No\\nLlama\\n3.2\\n11B\\nInstruct\\nMeta\\nYes* Yes* Yes* No No No No No No No No No No No No No No\\nLlama\\n3.2\\n90B\\nInstruct\\nMeta\\nYes* Yes Yes* No No No No No No No No No No No No No No\\nLlama\\n3.3\\n70B\\nInstruct\\nMistral\\nYes No Yes No No No No Yes No Yes Yes No No GatedYes Yes Yes\\nAI\\nMistral\\n7B\\nInstruct\\nMistral\\nYes No Yes No No No No Yes No Yes Yes No No GatedYes Yes Yes\\nAI\\nMistral\\nLarge\\n(24.02)\\nModel support by Region 78\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nMistral\\nNo No Yes No No No No No No No No No No No No No No\\n'}\n",
      "{'question': 'How does the InvokeModel operation in Amazon Bedrock handle model-specific configurations, and what are the key components of the request payload when using the AWS SDK for Python?', 'ground_truth': 'The InvokeModel operation in Amazon Bedrock handles model-specific configurations through a structured request payload that is formatted according to the model\\'s native structure. When using the AWS SDK for Python, the key components of the request payload include:\\n\\n1. The input text or prompt for the model.\\n2. A textGenerationConfig object containing parameters such as:\\n   - maxTokenCount: to limit the length of the generated response\\n   - temperature: to control the randomness of the output\\n   - topP: to influence the diversity of the generated text\\n\\nThe payload is then converted to JSON format before being sent to the model. For example, with the Amazon Titan Text G1 - Express model, the request payload would look like this:\\n\\n{\\n  \"inputText\": \"Describe the purpose of a \\'hello world\\' program in one line.\",\\n  \"textGenerationConfig\": {\\n    \"maxTokenCount\": 512,\\n    \"temperature\": 0.5,\\n    \"topP\": 0.9\\n  }\\n}\\n\\nThis structured approach allows for flexible configuration of different models while maintaining a consistent interface for the InvokeModel operation across various foundation models in Amazon Bedrock.', 'question_type': 'complex', 'contexts': 'languages. For more information, see Code examples for Amazon Bedrock using AWS SDKs.\\nTopics\\n• List the foundation models that Amazon Bedrock has to offer\\n• Submit a text prompt to a model and generate a text response with InvokeModel\\n• Submit a text prompt to a model and generate a text response with Converse\\nList the foundation models that Amazon Bedrock has to offer\\nThe following example runs the ListFoundationModels operation using an Amazon Bedrock client.\\nListFoundationModels lists the foundation models (FMs) that are available in Amazon Bedrock\\nin your region. Run the following SDK for Python script to create an Amazon Bedrock client and\\ntest the ListFoundationModels operation:\\n# Use the ListFoundationModels API to show the models that are available in your\\nregion.\\nimport boto3\\n# Create an &BR; client in the &region-us-east-1; Region.\\nbedrock = boto3.client(\\nservice_name=\"bedrock\"\\n)\\nbedrock.list_foundation_models()\\n If the script is successful, the response returns a list of foundation models that are available in\\nAmazon Bedrock.\\nSubmit a text prompt to a model and generate a text response with InvokeModel\\nThe following example runs the InvokeModel operation using an Amazon Bedrock client.\\nInvokeModel lets you submit a prompt to generate a model response. Run the following SDK for\\nPython script to create an Amazon Bedrock runtime client and generate a text response with the\\noperation:\\nRun examples with the AWS SDK for Python (Boto3) 21\\nAmazon Bedrock User Guide\\n# Use the native inference API to send a text message to Amazon Titan Text G1 -\\nExpress.\\nimport boto3\\nimport json\\nfrom botocore.exceptions import ClientError\\n# Create an Amazon Bedrock Runtime client.\\nbrt = boto3.client(\"bedrock-runtime\")\\n# Set the model ID, e.g., Amazon Titan Text G1 - Express.\\nmodel_id = \"amazon.titan-text-express-v1\"\\n# Define the prompt for the model.\\n prompt = \"Describe the purpose of a \\'hello world\\' program in one line.\"\\n# Format the request payload using the model\\'s native structure.\\nnative_request = {\\n\"inputText\": prompt,\\n\"textGenerationConfig\": {\\n\"maxTokenCount\": 512,\\n\"temperature\": 0.5,\\n\"topP\": 0.9\\n},\\n}\\n# Convert the native request to JSON.\\nrequest = json.dumps(native_request)\\ntry:\\n# Invoke the model with the request.\\nresponse = brt.invoke_model(modelId=model_id, body=request)\\nexcept (ClientError, Exception) as e:\\nprint(f\"ERROR: Can\\'t invoke \\'{model_id}\\'. Reason: {e}\")\\nexit(1)\\n# Decode the response body.\\nmodel_response = json.loads(response[\"body\"].read())\\n# Extract and print the response text.\\nresponse_text = model_response[\"results\"][0][\"outputText\"]\\nRun examples with the AWS SDK for Python (Boto3) 22\\nAmazon Bedrock User Guide\\nprint(response_text)\\nIf the command is successful, the response returns the text generated by the model in response to\\nthe prompt.\\n'}\n",
      "{'question': 'How can you secure your AWS account root user?', 'ground_truth': 'To secure your AWS account root user, you should turn on multi-factor authentication (MFA) for the root user.', 'question_type': 'simple', 'contexts': \"and choosing My Account.\\nSecure your AWS account root user\\n1. Sign in to the AWS Management Console as the account owner by choosing Root user and\\nentering your AWS account email address. On the next page, enter your password.\\nFor help signing in by using root user, see Signing in as the root user in the AWS Sign-In User\\nGuide.\\n2. Turn on multi-factor authentication (MFA) for your root user.\\nFor instructions, see Enable a virtual MFA device for your AWS account root user (console) in\\nthe IAM User Guide.\\nI need to install the AWS CLI or an AWS SDK\\nTo install the AWS CLI, follow the steps at Install or update to the latest version of the AWS CLI.\\nTo install an AWS SDK, select the tab that corresponds to the programming language that you\\nwant to use at Tools to Build on AWS. AWS software development kits (SDKs) are available\\nfor many popular programming languages. Each SDK provides an API, code examples, and\\n documentation that make it easier for developers to build applications in their preferred language.\\nSDKs automatically perform useful tasks for you, such as:\\n• Cryptographically sign your service requests\\n• Retry requests\\n• Handle error responses\\nGet credentials to grant programmatic access\\nUsers need programmatic access if they want to interact with AWS outside of the AWS\\nManagement Console. The way to grant programmatic access depends on the type of user that's\\naccessing AWS.\\nTo grant users programmatic access, choose one of the following options.\\nGet credentials to grant programmatic access 13\\nAmazon Bedrock User Guide\\nWhich principal needs To By\\nprogrammatic access?\\nIAM users Limit the duration of long- Following the instructions for\\nterm credentials to sign the interface that you want to\\nprogrammatic requests to the use.\\nAWS CLI, AWS SDKs, or AWS\\n• For the AWS CLI, see\\nAPIs.\\nAuthenticating using IAM\\nuser credentials in the AWS\\nCommand Line Interface\\nUser Guide.\\n • For AWS SDKs and tools,\\nsee Authenticate using\\nlong-term credentials in\\nthe AWS SDKs and Tools\\nReference Guide.\\n• For AWS APIs, see\\nManaging access keys for\\nIAM users in the IAM User\\nGuide.\\nIAM roles Use temporary credentials to Following the instructions in\\nsign programmatic requests Using temporary credentia\\nto the AWS CLI, AWS SDKs, or ls with AWS resources in the\\nAWS APIs. IAM User Guide.\\nWorkforce identity Use temporary credentials to Following the instructions for\\nsign programmatic requests the interface that you want to\\n(Users managed in IAM\\nto the AWS CLI, AWS SDKs, or use.\\nIdentity Center)\\nAWS APIs.\\n• For the AWS CLI, see\\nConfiguring the AWS\\nCLI to use AWS IAM\\nIdentity Center in the AWS\\nCommand Line Interface\\nUser Guide.\\nGet credentials to grant programmatic access 14\\nAmazon Bedrock User Guide\\nWhich principal needs To By\\nprogrammatic access?\\n• For AWS SDKs, tools, and\\nAWS APIs, see IAM Identity\\nCenter authentication in\\nthe AWS SDKs and Tools\\nReference Guide.\\n\"}\n",
      "{'question': 'How does the regional availability of Amazon Nova models compare to AI21 Labs models in Amazon Bedrock, and what implications might this have for developers choosing between these providers?', 'ground_truth': 'The regional availability of Amazon Nova models is broader compared to AI21 Labs models in Amazon Bedrock. Amazon Nova models (Lite, Micro, and Pro) are available in US East (N. Virginia), and have cross-region inference support in US East (Ohio) and US West (Oregon). In contrast, AI21 Labs models (Jamba 1.5 Large, Jamba 1.5 Mini, and Jamba-Instruct) are only available in US East (N. Virginia) with no cross-region inference support mentioned. This difference in availability implies that developers choosing Amazon Nova models have more flexibility in terms of geographical deployment and potentially lower latency for users in different regions. However, those requiring AI21 Labs models may face limitations in regional deployment options and possible higher latency for users outside the US East region.', 'question_type': 'complex', 'contexts': 'Stability Stable stability us- Text Image No Link N/A\\nAI Image .stable- west-2\\nUltra image-\\n1.0 ultra-\\nv1:1\\nSupported foundation models 69\\nAmazon Bedrock User Guide\\nNote\\n* Some models are accessible in some Regions only through cross-region inference. To learn\\nmore about cross-region inference, see Increase throughput with cross-region inference and\\nSupported Regions and models for inference profiles.\\nThe following table lists models that have a target date for deprecation. For more information, see\\nModel lifecycle:\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAI21 J2 ai21.j2- us- Text Text, No Link N/A\\nLabs Grande grande- east-1 Chat\\nInstruct instruct\\nAI21 J2 ai21.j2- us- Text Text, No Link N/A\\nLabs Jumbo jumbo- east-1 Chat\\nInstruct instruct\\nAI21 Jurassic- ai21.j2- us- Text Text, No Link N/A\\nLabs 2 Mid mid-v1 east-1 Chat\\nAI21 Jurassic- ai21.j2- us- Text Text, No Link N/A\\n Labs 2 Ultra ultra-v1 east-1 Chat\\nStability SDXL stability us- Text, Image No Link N/A\\nAI 1.0 .stable- east-1 Image\\nd\\nus-\\niffusion-\\nwest-2\\nxl-v1\\nSupported foundation models 70\\nAmazon Bedrock User Guide\\nModel support by AWS Region in Amazon Bedrock\\nFor a list of AWS Regions that support Amazon Bedrock, see Amazon Bedrock endpoints and\\nquotas. Amazon Bedrock foundation models differ in their regional support.\\nThe following table shows Region support by model:\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJamba\\n1.5\\nLarge\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJamba\\n1.5\\nMini\\nAI21\\n Yes No No No No No No No No No No No No No No No No\\nLabs\\nJamba-\\nIns\\ntruct\\nAmazon\\nYes No No No No No No No No No No No No No No No No\\nNova\\nCanvas\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nLite\\nModel support by Region 71\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nMicro\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nPro\\nAmazon\\nYes No No No No No No No No No No No No No No No No\\nNova\\nReel\\nAmazon\\nNo No Yes No No Yes No No No No Yes Yes No No No No No\\nRerank\\n1.0\\nAmazon\\nYes No Yes No No Yes No No No No No Yes No No No No No\\nTitan\\nEmbedding\\ns\\nG1\\n-\\nText\\nAmazon\\n'}\n",
      "{'question': 'Which provider offers the Stable Diffusion 3.5 Large model in Amazon Bedrock?', 'ground_truth': 'Stability AI offers the Stable Diffusion 3.5 Large model in Amazon Bedrock.', 'question_type': 'simple', 'contexts': 'Mistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI 7B istral-7b east-1\\nInstruct -\\nus-\\ninstruct\\nwest-2\\n-v0:2\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nSupported foundation models 66\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI Large istral-la east-1\\n(24.02) rge-2402-\\nus-\\nv1:0\\nwest-2\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nMistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI Large istral-la west-2\\n(24.07) rge-2407-\\nv1:0\\nSupported foundation models 67\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI Small istral- east-1\\n (24.02) sm\\nall-2402-\\nv1:0\\nMistral Mixtral mistral.m us- Text Text Yes Link N/A\\nAI 8x7B ixtral-8x east-1\\nInstruct 7b-\\nus-\\ninstru\\nwest-2\\nct-v0:1\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nSupported foundation models 68\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nStability SD3 stability us- Text, Image No Link N/A\\nAI Large .sd3- west-2 Image\\n1.0 large-\\nv1:0\\nStability Stable stability us- Text, Image No Link N/A\\nAI Diffusion .sd3-5- west-2 Image\\n3.5 large-\\nLarge v1:0\\nStability Stable stability us- Text Image No Link N/A\\nAI Image .stable- west-2\\nCore image-\\n1.0 core-\\nv1:0\\nStability Stable stability us- Text Image No Link N/A\\nAI Image .stable- west-2\\nCore image-\\n1.0 core-\\nv1:1\\nStability Stable stability us- Text Image No Link N/A\\nAI Image .stable- west-2\\nUltra image-\\n1.0 ultra-\\nv1:0\\n Stability Stable stability us- Text Image No Link N/A\\nAI Image .stable- west-2\\nUltra image-\\n1.0 ultra-\\nv1:1\\nSupported foundation models 69\\nAmazon Bedrock User Guide\\nNote\\n* Some models are accessible in some Regions only through cross-region inference. To learn\\nmore about cross-region inference, see Increase throughput with cross-region inference and\\nSupported Regions and models for inference profiles.\\nThe following table lists models that have a target date for deprecation. For more information, see\\nModel lifecycle:\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAI21 J2 ai21.j2- us- Text Text, No Link N/A\\nLabs Grande grande- east-1 Chat\\nInstruct instruct\\nAI21 J2 ai21.j2- us- Text Text, No Link N/A\\nLabs Jumbo jumbo- east-1 Chat\\nInstruct instruct\\nAI21 Jurassic- ai21.j2- us- Text Text, No Link N/A\\nLabs 2 Mid mid-v1 east-1 Chat\\nAI21 Jurassic- ai21.j2- us- Text Text, No Link N/A\\n'}\n",
      "{'question': 'How can a developer use the ListFoundationModels operation in Amazon Bedrock, and what strategic advantage does this provide when building AI-powered applications?', 'ground_truth': 'A developer can use the ListFoundationModels operation in Amazon Bedrock by creating an Amazon Bedrock client and calling the list_foundation_models() method. This operation lists all available foundation models (FMs) in the specified AWS region. The strategic advantage this provides is twofold: First, it allows developers to dynamically discover which AI models are accessible in their region, enabling them to make informed decisions about which models to use for their specific use cases. Second, it facilitates the creation of more flexible and region-aware applications that can adapt to the available AI capabilities, potentially improving performance and reducing costs by selecting the most appropriate model for each task.', 'question_type': 'complex', 'contexts': 'languages. For more information, see Code examples for Amazon Bedrock using AWS SDKs.\\nTopics\\n• List the foundation models that Amazon Bedrock has to offer\\n• Submit a text prompt to a model and generate a text response with InvokeModel\\n• Submit a text prompt to a model and generate a text response with Converse\\nList the foundation models that Amazon Bedrock has to offer\\nThe following example runs the ListFoundationModels operation using an Amazon Bedrock client.\\nListFoundationModels lists the foundation models (FMs) that are available in Amazon Bedrock\\nin your region. Run the following SDK for Python script to create an Amazon Bedrock client and\\ntest the ListFoundationModels operation:\\n# Use the ListFoundationModels API to show the models that are available in your\\nregion.\\nimport boto3\\n# Create an &BR; client in the &region-us-east-1; Region.\\nbedrock = boto3.client(\\nservice_name=\"bedrock\"\\n)\\nbedrock.list_foundation_models()\\n If the script is successful, the response returns a list of foundation models that are available in\\nAmazon Bedrock.\\nSubmit a text prompt to a model and generate a text response with InvokeModel\\nThe following example runs the InvokeModel operation using an Amazon Bedrock client.\\nInvokeModel lets you submit a prompt to generate a model response. Run the following SDK for\\nPython script to create an Amazon Bedrock runtime client and generate a text response with the\\noperation:\\nRun examples with the AWS SDK for Python (Boto3) 21\\nAmazon Bedrock User Guide\\n# Use the native inference API to send a text message to Amazon Titan Text G1 -\\nExpress.\\nimport boto3\\nimport json\\nfrom botocore.exceptions import ClientError\\n# Create an Amazon Bedrock Runtime client.\\nbrt = boto3.client(\"bedrock-runtime\")\\n# Set the model ID, e.g., Amazon Titan Text G1 - Express.\\nmodel_id = \"amazon.titan-text-express-v1\"\\n# Define the prompt for the model.\\n prompt = \"Describe the purpose of a \\'hello world\\' program in one line.\"\\n# Format the request payload using the model\\'s native structure.\\nnative_request = {\\n\"inputText\": prompt,\\n\"textGenerationConfig\": {\\n\"maxTokenCount\": 512,\\n\"temperature\": 0.5,\\n\"topP\": 0.9\\n},\\n}\\n# Convert the native request to JSON.\\nrequest = json.dumps(native_request)\\ntry:\\n# Invoke the model with the request.\\nresponse = brt.invoke_model(modelId=model_id, body=request)\\nexcept (ClientError, Exception) as e:\\nprint(f\"ERROR: Can\\'t invoke \\'{model_id}\\'. Reason: {e}\")\\nexit(1)\\n# Decode the response body.\\nmodel_response = json.loads(response[\"body\"].read())\\n# Extract and print the response text.\\nresponse_text = model_response[\"results\"][0][\"outputText\"]\\nRun examples with the AWS SDK for Python (Boto3) 22\\nAmazon Bedrock User Guide\\nprint(response_text)\\nIf the command is successful, the response returns the text generated by the model in response to\\nthe prompt.\\n'}\n",
      "{'question': 'How can you retrieve information about all foundation models in Amazon Bedrock?', 'ground_truth': 'You can send a ListFoundationModels request using the Amazon Bedrock API to retrieve information about all the foundation models that Amazon Bedrock provides.', 'question_type': 'simple', 'contexts': \"• Model support by AWS Region in Amazon Bedrock\\n• Feature support by AWS Region in Amazon Bedrock\\n• Model support by feature\\n• Inference request parameters and response fields for foundation models\\n• Custom model hyperparameters\\n• Model lifecycle\\n36\\nAmazon Bedrock User Guide\\nGet information about foundation models\\nIn the Amazon Bedrock console, you can find overarching information about Amazon Bedrock\\nfoundation model providers and the models they provide in the Providers and Base models\\nsections.\\nUse the API to retrieve information about Amazon Bedrock foundation model, including its\\nARN, model ID, modalities and features it supports, and whether it is deprecated or not, in a\\nFoundationModelSummary object.\\n• To return information about all the foundation models that Amazon Bedrock provides, send a\\nListFoundationModels request.\\nNote\\nThe response also returns model IDs that aren't in the base model ID or base model IDs\\n for Provisioned Throughput charts. These model IDs are deprecated or for backwards\\ncompability.\\n• To return information about a specific foundation model, send a GetFoundationModel request,\\nspecifying the model ID.\\nChoose a tab to see code examples in an interface or language.\\nAWS CLI\\nList the Amazon Bedrock foundation models.\\naws bedrock list-foundation-models\\nGet information about Anthropic Claude v2.\\naws bedrock get-foundation-model --model-identifier anthropic.claude-v2\\nPython\\nList the Amazon Bedrock foundation models.\\nimport boto3\\nbedrock = boto3.client(service_name='bedrock')\\nGet model information 37\\nAmazon Bedrock User Guide\\nbedrock.list_foundation_models()\\nGet information about Anthropic Claude v2.\\nimport boto3\\nbedrock = boto3.client(service_name='bedrock')\\nbedrock.get_foundation_model(modelIdentifier='anthropic.claude-v2')\\nSupported foundation models in Amazon Bedrock\\nAmazon Bedrock supports foundation models (FMs) from multiple providers.\\n The following table lists each model alongside the ID that you can use to make on-demand API\\ncalls, the AWS Regions that support it, its capabilities, and links to relevant documentation:\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAI21 Jamba ai21.jamb us- Text Text, Yes Link N/A\\nLabs 1.5 a-1-5- east-1 Chat\\nLarge large-\\nv1:0\\nAI21 Jamba ai21.jamb us- Text Text, Yes Link N/A\\nLabs 1.5 Mini a-1-5- east-1 Chat\\nmini-\\nv1:0\\nAI21 Jamba- ai21.jamb us- Text Text, Yes Link N/A\\nLabs Instruct a- east-1 Chat\\ninstruc\\nt-v1:0\\nAmazon Nova amazon.no us- Text, Image No Link Link\\nCanvas va- east-1 Image\\nSupported foundation models 38\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\ncanvas-\\nv1:0\\nAmazon Nova amazon.no us- Text, Text Yes Link Link\\nLite va-lite- east-1 Image,\\nv1:0 Video\\nus-\\neast-2*\\n\"}\n",
      "{'question': 'How can an organization implement fine-grained control over which Amazon Bedrock foundation models their IAM users can request access to, and what are the potential implications of this approach?', 'ground_truth': \"An organization can implement fine-grained control over which Amazon Bedrock foundation models their IAM users can request access to by using the aws-marketplace:ProductId condition key in combination with the aws-marketplace:Subscribe action in their IAM policies. This approach allows administrators to restrict subscription requests to specific models by their Product IDs.\\n\\nFor example, an IAM policy could be crafted to allow subscription requests only for certain models, such as Anthropic Claude and Cohere Command, by specifying their respective Product IDs (c468b48a-84df-43a4-8c46-8870630108a7 and a61c46fe-1747-41aa-9af0-2e0ae8a9ce05).\\n\\nImplications of this approach include:\\n1. Enhanced security and compliance by limiting access to only necessary models.\\n2. Potential cost control by restricting access to more expensive models.\\n3. Increased administrative overhead in managing and updating policies as new models become available or requirements change.\\n4. The need for careful planning to ensure that users have access to the most appropriate models for their tasks without overly restricting innovation or productivity.\\n\\nIt's important to note that this fine-grained control applies to requesting access, not to making inference calls. To prevent users from making inference calls to specific models, a separate IAM policy specifying the model ID would be required.\", 'question_type': 'complex', 'contexts': 'permissions to manage access to foundation models. Then, add or remove access to a model by\\nfollowing the instructions at Add or remove access to Amazon Bedrock foundation models.\\nFor information about model pricing, refer to Amazon Bedrock Pricing.\\nTopics\\n• Grant IAM permissions to request access to Amazon Bedrock foundation models\\n• Add or remove access to Amazon Bedrock foundation models\\nGrant IAM permissions to request access to Amazon Bedrock\\nfoundation models\\nBefore you can request access, or modify access, to Amazon Bedrock foundation models, you need\\nto attach an identity-based IAM policy with the following AWS Marketplace actions to the IAM role\\nthat allows access to Amazon Bedrock:\\n• aws-marketplace:Subscribe\\n• aws-marketplace:Unsubscribe\\n• aws-marketplace:ViewSubscriptions\\nFor information creating the policy, see I already have an AWS account.\\nFor the aws-marketplace:Subscribe action only, you can use the aws-\\n marketplace:ProductId condition key to restrict subscription to specific models.\\nGrant permissions to request access to foundation models 29\\nAmazon Bedrock User Guide\\nNote\\nYou can\\'t remove request access from the Amazon Titan, Mistral AI, and Meta Llama 3\\nInstruct models. You can prevent users from making inference calls to these models by\\nusing an IAM policy and specifying the model ID. For more information, see Deny access for\\ninference of foundation models.\\nThe following table lists product IDs for Amazon Bedrock foundation models:\\nThe following is the format of the IAM policy you can attach to a role to control model access\\npermissions:\\nModel Product ID\\nAI21 Labs Jurassic-2 Mid 1d288c71-65f9-489a-a3e2-9c7f4f6e6a85\\nAI21 Labs Jurassic-2 Ultra cc0bdd50-279a-40d8-829c-4009b77a1fcc\\nAI21 Jamba-Instruct prod-dr2vpvd4k73aq\\nAI21 Labs Jamba 1.5 Large prod-evcp4w4lurj26\\nAI21 Labs Jamba 1.5 Mini prod-ggrzjm65qmjhm\\nAnthropic Claude c468b48a-84df-43a4-8c46-8870630108a7\\n Anthropic Claude Instant b0eb9475-3a2c-43d1-94d3-56756fd43737\\nAnthropic Claude 3 Sonnet prod-6dw3qvchef7zy\\nAnthropic Claude 3.5 Sonnet prod-m5ilt4siql27k\\nAnthropic Claude 3.5 Sonnet v2 prod-cx7ovbu5wex7g\\nAnthropic Claude 3 Haiku prod-ozonys2hmmpeu\\nAnthropic Claude 3.5 Haiku prod-5oba7y7jpji56\\nAnthropic Claude 3 Opus prod-fm3feywmwerog\\nGrant permissions to request access to foundation models 30\\nAmazon Bedrock User Guide\\nModel Product ID\\nCohere Command a61c46fe-1747-41aa-9af0-2e0ae8a9ce05\\nCohere Command Light 216b69fd-07d5-4c7b-866b-936456d68311\\nCohere Command R prod-tukx4z3hrewle\\nCohere Command R+ prod-nb4wqmplze2pm\\nCohere Embed (English) b7568428-a1ab-46d8-bab3-37def50f6f6a\\nCohere Embed (Multilingual) 38e55671-c3fe-4a44-9783-3584906e7cad\\nCohere Rerank 3.5 prod-2o5bej62oxkbi\\nStable Diffusion XL 1.0 prod-2lvuzn4iy6n6o\\nStable Image Core 1.0 prod-eacdrmv7zfc5e\\nStable Diffusion 3 Large 1.0 prod-cqfmszl26sxu4\\nStable Image Ultra 1.0 prod-7boen2z2wnxrg\\n{\\n\"Version\": \"2012-10-17\",\\n'}\n",
      "{'question': 'Which region supports the most AI models in Amazon Bedrock?', 'ground_truth': 'US East (N. Virginia) supports the most AI models in Amazon Bedrock, with \"Yes\" indicated for several models across different providers.', 'question_type': 'simple', 'contexts': 'AI\\nMistral\\nLarge\\n(24.07)\\nMistral\\nYes No No No No No No No No No No No No No No No No\\nAI\\nMistral\\nSmall\\n(24.02)\\nMistral\\nYes No Yes No No No No Yes No Yes Yes No No GatedYes Yes Yes\\nAI\\nMixtral\\n8x7B\\nInstruct\\nStability\\nNo No Yes No No No No No No No No No No No No No No\\nAI\\nSD3\\nLarge\\n1.0\\nStability\\nNo No Yes No No No No No No No No No No No No No No\\nAI\\nStable\\nDiffusion\\n3.5\\nLarge\\nModel support by Region 79\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nStability\\nNo No Yes No No No No No No No No No No No No No No\\nAI\\nStable\\nImage\\nCore\\n1.0\\nStability\\nNo No Yes No No No No No No No No No No No No No No\\nAI\\nStable\\nImage\\nCore\\n1.0\\nStability\\n No No Yes No No No No No No No No No No No No No No\\nAI\\nStable\\nImage\\nUltra\\n1.0\\nStability\\nNo No Yes No No No No No No No No No No No No No No\\nAI\\nStable\\nImage\\nUltra\\n1.0\\nModel support by Region 80\\nAmazon Bedrock User Guide\\nNote\\n* Some models are accessible in some Regions only through cross-region inference. To learn\\nmore about cross-region inference, see Increase throughput with cross-region inference and\\nSupported Regions and models for inference profiles.\\nThe following table shows Region support for models that have a target date for deprecation. For\\nmore information, see Model lifecycle.\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJ2\\n Grande\\nInstruct\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJ2\\nJumbo\\nInstruct\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJurassic-\\n2\\nMid\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJurassic-\\nModel support by Region 81\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\n2\\nUltra\\nStability\\nYes No Yes No No No No No No No No No No No No No No\\nAI\\nSDXL\\n1.0\\nTo learn more about Region and model support for specific features, see the following links:\\n• Converse API\\n• Batch inference\\n• Inference profiles\\n• Latency optimization\\n• Prompt management\\n• Prompt management\\n• Prompt optimization\\n• Amazon Bedrock Guardrails\\n• Model evaluation\\n'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'question': 'What are the key steps to set up and manage access for Amazon Bedrock in an existing AWS account, and how does this process differ from setting up access for a new administrative user?',\n",
       "  'ground_truth': 'For an existing AWS account, the key steps to set up and manage access for Amazon Bedrock are:\\n\\n1. Create an IAM role with the AmazonBedrockFullAccess managed policy.\\n2. Create a custom policy to manage access to Amazon Bedrock models, including marketplace actions like ViewSubscriptions, Unsubscribe, and Subscribe.\\n3. Attach the custom policy to the Amazon Bedrock role.\\n4. Add users to the Amazon Bedrock role and grant them permissions to switch to this role.\\n\\nThis process differs from setting up access for a new administrative user in the following ways:\\n- For new users, you would configure access using the default IAM Identity Center directory.\\n- New administrative users receive a sign-in URL for the AWS access portal.\\n- Existing account setup focuses on creating and managing IAM roles, while new user setup involves creating IAM Identity Center users.\\n- The existing account method provides more granular control over permissions through custom policies, whereas the new user method relies more on predefined access levels within IAM Identity Center.',\n",
       "  'question_type': 'complex',\n",
       "  'contexts': 'Configure user access with the default IAM Identity Center directory in the AWS IAM Identity\\nCenter User Guide.\\nSign in as the user with administrative access\\n• To sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email\\naddress when you created the IAM Identity Center user.\\nFor help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in\\nthe AWS Sign-In User Guide.\\nTo learn more about IAM, see Identity and access management for Amazon Bedrock and the IAM\\nUser Guide.\\nAfter you have created an administrative user, proceed to I already have an AWS account to set up\\npermissions for Amazon Bedrock.\\nI already have an AWS account\\nUse IAM to create a role for with the necessary permissions to use Amazon Bedrock. You can then\\nadd users to this role to grant the permissions.\\nI already have an AWS account 7\\nAmazon Bedrock User Guide\\nTo create an Amazon Bedrock role\\n 1. Create a role with a name of your choice by following the steps at Creating a role to delegate\\npermissions to an IAM user in the IAM User Guide. When you reach the step to attach a policy\\nto the role, attach the AmazonBedrockFullAccess AWS managed policy.\\n2. Create a new policy to allow your role to manage access to Amazon Bedrock models. From the\\nfollowing list, select the link that corresponds to your method of choice and follow the steps.\\nUse the following JSON object as the policy.\\n• Creating IAM policies (console)\\n• Creating IAM policies (AWS CLI)\\n• Creating IAM policies (AWS API)\\n{\\n\"Version\": \"2012-10-17\",\\n\"Statement\": [\\n{\\n\"Sid\": \"MarketplaceBedrock\",\\n\"Effect\": \"Allow\",\\n\"Action\": [\\n\"aws-marketplace:ViewSubscriptions\",\\n\"aws-marketplace:Unsubscribe\",\\n\"aws-marketplace:Subscribe\"\\n],\\n\"Resource\": \"*\"\\n}\\n]\\n}\\n3. Attach the policy that you created in the last step to your Amazon Bedrock role by following\\nthe steps at Adding and removing IAM identity permissions.\\n To add users to the Amazon Bedrock role\\n1. For users to access an IAM role, you must add them to the role. You can add both users in your\\naccount or from other accounts. To grant users permissions to switch to the Amazon Bedrock\\nrole that you created, follow the steps at Granting a user permissions to switch roles and\\nspecify the Amazon Bedrock role as the Resource.\\nI already have an AWS account 8\\nAmazon Bedrock User Guide\\nNote\\nIf you need to create more users in your account so that you can give them access\\nto the Amazon Bedrock role, follow the steps in Creating an IAM user in your AWS\\naccount.\\n2. After you\\'ve granted a user permissions to use the Amazon Bedrock role, provide the user\\nwith role name and ID or alias of the account to which the role belongs. Then, guide the user\\nthrough how to switch to the role by following the instructions at Providing information to the\\nuser.\\nRequest access to an Amazon Bedrock foundation model\\n'},\n",
       " {'question': 'What command lists available foundation models in Amazon Bedrock?',\n",
       "  'ground_truth': 'The command to list available foundation models in Amazon Bedrock is: aws bedrock list-foundation-models --region us-east-1',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': 'This section guides you through trying out some common operations in Amazon Bedrock using the\\nAWS CLI to test that your permissions and authentication are set up properly. Before you run the\\nfollowing examples, you should check that you have fulfilled the following prerequisites:\\nPrerequisites\\n• You have an AWS account and a user or role with authentication set up and the necessary\\npermissions for Amazon Bedrock. Otherwise, follow the steps at Getting started with the API.\\n• You\\'ve requested access to the Amazon Titan Text G1 - Express model. Otherwise, follow the\\nsteps at Request access to an Amazon Bedrock foundation model.\\nRequest access to Amazon Bedrock models 18\\nAmazon Bedrock User Guide\\n• You\\'ve installed and set up authentication for the AWS CLI. To install the CLI, follow the steps at\\nInstall or update to the latest version of the AWS CLI. Verify that you\\'ve set up your credentials to\\nuse the CLI by following the steps at Get credentials to grant programmatic access.\\n Test that your permissions are set up properly for Amazon Bedrock, using a user or role that you set\\nup with the proper permissions.\\nTopics\\n• List the foundation models that Amazon Bedrock has to offer\\n• Submit a text prompt to a model and generate a text response with InvokeModel\\n• Submit a text prompt to a model and generate a text response with Converse\\nList the foundation models that Amazon Bedrock has to offer\\nThe following example runs the ListFoundationModels operation using an Amazon Bedrock\\nendpoint. ListFoundationModels lists the foundation models (FMs) that are available in\\nAmazon Bedrock in your region. In a terminal, run the following command:\\naws bedrock list-foundation-models --region us-east-1\\nIf the command is successful, the response returns a list of foundation models that are available in\\nAmazon Bedrock.\\nSubmit a text prompt to a model and generate a text response with InvokeModel\\nThe following example runs the InvokeModel operation using an Amazon Bedrock runtime\\n endpoint. InvokeModel lets you submit a prompt to generate a model response. In a terminal, run\\nthe following command:\\naws bedrock-runtime invoke-model \\\\\\n--model-id amazon.titan-text-express-v1 \\\\\\n--body \\'{\"inputText\": \"Describe the purpose of a \\\\\"hello world\\\\\" program in one line.\",\\n\"textGenerationConfig\" : {\"maxTokenCount\": 512, \"temperature\": 0.5, \"topP\": 0.9}}\\' \\\\\\n--cli-binary-format raw-in-base64-out \\\\\\ninvoke-model-output-text.txt\\nRun examples with the AWS CLI 19\\nAmazon Bedrock User Guide\\nIf the command is successful, the response generated by the model is written to the invoke-\\nmodel-output-text.txt file. The text response is returned in the outputText field, alongside\\naccompanying information.\\nSubmit a text prompt to a model and generate a text response with Converse\\nThe following example runs the Converse operation using an Amazon Bedrock runtime endpoint.\\nConverse lets you submit a prompt to generate a model response. We recommend using\\n'},\n",
       " {'question': \"How does Amazon Bedrock's pricing model work, and what factors should a developer consider when estimating costs for a project that involves heavy use of foundation models?\",\n",
       "  'ground_truth': \"Amazon Bedrock's pricing model is based on the volume of input and output tokens processed during model inference. Developers should consider several factors when estimating costs:\\n\\n1. Model selection: Different foundation models have varying pricing structures.\\n2. Usage volume: Costs are directly related to the number of tokens processed.\\n3. Provisioned Throughput: Purchasing this can affect pricing and should be considered for high-volume applications.\\n4. Input vs. Output tokens: Pricing may differ for input and output tokens.\\n5. Model access: Developers must request access to foundation models before use, which may impact project timelines.\\n6. Use case complexity: More complex prompts or tasks may require more tokens, increasing costs.\\n\\nTo accurately estimate costs, developers should review the specific pricing for each model on the Model providers page in the Amazon Bedrock console, consider their application's expected usage patterns, and potentially explore Provisioned Throughput options for high-volume scenarios. They should also factor in the potential need for multiple model types if their project requires varied AI capabilities (text generation, image generation, embeddings, etc.).\",\n",
       "  'question_type': 'complex',\n",
       "  'contexts': \"How do I get started with Amazon Bedrock? 2\\nAmazon Bedrock User Guide\\n4. Read the documentation for the features that you want to include in your application.\\nAmazon Bedrock pricing\\nWhen you sign up for AWS, your AWS account is automatically signed up for all services in AWS,\\nincluding Amazon Bedrock. However, you are charged only for the services that you use.\\nFor information about pricing for different Amazon Bedrock resources, see Amazon Bedrock\\nPricing.\\nTo see your bill, go to the Billing and Cost Management Dashboard in the AWS Billing and Cost\\nManagement console. To learn more about AWS account billing, see the AWS Billing User Guide. If\\nyou have questions concerning AWS billing and AWS accounts, contact AWS Support.\\nWith Amazon Bedrock, you pay to run inference on any of the third-party foundation models.\\nPricing is based on the volume of input tokens and output tokens, and on whether you have\\n purchased Provisioned Throughput for the model. For more information, see the Model providers\\npage in the Amazon Bedrock console. For each model, pricing is listed following the model version.\\nFor more information about purchasing Provisioned Throughput, see Increase model invocation\\ncapacity with Provisioned Throughput in Amazon Bedrock.\\nKey terminology\\nThis chapter explains terminology that will help you understand what Amazon Bedrock offers\\nand how it works. Read through the following list to understand generative AI terminology and\\nAmazon Bedrock's fundamental capabilities:\\n• Foundation model (FM) – An AI model with a large number of parameters and trained on a\\nmassive amount of diverse data. A foundation model can generate a variety of responses for a\\nwide range of use cases. Foundation models can generate text or image, and can also convert\\ninput into embeddings. Before you can use an Amazon Bedrock foundation model, you must\\n request access. For more information about foundation models, see Supported foundation\\nmodels in Amazon Bedrock.\\n• Base model – A foundation model that is packaged by a provider and ready to use. Amazon\\nBedrock offers a variety of industry-leading foundation models from leading providers. For more\\ninformation, see Supported foundation models in Amazon Bedrock.\\nAmazon Bedrock pricing 3\\nAmazon Bedrock User Guide\\n• Model inference – The process of a foundation model generating an output (response) from a\\ngiven input (prompt). For more information, see Submit prompts and generate responses with\\nmodel inference.\\n• Prompt – An input provided to a model to guide it to generate an appropriate response or\\noutput for the input. For example, a text prompt can consist of a single line for the model\\nto respond to, or it can detail instructions or a task for the model to perform. The prompt\\ncan contain the context of the task, examples of outputs, or text for a model to use in its\\n\"},\n",
       " {'question': 'Which regions support the Cohere Command model?',\n",
       "  'ground_truth': 'The Cohere Command model is supported in US East (N. Virginia) and US West (Oregon) regions.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': 'East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nR\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nEnglish\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nMultiling\\nual\\nCohere\\nNo No Yes No No Yes No No No No Yes Yes No No No No No\\nRerank\\n3.5\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n8B\\nInstruct\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n70B\\nInstruct\\nModel support by Region 76\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nMeta\\nYes* Yes* Yes No No No No No No No No No No No No No No\\nLlama\\n3.1\\n8B\\nInstruct\\nMeta\\nYes* Yes* Yes No No No No No No No No No No No No No No\\nLlama\\n3.1\\n70B\\nInstruct\\nMeta\\nNo Yes* Yes No No No No No No No No No No No No No No\\nLlama\\n3.1\\n405B\\nInstruct\\nMeta\\nYes* Yes* Yes* No No No No No No No No Yes* No GatedNo Yes* No\\nLlama\\n3.2\\n1B\\nInstruct\\nMeta\\nYes* Yes* Yes* No No No No No No No No Yes* No GatedNo Yes* No\\nLlama\\n3.2\\n3B\\nInstruct\\nModel support by Region 77\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n (N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nMeta\\nYes* Yes* Yes* No No No No No No No No No No No No No No\\nLlama\\n3.2\\n11B\\nInstruct\\nMeta\\nYes* Yes* Yes* No No No No No No No No No No No No No No\\nLlama\\n3.2\\n90B\\nInstruct\\nMeta\\nYes* Yes Yes* No No No No No No No No No No No No No No\\nLlama\\n3.3\\n70B\\nInstruct\\nMistral\\nYes No Yes No No No No Yes No Yes Yes No No GatedYes Yes Yes\\nAI\\nMistral\\n7B\\nInstruct\\nMistral\\nYes No Yes No No No No Yes No Yes Yes No No GatedYes Yes Yes\\nAI\\nMistral\\nLarge\\n(24.02)\\nModel support by Region 78\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nMistral\\nNo No Yes No No No No No No No No No No No No No No\\n'},\n",
       " {'question': 'What are the key steps and security measures involved in setting up a new AWS account, and why is it crucial to differentiate between root user and administrative access?',\n",
       "  'ground_truth': \"Setting up a new AWS account involves several key steps and security measures. First, you sign up at https://portal.aws.amazon.com/billing/signup, which includes phone verification. This process creates an AWS account root user. However, it's crucial to differentiate between root user and administrative access for security reasons. As a best practice, you should only use the root user for tasks that specifically require root access. Instead, you should create a separate user with administrative privileges for day-to-day management. Additionally, it's essential to secure the root user by enabling multi-factor authentication (MFA). This adds an extra layer of security to prevent unauthorized access. Finally, for programmatic access to AWS services outside the console, you need to obtain the appropriate credentials, which vary depending on the type of user (IAM user, etc.) and the interface you're using (AWS CLI, SDKs, or APIs). These steps collectively ensure a secure foundation for your AWS account, minimizing the risk of unauthorized access and following the principle of least privilege.\",\n",
       "  'question_type': 'complex',\n",
       "  'contexts': \"sections pertain to you, expand them and follow the instructions. Otherwise, proceed through the\\nremaining sections.\\nI'm new to AWS\\nIf you do not have an AWS account, complete the following steps to create one.\\nTo sign up for an AWS account\\n1. Open https://portal.aws.amazon.com/billing/signup.\\n2. Follow the online instructions.\\nPart of the sign-up procedure involves receiving a phone call and entering a verification code\\non the phone keypad.\\nWhen you sign up for an AWS account, an AWS account root user is created. The root user\\nhas access to all AWS services and resources in the account. As a security best practice, assign\\nadministrative access to a user, and use only the root user to perform tasks that require root\\nuser access.\\nGetting started with the API 12\\nAmazon Bedrock User Guide\\nAWS sends you a confirmation email after the sign-up process isn complete. At any time, you can\\nview your current account activity and manage your account by going to https://aws.amazon.com/\\n and choosing My Account.\\nSecure your AWS account root user\\n1. Sign in to the AWS Management Console as the account owner by choosing Root user and\\nentering your AWS account email address. On the next page, enter your password.\\nFor help signing in by using root user, see Signing in as the root user in the AWS Sign-In User\\nGuide.\\n2. Turn on multi-factor authentication (MFA) for your root user.\\nFor instructions, see Enable a virtual MFA device for your AWS account root user (console) in\\nthe IAM User Guide.\\nI need to install the AWS CLI or an AWS SDK\\nTo install the AWS CLI, follow the steps at Install or update to the latest version of the AWS CLI.\\nTo install an AWS SDK, select the tab that corresponds to the programming language that you\\nwant to use at Tools to Build on AWS. AWS software development kits (SDKs) are available\\nfor many popular programming languages. Each SDK provides an API, code examples, and\\n documentation that make it easier for developers to build applications in their preferred language.\\nSDKs automatically perform useful tasks for you, such as:\\n• Cryptographically sign your service requests\\n• Retry requests\\n• Handle error responses\\nGet credentials to grant programmatic access\\nUsers need programmatic access if they want to interact with AWS outside of the AWS\\nManagement Console. The way to grant programmatic access depends on the type of user that's\\naccessing AWS.\\nTo grant users programmatic access, choose one of the following options.\\nGet credentials to grant programmatic access 13\\nAmazon Bedrock User Guide\\nWhich principal needs To By\\nprogrammatic access?\\nIAM users Limit the duration of long- Following the instructions for\\nterm credentials to sign the interface that you want to\\nprogrammatic requests to the use.\\nAWS CLI, AWS SDKs, or AWS\\n• For the AWS CLI, see\\nAPIs.\\nAuthenticating using IAM\\nuser credentials in the AWS\\nCommand Line Interface\\nUser Guide.\\n\"},\n",
       " {'question': 'Which region supports the Stability AI SDXL 1.0 model?',\n",
       "  'ground_truth': 'The Stability AI SDXL 1.0 model is supported in the US East (N. Virginia) and US West (Oregon) regions.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': 'No No Yes No No No No No No No No No No No No No No\\nAI\\nStable\\nImage\\nUltra\\n1.0\\nStability\\nNo No Yes No No No No No No No No No No No No No No\\nAI\\nStable\\nImage\\nUltra\\n1.0\\nModel support by Region 80\\nAmazon Bedrock User Guide\\nNote\\n* Some models are accessible in some Regions only through cross-region inference. To learn\\nmore about cross-region inference, see Increase throughput with cross-region inference and\\nSupported Regions and models for inference profiles.\\nThe following table shows Region support for models that have a target date for deprecation. For\\nmore information, see Model lifecycle.\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJ2\\n Grande\\nInstruct\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJ2\\nJumbo\\nInstruct\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJurassic-\\n2\\nMid\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJurassic-\\nModel support by Region 81\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\n2\\nUltra\\nStability\\nYes No Yes No No No No No No No No No No No No No No\\nAI\\nSDXL\\n1.0\\nTo learn more about Region and model support for specific features, see the following links:\\n• Converse API\\n• Batch inference\\n• Inference profiles\\n• Latency optimization\\n• Prompt management\\n• Prompt management\\n• Prompt optimization\\n• Amazon Bedrock Guardrails\\n• Model evaluation\\n • RAG evaluation\\n• Amazon Bedrock Knowledge Bases\\n• Rerank\\n• Amazon Bedrock Agents\\n• Amazon Bedrock Flows\\n• Model customization\\n• Amazon Bedrock Custom Model Import\\n• Provisioned Throughput\\n• Amazon Bedrock Studio\\nModel support by Region 82'},\n",
       " {'question': \"How does the availability of streaming support and input/output modalities differ between AI21 Labs' Jurassic models and Amazon's Nova models in Amazon Bedrock, and what implications might this have for developers choosing between them?\",\n",
       "  'ground_truth': \"The AI21 Labs' Jurassic models (Jamba 1.5 Large, Jamba 1.5 Mini, and Jamba-Instruct) and Amazon's Nova models (Nova and Nova Lite) have distinct differences in streaming support and input/output modalities:\\n\\n1. Streaming support:\\n   - AI21 Labs models: All support streaming\\n   - Amazon Nova: Does not support streaming\\n   - Amazon Nova Lite: Supports streaming\\n\\n2. Input modalities:\\n   - AI21 Labs models: Text only\\n   - Amazon Nova: Text and Image\\n   - Amazon Nova Lite: Text, Image, and Video\\n\\n3. Output modalities:\\n   - AI21 Labs models: Text and Chat\\n   - Amazon Nova: Image only\\n   - Amazon Nova Lite: Text\\n\\nThese differences have several implications for developers:\\n\\n1. Real-time applications: AI21 Labs models and Nova Lite are more suitable for real-time, interactive applications due to their streaming support.\\n\\n2. Multimodal capabilities: Amazon's Nova models offer more versatility in handling different types of input data, making them better suited for applications that need to process images or videos alongside text.\\n\\n3. Output format: AI21 Labs models are more appropriate for text-generation tasks, while Nova is specialized for image generation. Nova Lite offers a balance with text output capabilities.\\n\\n4. Use case specificity: Developers need to carefully consider their application requirements when choosing between these models, as they have distinct strengths in different areas (e.g., text processing vs. image processing).\\n\\n5. API integration: The differences in input/output modalities and streaming support may require different API integration approaches for each model family.\\n\\nBy understanding these differences, developers can select the most appropriate model for their specific use case, considering factors such as real-time requirements, input data types, and desired output formats.\",\n",
       "  'question_type': 'complex',\n",
       "  'contexts': \"• Model support by AWS Region in Amazon Bedrock\\n• Feature support by AWS Region in Amazon Bedrock\\n• Model support by feature\\n• Inference request parameters and response fields for foundation models\\n• Custom model hyperparameters\\n• Model lifecycle\\n36\\nAmazon Bedrock User Guide\\nGet information about foundation models\\nIn the Amazon Bedrock console, you can find overarching information about Amazon Bedrock\\nfoundation model providers and the models they provide in the Providers and Base models\\nsections.\\nUse the API to retrieve information about Amazon Bedrock foundation model, including its\\nARN, model ID, modalities and features it supports, and whether it is deprecated or not, in a\\nFoundationModelSummary object.\\n• To return information about all the foundation models that Amazon Bedrock provides, send a\\nListFoundationModels request.\\nNote\\nThe response also returns model IDs that aren't in the base model ID or base model IDs\\n for Provisioned Throughput charts. These model IDs are deprecated or for backwards\\ncompability.\\n• To return information about a specific foundation model, send a GetFoundationModel request,\\nspecifying the model ID.\\nChoose a tab to see code examples in an interface or language.\\nAWS CLI\\nList the Amazon Bedrock foundation models.\\naws bedrock list-foundation-models\\nGet information about Anthropic Claude v2.\\naws bedrock get-foundation-model --model-identifier anthropic.claude-v2\\nPython\\nList the Amazon Bedrock foundation models.\\nimport boto3\\nbedrock = boto3.client(service_name='bedrock')\\nGet model information 37\\nAmazon Bedrock User Guide\\nbedrock.list_foundation_models()\\nGet information about Anthropic Claude v2.\\nimport boto3\\nbedrock = boto3.client(service_name='bedrock')\\nbedrock.get_foundation_model(modelIdentifier='anthropic.claude-v2')\\nSupported foundation models in Amazon Bedrock\\nAmazon Bedrock supports foundation models (FMs) from multiple providers.\\n The following table lists each model alongside the ID that you can use to make on-demand API\\ncalls, the AWS Regions that support it, its capabilities, and links to relevant documentation:\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAI21 Jamba ai21.jamb us- Text Text, Yes Link N/A\\nLabs 1.5 a-1-5- east-1 Chat\\nLarge large-\\nv1:0\\nAI21 Jamba ai21.jamb us- Text Text, Yes Link N/A\\nLabs 1.5 Mini a-1-5- east-1 Chat\\nmini-\\nv1:0\\nAI21 Jamba- ai21.jamb us- Text Text, Yes Link N/A\\nLabs Instruct a- east-1 Chat\\ninstruc\\nt-v1:0\\nAmazon Nova amazon.no us- Text, Image No Link Link\\nCanvas va- east-1 Image\\nSupported foundation models 38\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\ncanvas-\\nv1:0\\nAmazon Nova amazon.no us- Text, Text Yes Link Link\\nLite va-lite- east-1 Image,\\nv1:0 Video\\nus-\\neast-2*\\n\"},\n",
       " {'question': 'What is a token in the context of foundation models?',\n",
       "  'ground_truth': 'A token is a sequence of characters that a model can interpret or predict as a single unit of meaning. It could be a word, part of a word with grammatical meaning, a punctuation mark, or a common phrase.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': 'request access. For more information about foundation models, see Supported foundation\\nmodels in Amazon Bedrock.\\n• Base model – A foundation model that is packaged by a provider and ready to use. Amazon\\nBedrock offers a variety of industry-leading foundation models from leading providers. For more\\ninformation, see Supported foundation models in Amazon Bedrock.\\nAmazon Bedrock pricing 3\\nAmazon Bedrock User Guide\\n• Model inference – The process of a foundation model generating an output (response) from a\\ngiven input (prompt). For more information, see Submit prompts and generate responses with\\nmodel inference.\\n• Prompt – An input provided to a model to guide it to generate an appropriate response or\\noutput for the input. For example, a text prompt can consist of a single line for the model\\nto respond to, or it can detail instructions or a task for the model to perform. The prompt\\ncan contain the context of the task, examples of outputs, or text for a model to use in its\\n response. Prompts can be used to carry out tasks such as classification, question answering, code\\ngeneration, creative writing, and more. For more information, see Prompt engineering concepts.\\n• Token – A sequence of characters that a model can interpret or predict as a single unit of\\nmeaning. For example, with text models, a token could correspond not just to a word, but also to\\na part of a word with grammatical meaning (such as \"-ed\"), a punctuation mark (such as \"?\"), or a\\ncommon phrase (such as \"a lot\").\\n• Model parameters – Values that define a model and its behavior in interpreting input and\\ngenerating responses. Model parameters are controlled and updated by providers. You can also\\nupdate model parameters to create a new model through the process of model customization.\\n• Inference parameters – Values that can be adjusted during model inference to influence a\\nresponse. Inference parameters can affect how varied responses are and can also limit the length\\n of a response or the occurrence of specified sequences. For more information and definitions of\\nspecific inference parameters, see Influence response generation with inference parameters.\\n• Playground – A user-friendly graphical interface in the AWS Management Console in which\\nyou can experiment with running model inference to familiarize yourself with Amazon Bedrock.\\nUse the playground to test out the effects of different models, configurations, and inference\\nparameters on the responses generated for different prompts that you enter. For more\\ninformation, see Generate responses in the console using playgrounds.\\n• Embedding – The process of condensing information by transforming input into a vector\\nof numerical values, known as the embeddings, in order to compare the similarity between\\ndifferent objects by using a shared numerical representation. For example, sentences can be\\ncompared to determine the similarity in meaning, images can be compared to determine visual\\n'},\n",
       " {'question': 'How does Amazon Bedrock manage access to different foundation models, and what unique considerations exist for Amazon Titan, Mistral AI, and Meta Llama 3 Instruct models?',\n",
       "  'ground_truth': 'Amazon Bedrock manages access to foundation models through a request-based system. Users must request access to specific models before using them, and this access is granted at the AWS account level. However, Amazon Titan, Mistral AI, and Meta Llama 3 Instruct models are exceptions to this rule. These models are always accessible, but their usage can be restricted using IAM policies. To control access to other models, administrators can use the Amazon Bedrock console to modify model access, selecting or deselecting models as needed. Additionally, IAM policies can be used to control who can request access to models, using the \"aws-marketplace:Subscribe\" action and specifying product IDs in the policy conditions.',\n",
       "  'question_type': 'complex',\n",
       "  'contexts': 'Anthropic Claude Instant b0eb9475-3a2c-43d1-94d3-56756fd43737\\nAnthropic Claude 3 Sonnet prod-6dw3qvchef7zy\\nAnthropic Claude 3.5 Sonnet prod-m5ilt4siql27k\\nAnthropic Claude 3.5 Sonnet v2 prod-cx7ovbu5wex7g\\nAnthropic Claude 3 Haiku prod-ozonys2hmmpeu\\nAnthropic Claude 3.5 Haiku prod-5oba7y7jpji56\\nAnthropic Claude 3 Opus prod-fm3feywmwerog\\nGrant permissions to request access to foundation models 30\\nAmazon Bedrock User Guide\\nModel Product ID\\nCohere Command a61c46fe-1747-41aa-9af0-2e0ae8a9ce05\\nCohere Command Light 216b69fd-07d5-4c7b-866b-936456d68311\\nCohere Command R prod-tukx4z3hrewle\\nCohere Command R+ prod-nb4wqmplze2pm\\nCohere Embed (English) b7568428-a1ab-46d8-bab3-37def50f6f6a\\nCohere Embed (Multilingual) 38e55671-c3fe-4a44-9783-3584906e7cad\\nCohere Rerank 3.5 prod-2o5bej62oxkbi\\nStable Diffusion XL 1.0 prod-2lvuzn4iy6n6o\\nStable Image Core 1.0 prod-eacdrmv7zfc5e\\nStable Diffusion 3 Large 1.0 prod-cqfmszl26sxu4\\nStable Image Ultra 1.0 prod-7boen2z2wnxrg\\n{\\n\"Version\": \"2012-10-17\",\\n \"Statement\": [\\n{\\n\"Effect\": \"Allow|Deny\",\\n\"Action\": [\\n\"aws-marketplace:Subscribe\"\\n],\\n\"Resource\": \"*\",\\n\"Condition\": {\\n\"ForAnyValue:StringEquals\": {\\n\"aws-marketplace:ProductId\": [\\nmodel-product-id-1,\\nmodel-product-id-2,\\n...\\n]\\n}\\nGrant permissions to request access to foundation models 31\\nAmazon Bedrock User Guide\\n}\\n},\\n{\\n\"Effect\": \"Allow|Deny\",\\n\"Action\": [\\n\"aws-marketplace:Unsubscribe\"\\n\"aws-marketplace:ViewSubscriptions\"\\n],\\n\"Resource\": \"*\"\\n}\\n]\\n}\\nTo see an example policy, refer to Allow access to third-party model subscriptions.\\nAdd or remove access to Amazon Bedrock foundation models\\nBefore you can use a foundation model in Amazon Bedrock, you must request access to it. If you no\\nlonger need access to a model, you can remove access from it.\\nNote\\nYou can\\'t remove request access from the Amazon Titan, Mistral AI, and Meta Llama 3\\nInstruct models. You can prevent users from making inference calls to these models by\\n using an IAM policy and specifying the model ID. For more information, see Deny access for\\ninference of foundation models.\\nOnce access is provided to a model, it is available for all users in the AWS account.\\nTo add or remove access to foundation models\\n1. Make sure you have permissions to request access, or modify access, to Amazon Bedrock\\nfoundation models.\\n2. Sign into the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/.\\n3. In the left navigation pane, under Bedrock configurations, choose Model access.\\n4. On the Model access page, choose Modify model access.\\n5. Select the models that you want the account to have access to and unselect the models that\\nyou don\\'t want the account to have access to. You have the following options:\\nAdd or remove access to foundation models 32\\nAmazon Bedrock User Guide\\nBe sure to review the End User License Agreement (EULA) for terms and conditions of using a\\nmodel before requesting access to it.\\n'},\n",
       " {'question': 'Which Claude model supports both text and image input?',\n",
       "  'ground_truth': 'Claude 3 Haiku, Claude 3 Opus, Claude 3 Sonnet, Claude 3.5 Haiku, Claude 3.5 Sonnet, and Claude 3.5 Sonnet v2 all support both text and image input according to the information provided.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': 'l-1\\nAnthropic Claude anthropic us- Text Text, Yes Link N/A\\n2 .claude- east-1 Chat\\nv2\\nus-\\nwest-2\\nap-\\nsouthe\\nast-1\\n(Gated)\\neu-\\ncentra\\nl-1\\nSupported foundation models 48\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n3 Haiku .claude-3 east-1 Image Chat\\n-\\nus-\\nhaiku-20\\neast-2*\\n240307-\\nv1:0\\nus-\\nwest-2\\nus-gov-\\neast-1*\\nus-gov-\\nwest-1\\nap-\\nnorthe\\nast-1\\nap-\\nnorthe\\nast-2\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-1\\n(Gated)\\nap-\\nsouthe\\nast-1\\n(Gated)\\nSupported foundation models 49\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\ncentra\\nl-1\\neu-\\ncentra\\nl-2\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n 3 Opus .claude-3 east-1* Image Chat\\n-\\nus-\\nopus-202\\nwest-2\\n40229-\\nv1:0\\nSupported foundation models 50\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n3 .claude-3 east-1 Image Chat\\nSonnet -\\nus-\\nsonnet-2\\nwest-2\\n0240229-\\nv1:0\\nap-\\nnorthe\\nast-1*\\nap-\\nnorthe\\nast-2*\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-1\\n(Gated)*\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\ncentra\\nl-1\\nSupported foundation models 51\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n3.5 .claude-3 east-1* Image Chat\\nHaiku -5-\\nus-\\nhaiku-\\neast-2*\\n20241022-\\nv1:0\\nus-\\nwest-2\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n 3.5 .claude-3 east-1* Image Chat\\nSonnet -5-\\nus-\\nv2 sonnet\\nwest-2\\n-20241022\\n-v2:0\\nSupported foundation models 52\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n3.5 .claude-3 east-1 Image Chat\\nSonnet -5-\\nus-\\nsonnet\\neast-2*\\n-20240620\\n-v1:0\\nus-\\nwest-2\\nus-gov-\\neast-1*\\nus-gov-\\nwest-1\\nap-\\nnorthe\\nast-1\\nap-\\nnorthe\\nast-2\\nap-\\nsouth-\\n1*\\nap-\\nsouthe\\nast-1\\n(Gated)\\nap-\\nsouthe\\nSupported foundation models 53\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nast-1\\n(Gated)\\nap-\\nsouthe\\nast-2*\\neu-\\ncentra\\nl-1\\neu-\\ncentra\\nl-2\\neu-\\nwest-1\\n(Gated)*\\neu-\\nwest-3*\\nSupported foundation models 54\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\n'},\n",
       " {'question': \"How does Amazon Bedrock's pricing structure work, and what factors should a developer consider when estimating costs for a project that involves heavy use of foundation models?\",\n",
       "  'ground_truth': \"Amazon Bedrock's pricing structure is based on the volume of input and output tokens processed during model inference. Developers should consider several factors when estimating costs:\\n\\n1. Model selection: Different foundation models have varying pricing rates.\\n2. Usage volume: Costs are directly related to the amount of data processed.\\n3. Provisioned Throughput: Purchasing this option can affect pricing.\\n4. Input vs. Output tokens: Pricing distinguishes between these, so the ratio in your application matters.\\n5. Model access: Before using a model, access must be requested, which may impact project timeline and costs.\\n6. Use case complexity: More complex prompts or tasks may require more tokens, increasing costs.\\n\\nTo manage and estimate costs effectively, developers should:\\n- Regularly check the Billing and Cost Management Dashboard\\n- Review the specific pricing for each model on the Model providers page in the Amazon Bedrock console\\n- Consider purchasing Provisioned Throughput for high-volume applications\\n- Optimize prompts to reduce unnecessary token usage\\n\\nBy carefully considering these factors, developers can better estimate and control costs for projects heavily utilizing foundation models in Amazon Bedrock.\",\n",
       "  'question_type': 'complex',\n",
       "  'contexts': \"How do I get started with Amazon Bedrock? 2\\nAmazon Bedrock User Guide\\n4. Read the documentation for the features that you want to include in your application.\\nAmazon Bedrock pricing\\nWhen you sign up for AWS, your AWS account is automatically signed up for all services in AWS,\\nincluding Amazon Bedrock. However, you are charged only for the services that you use.\\nFor information about pricing for different Amazon Bedrock resources, see Amazon Bedrock\\nPricing.\\nTo see your bill, go to the Billing and Cost Management Dashboard in the AWS Billing and Cost\\nManagement console. To learn more about AWS account billing, see the AWS Billing User Guide. If\\nyou have questions concerning AWS billing and AWS accounts, contact AWS Support.\\nWith Amazon Bedrock, you pay to run inference on any of the third-party foundation models.\\nPricing is based on the volume of input tokens and output tokens, and on whether you have\\n purchased Provisioned Throughput for the model. For more information, see the Model providers\\npage in the Amazon Bedrock console. For each model, pricing is listed following the model version.\\nFor more information about purchasing Provisioned Throughput, see Increase model invocation\\ncapacity with Provisioned Throughput in Amazon Bedrock.\\nKey terminology\\nThis chapter explains terminology that will help you understand what Amazon Bedrock offers\\nand how it works. Read through the following list to understand generative AI terminology and\\nAmazon Bedrock's fundamental capabilities:\\n• Foundation model (FM) – An AI model with a large number of parameters and trained on a\\nmassive amount of diverse data. A foundation model can generate a variety of responses for a\\nwide range of use cases. Foundation models can generate text or image, and can also convert\\ninput into embeddings. Before you can use an Amazon Bedrock foundation model, you must\\n request access. For more information about foundation models, see Supported foundation\\nmodels in Amazon Bedrock.\\n• Base model – A foundation model that is packaged by a provider and ready to use. Amazon\\nBedrock offers a variety of industry-leading foundation models from leading providers. For more\\ninformation, see Supported foundation models in Amazon Bedrock.\\nAmazon Bedrock pricing 3\\nAmazon Bedrock User Guide\\n• Model inference – The process of a foundation model generating an output (response) from a\\ngiven input (prompt). For more information, see Submit prompts and generate responses with\\nmodel inference.\\n• Prompt – An input provided to a model to guide it to generate an appropriate response or\\noutput for the input. For example, a text prompt can consist of a single line for the model\\nto respond to, or it can detail instructions or a task for the model to perform. The prompt\\ncan contain the context of the task, examples of outputs, or text for a model to use in its\\n\"},\n",
       " {'question': 'Which AWS Region supports all listed Amazon Titan models?',\n",
       "  'ground_truth': 'US East (N. Virginia) supports all listed Amazon Titan models, including Titan Embeddings, Titan Image Generator, Titan Multimodal Embeddings, Titan Text Embeddings, and Titan Text Express.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': 'Labs 2 Ultra ultra-v1 east-1 Chat\\nStability SDXL stability us- Text, Image No Link N/A\\nAI 1.0 .stable- east-1 Image\\nd\\nus-\\niffusion-\\nwest-2\\nxl-v1\\nSupported foundation models 70\\nAmazon Bedrock User Guide\\nModel support by AWS Region in Amazon Bedrock\\nFor a list of AWS Regions that support Amazon Bedrock, see Amazon Bedrock endpoints and\\nquotas. Amazon Bedrock foundation models differ in their regional support.\\nThe following table shows Region support by model:\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJamba\\n1.5\\nLarge\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJamba\\n1.5\\nMini\\nAI21\\n Yes No No No No No No No No No No No No No No No No\\nLabs\\nJamba-\\nIns\\ntruct\\nAmazon\\nYes No No No No No No No No No No No No No No No No\\nNova\\nCanvas\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nLite\\nModel support by Region 71\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nMicro\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nPro\\nAmazon\\nYes No No No No No No No No No No No No No No No No\\nNova\\nReel\\nAmazon\\nNo No Yes No No Yes No No No No Yes Yes No No No No No\\nRerank\\n1.0\\nAmazon\\nYes No Yes No No Yes No No No No No Yes No No No No No\\nTitan\\nEmbedding\\ns\\nG1\\n-\\nText\\nAmazon\\n Yes No Yes No No No No No No No No No No No No No No\\nTitan\\nImage\\nGenerator\\nG1\\nv2\\nModel support by Region 72\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAmazon\\nYes No Yes No No No No Yes No No No No No GatedYes No No\\nTitan\\nImage\\nGenerator\\nG1\\nAmazon\\nYes No Yes No No No No Yes No Yes Yes Yes No GatedYes Yes Yes\\nTitan\\nMultimoda\\nl\\nEmbedding\\ns\\nG1\\nAmazon\\nYes Yes Yes Yes Yes Yes Yes Yes No Yes Yes Yes Yes No Yes Yes Yes\\nTitan\\nText\\nEmbedding\\ns\\nV2\\nAmazon\\nYes No Yes No Yes Yes No Yes No Yes Yes Yes No GatedYes Yes Yes\\nTitan\\nText\\nG1\\n-\\nExpress\\nModel support by Region 73\\nAmazon Bedrock User Guide\\n'},\n",
       " {'question': 'What are the key steps to set up and manage access for Amazon Bedrock in an existing AWS account, and how does this process differ from setting up access with IAM Identity Center?',\n",
       "  'ground_truth': \"To set up and manage access for Amazon Bedrock in an existing AWS account, the key steps are:\\n\\n1. Create an IAM role with the AmazonBedrockFullAccess managed policy.\\n2. Create a custom policy to manage access to Amazon Bedrock models, including marketplace actions like ViewSubscriptions, Unsubscribe, and Subscribe.\\n3. Attach the custom policy to the Amazon Bedrock role.\\n4. Add users to the Amazon Bedrock role and grant them permissions to switch to this role.\\n\\nThis process differs from setting up access with IAM Identity Center in several ways:\\n1. It uses traditional IAM roles and policies instead of the centralized identity management provided by IAM Identity Center.\\n2. Users need to switch to the specific Amazon Bedrock role to access the service, rather than using a single sign-on process.\\n3. The setup requires more manual steps, including creating custom policies and managing role assignments, compared to the more streamlined user management in IAM Identity Center.\\n4. There's no mention of a sign-in URL or access portal, which are typically used with IAM Identity Center for user authentication.\",\n",
       "  'question_type': 'complex',\n",
       "  'contexts': 'Configure user access with the default IAM Identity Center directory in the AWS IAM Identity\\nCenter User Guide.\\nSign in as the user with administrative access\\n• To sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email\\naddress when you created the IAM Identity Center user.\\nFor help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in\\nthe AWS Sign-In User Guide.\\nTo learn more about IAM, see Identity and access management for Amazon Bedrock and the IAM\\nUser Guide.\\nAfter you have created an administrative user, proceed to I already have an AWS account to set up\\npermissions for Amazon Bedrock.\\nI already have an AWS account\\nUse IAM to create a role for with the necessary permissions to use Amazon Bedrock. You can then\\nadd users to this role to grant the permissions.\\nI already have an AWS account 7\\nAmazon Bedrock User Guide\\nTo create an Amazon Bedrock role\\n 1. Create a role with a name of your choice by following the steps at Creating a role to delegate\\npermissions to an IAM user in the IAM User Guide. When you reach the step to attach a policy\\nto the role, attach the AmazonBedrockFullAccess AWS managed policy.\\n2. Create a new policy to allow your role to manage access to Amazon Bedrock models. From the\\nfollowing list, select the link that corresponds to your method of choice and follow the steps.\\nUse the following JSON object as the policy.\\n• Creating IAM policies (console)\\n• Creating IAM policies (AWS CLI)\\n• Creating IAM policies (AWS API)\\n{\\n\"Version\": \"2012-10-17\",\\n\"Statement\": [\\n{\\n\"Sid\": \"MarketplaceBedrock\",\\n\"Effect\": \"Allow\",\\n\"Action\": [\\n\"aws-marketplace:ViewSubscriptions\",\\n\"aws-marketplace:Unsubscribe\",\\n\"aws-marketplace:Subscribe\"\\n],\\n\"Resource\": \"*\"\\n}\\n]\\n}\\n3. Attach the policy that you created in the last step to your Amazon Bedrock role by following\\nthe steps at Adding and removing IAM identity permissions.\\n To add users to the Amazon Bedrock role\\n1. For users to access an IAM role, you must add them to the role. You can add both users in your\\naccount or from other accounts. To grant users permissions to switch to the Amazon Bedrock\\nrole that you created, follow the steps at Granting a user permissions to switch roles and\\nspecify the Amazon Bedrock role as the Resource.\\nI already have an AWS account 8\\nAmazon Bedrock User Guide\\nNote\\nIf you need to create more users in your account so that you can give them access\\nto the Amazon Bedrock role, follow the steps in Creating an IAM user in your AWS\\naccount.\\n2. After you\\'ve granted a user permissions to use the Amazon Bedrock role, provide the user\\nwith role name and ID or alias of the account to which the role belongs. Then, guide the user\\nthrough how to switch to the role by following the instructions at Providing information to the\\nuser.\\nRequest access to an Amazon Bedrock foundation model\\n'},\n",
       " {'question': 'How can you get information about a specific foundation model in Amazon Bedrock?',\n",
       "  'ground_truth': 'You can send a GetFoundationModel request, specifying the model ID.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': \"for Provisioned Throughput charts. These model IDs are deprecated or for backwards\\ncompability.\\n• To return information about a specific foundation model, send a GetFoundationModel request,\\nspecifying the model ID.\\nChoose a tab to see code examples in an interface or language.\\nAWS CLI\\nList the Amazon Bedrock foundation models.\\naws bedrock list-foundation-models\\nGet information about Anthropic Claude v2.\\naws bedrock get-foundation-model --model-identifier anthropic.claude-v2\\nPython\\nList the Amazon Bedrock foundation models.\\nimport boto3\\nbedrock = boto3.client(service_name='bedrock')\\nGet model information 37\\nAmazon Bedrock User Guide\\nbedrock.list_foundation_models()\\nGet information about Anthropic Claude v2.\\nimport boto3\\nbedrock = boto3.client(service_name='bedrock')\\nbedrock.get_foundation_model(modelIdentifier='anthropic.claude-v2')\\nSupported foundation models in Amazon Bedrock\\nAmazon Bedrock supports foundation models (FMs) from multiple providers.\\n The following table lists each model alongside the ID that you can use to make on-demand API\\ncalls, the AWS Regions that support it, its capabilities, and links to relevant documentation:\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAI21 Jamba ai21.jamb us- Text Text, Yes Link N/A\\nLabs 1.5 a-1-5- east-1 Chat\\nLarge large-\\nv1:0\\nAI21 Jamba ai21.jamb us- Text Text, Yes Link N/A\\nLabs 1.5 Mini a-1-5- east-1 Chat\\nmini-\\nv1:0\\nAI21 Jamba- ai21.jamb us- Text Text, Yes Link N/A\\nLabs Instruct a- east-1 Chat\\ninstruc\\nt-v1:0\\nAmazon Nova amazon.no us- Text, Image No Link Link\\nCanvas va- east-1 Image\\nSupported foundation models 38\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\ncanvas-\\nv1:0\\nAmazon Nova amazon.no us- Text, Text Yes Link Link\\nLite va-lite- east-1 Image,\\nv1:0 Video\\nus-\\neast-2*\\n us-\\nwest-2*\\nAmazon Nova amazon.no us- Text Text Yes Link Link\\nMicro va- east-1\\nmicro-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2*\\nAmazon Nova amazon.no us- Text, Text Yes Link Link\\nPro va-pro- east-1 Image,\\nv1:0 Video\\nus-\\neast-2*\\nus-\\nwest-2*\\nAmazon Nova amazon.no us- Text, Video No Link Link\\nReel va-reel- east-1 Image\\nv1:0\\nSupported foundation models 39\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAmazon Rerank amazon.re us- Text Text No N/A N/A\\n1.0 rank- west-2\\nv1:0\\nap-\\nnorthe\\nast-1\\nca-\\ncentra\\nl-1\\neu-\\ncentra\\nl-1\\nAmazon Titan amazon.ti us- Text EmbeddingNo Link N/A\\nEmbeddingt an- east-1\\ns G1 - embed-\\nus-\\nText text-v1\\nwest-2\\nap-\\nnorthe\\nast-1\\neu-\\ncentra\\nl-1\\nAmazon Titan amazon.ti us- Text, Image No Link Link\\nImage tan- east-1 Image\\nGenerator image-\\nus-\\nG1 v2 generato\\nwest-2\\nr-v2:0\\nSupported foundation models 40\\nAmazon Bedrock User Guide\\n\"},\n",
       " {'question': 'Which AI model provider offers the most comprehensive regional coverage, and how does its availability compare to other providers in key global markets like Asia Pacific and Europe?',\n",
       "  'ground_truth': 'Based on the provided information, Anthropic\\'s Claude 3.5 Sonnet v2 offers the most comprehensive regional coverage among the listed AI models. It is available in most regions, including US East, US West, Asia Pacific (Tokyo, Seoul, Mumbai, Singapore, Sydney), and Europe (Frankfurt, Ireland, London, Paris). \\n\\nComparing it to other providers:\\n1. In Asia Pacific: Claude 3.5 Sonnet v2 is available in all listed Asian regions, while most other models have limited or no presence. For example, Cohere\\'s models are mostly unavailable in Asia, and Meta\\'s Llama models are only available in some regions.\\n\\n2. In Europe: Claude 3.5 Sonnet v2 is available in all listed European regions, whereas many other models have limited availability. For instance, Cohere\\'s Command models are not available in Europe, and Meta\\'s Llama models have limited availability, with only some versions available in certain European regions.\\n\\n3. Global presence: Claude 3.5 Sonnet v2 is also available in other key markets like Canada Central and South America (São Paulo), where many other models are not present.\\n\\nIt\\'s worth noting that availability is often marked with an asterisk (*) or as \"Gated\" for Claude 3.5 Sonnet v2 in some regions, which might indicate some restrictions or special access requirements. Despite this, it still offers the widest regional coverage among the models listed in the context.',\n",
       "  'question_type': 'complex',\n",
       "  'contexts': 'East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAnthropic\\nYes No Yes No No Yes* Yes* Yes GatedYes Yes Yes No GatedYes Yes Yes\\nClaude\\n3\\nSonnet\\nAnthropic\\nYes* Yes* Yes No No No No No No No No No No No No No No\\nClaude\\n3.5\\nHaiku\\nAnthropic\\nYes* No Yes No No No No No No No No No No No No No No\\nClaude\\n3.5\\nSonnet\\nv2\\nAnthropic\\nYes Yes* Yes Yes* Yes Yes Yes Yes* GatedYes* No Yes Yes GatedNo Yes* No\\nClaude\\n3.5\\nSonnet\\nAnthropic\\nYes No Yes No No Yes No No GatedNo No Yes No No No No No\\nClaude\\nInstant\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nLight\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nR+\\nModel support by Region 75\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nR\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nEnglish\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nMultiling\\nual\\nCohere\\nNo No Yes No No Yes No No No No Yes Yes No No No No No\\nRerank\\n3.5\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n8B\\nInstruct\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n70B\\nInstruct\\nModel support by Region 76\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nMeta\\nYes* Yes* Yes No No No No No No No No No No No No No No\\nLlama\\n3.1\\n8B\\nInstruct\\nMeta\\nYes* Yes* Yes No No No No No No No No No No No No No No\\nLlama\\n3.1\\n70B\\nInstruct\\nMeta\\nNo Yes* Yes No No No No No No No No No No No No No No\\nLlama\\n3.1\\n405B\\nInstruct\\nMeta\\nYes* Yes* Yes* No No No No No No No No Yes* No GatedNo Yes* No\\nLlama\\n3.2\\n1B\\nInstruct\\nMeta\\nYes* Yes* Yes* No No No No No No No No Yes* No GatedNo Yes* No\\nLlama\\n3.2\\n3B\\nInstruct\\nModel support by Region 77\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n'},\n",
       " {'question': 'What are the two main prerequisites for running Amazon Bedrock examples?',\n",
       "  'ground_truth': 'The two main prerequisites are having an AWS account with necessary permissions for Amazon Bedrock, and requesting access to the Amazon Titan Text G1 - Express model.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': 'up properly. Before you run the following examples, you should check that you have fulfilled the\\nfollowing prerequisites:\\nPrerequisites\\n• You have an AWS account and have permissions to access a role with the necessary permissions\\nfor Amazon Bedrock. Otherwise, follow the steps at I already have an AWS account.\\n• You\\'ve requested access to the Amazon Titan Text G1 - Express model. Otherwise, follow the\\nsteps at Request access to an Amazon Bedrock foundation model.\\n• Carry out the following steps to set up IAM permissions for SageMaker AI and create a notebook:\\n1. Modify the trust policy of the Amazon Bedrock role that you set up in I already have an AWS\\naccount through the console, CLI, or API. Attach the following trust policy to the role to\\nallow both the Amazon Bedrock and SageMaker AI services to assume the Amazon Bedrock\\nrole:\\n{\\n\"Version\": \"2012-10-17\",\\n\"Statement\": [\\n{\\n\"Sid\": \"BedrockTrust\",\\n\"Effect\": \"Allow\",\\n\"Principal\": {\\n\"Service\": \"bedrock.amazonaws.com\"\\n},\\n Run examples with a SageMaker AI notebook 24\\nAmazon Bedrock User Guide\\n\"Action\": \"sts:AssumeRole\"\\n},\\n{\\n\"Sid\": \"SagemakerTrust\",\\n\"Effect\": \"Allow\",\\n\"Principal\": {\\n\"Service\": \"sagemaker.amazonaws.com\"\\n},\\n\"Action\": \"sts:AssumeRole\"\\n}\\n]\\n}\\n2. Sign into the Amazon Bedrock role whose trust policy you just modified.\\n3. Follow the steps at Create an Amazon SageMaker AI Notebook Instance for the tutorial and\\nspecify the ARN of the Amazon Bedrock role that you created to create an SageMaker AI\\nnotebook instance.\\n4. When the Status of the notebook instance is InService, choose the instance and then choose\\nOpen JupyterLab.\\nAfter you open up your SageMaker AI notebook, you can try out the following examples:\\nTopics\\n• List the foundation models that Amazon Bedrock has to offer\\n• Submit a text prompt to a model and generate a response\\nList the foundation models that Amazon Bedrock has to offer\\nThe following example runs the ListFoundationModels operation using an Amazon Bedrock client.\\n ListFoundationModels lists the foundation models (FMs) that are available in Amazon Bedrock\\nin your region. Run the following SDK for Python script to create an Amazon Bedrock client and\\ntest the ListFoundationModels operation:\\n# Use the ListFoundationModels API to show the models that are available in your\\nregion.\\nimport boto3\\n# Create an &BR; client in the &region-us-east-1; Region.\\nbedrock = boto3.client(\\nRun examples with a SageMaker AI notebook 25\\nAmazon Bedrock User Guide\\nservice_name=\"bedrock\"\\n)\\nbedrock.list_foundation_models()\\nIf the script is successful, the response returns a list of foundation models that are available in\\nAmazon Bedrock.\\nSubmit a text prompt to a model and generate a response\\nThe following example runs the Converse operation using an Amazon Bedrock client. Converse\\nlets you submit a prompt to generate a model response. Run the following SDK for Python script to\\ncreate an Amazon Bedrock runtime client and test the Converse operation:\\n'},\n",
       " {'question': 'How does the regional availability of Amazon Nova models compare to AI21 Labs models in Amazon Bedrock, and what implications might this have for developers choosing between these providers?',\n",
       "  'ground_truth': 'The regional availability of Amazon Nova models is broader compared to AI21 Labs models in Amazon Bedrock. Amazon Nova models (Lite, Micro, and Pro) are available in US East (N. Virginia), and have cross-region inference support in US East (Ohio) and US West (Oregon). In contrast, AI21 Labs models (Jamba 1.5 Large, Jamba 1.5 Mini, and Jamba-Instruct) are only available in US East (N. Virginia) with no cross-region inference support mentioned. This difference in availability implies that developers choosing Amazon Nova models have more flexibility in terms of geographical deployment and potentially lower latency for users in different regions. However, those requiring AI21 Labs models may face limitations if they need to serve users outside the US East region efficiently.',\n",
       "  'question_type': 'complex',\n",
       "  'contexts': 'Stability Stable stability us- Text Image No Link N/A\\nAI Image .stable- west-2\\nUltra image-\\n1.0 ultra-\\nv1:1\\nSupported foundation models 69\\nAmazon Bedrock User Guide\\nNote\\n* Some models are accessible in some Regions only through cross-region inference. To learn\\nmore about cross-region inference, see Increase throughput with cross-region inference and\\nSupported Regions and models for inference profiles.\\nThe following table lists models that have a target date for deprecation. For more information, see\\nModel lifecycle:\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAI21 J2 ai21.j2- us- Text Text, No Link N/A\\nLabs Grande grande- east-1 Chat\\nInstruct instruct\\nAI21 J2 ai21.j2- us- Text Text, No Link N/A\\nLabs Jumbo jumbo- east-1 Chat\\nInstruct instruct\\nAI21 Jurassic- ai21.j2- us- Text Text, No Link N/A\\nLabs 2 Mid mid-v1 east-1 Chat\\nAI21 Jurassic- ai21.j2- us- Text Text, No Link N/A\\n Labs 2 Ultra ultra-v1 east-1 Chat\\nStability SDXL stability us- Text, Image No Link N/A\\nAI 1.0 .stable- east-1 Image\\nd\\nus-\\niffusion-\\nwest-2\\nxl-v1\\nSupported foundation models 70\\nAmazon Bedrock User Guide\\nModel support by AWS Region in Amazon Bedrock\\nFor a list of AWS Regions that support Amazon Bedrock, see Amazon Bedrock endpoints and\\nquotas. Amazon Bedrock foundation models differ in their regional support.\\nThe following table shows Region support by model:\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJamba\\n1.5\\nLarge\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJamba\\n1.5\\nMini\\nAI21\\n Yes No No No No No No No No No No No No No No No No\\nLabs\\nJamba-\\nIns\\ntruct\\nAmazon\\nYes No No No No No No No No No No No No No No No No\\nNova\\nCanvas\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nLite\\nModel support by Region 71\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nMicro\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nPro\\nAmazon\\nYes No No No No No No No No No No No No No No No No\\nNova\\nReel\\nAmazon\\nNo No Yes No No Yes No No No No Yes Yes No No No No No\\nRerank\\n1.0\\nAmazon\\nYes No Yes No No Yes No No No No No Yes No No No No No\\nTitan\\nEmbedding\\ns\\nG1\\n-\\nText\\nAmazon\\n'},\n",
       " {'question': 'Which Meta Llama model supports both text and image input?',\n",
       "  'ground_truth': 'The Meta Llama 3.2 11B and 90B Instruct models support both text and image input.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': 'Provider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nCohere Rerank cohere.re us- Text Text No Link N/A\\n3.5 rank- west-2\\nv3-5:0\\nap-\\nnorthe\\nast-1\\nca-\\ncentra\\nl-1\\neu-\\ncentra\\nl-1\\nSupported foundation models 60\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3 8B a3-8b- east-1 Chat\\nInstruct ins\\nus-\\ntruct-\\nwest-2\\nv1:0\\nus-gov-\\nwest-1\\nap-\\nsouth-1\\nca-\\ncentra\\nl-1\\neu-\\nwest-2\\nSupported foundation models 61\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3 70B a3-70b- east-1 Chat\\nInstruct in\\nus-\\nstruct-\\nwest-2\\nv1:0\\nus-gov-\\nwest-1\\nap-\\nsouth-1\\nca-\\n centra\\nl-1\\neu-\\nwest-2\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 8B a3-1-8b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 70B a3-1-70b- east-1* Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2\\nSupported foundation models 62\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 a3-1-405b east-2* Chat\\n405B -\\nus-\\nInstruct instruct\\nwest-2\\n-v1:0\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.2 1B a3-2-1b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2*\\neu-\\ncentra\\nl-1*\\neu-\\nwest-1\\n(Gated)*\\neu-\\nwest-3*\\nSupported foundation models 63\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\n Meta Llama meta.llam us- Text Text, Yes Link N/A\\n3.2 3B a3-2-3b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2*\\neu-\\ncentra\\nl-1*\\neu-\\nwest-1\\n(Gated)*\\neu-\\nwest-3*\\nMeta Llama meta.llam us- Text, Text, Yes Link N/A\\n3.2 11B a3-2-11b- east-1* Image Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2*\\nSupported foundation models 64\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text, Text, Yes Link N/A\\n3.2 90B a3-2-90b- east-1* Image Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2*\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.3 70B a3-3-70b- east-1* Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2\\nus-\\nwest-2*\\nSupported foundation models 65\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\n'},\n",
       " {'question': 'What are the key steps for granting a user access to Amazon Bedrock foundation models, and how does the process differ for users within your AWS account versus those from other accounts?',\n",
       "  'ground_truth': 'The process for granting user access to Amazon Bedrock foundation models involves several key steps:\\n\\n1. Add users to the Amazon Bedrock role:\\n   - For users in your account: Grant permissions to switch roles by following the \"Granting a user permissions to switch roles\" procedure.\\n   - For users from other accounts: Add them directly to the Amazon Bedrock role.\\n\\n2. Provide users with the Amazon Bedrock role name and the account ID or alias.\\n\\n3. Guide users on how to switch to the role using the \"Providing information to the user\" instructions.\\n\\n4. Users must sign into the AWS Management Console and switch to the Amazon Bedrock role.\\n\\n5. In the Amazon Bedrock console, users need to:\\n   - Navigate to the Model access page\\n   - Review the End User License Agreement (EULA) for desired models\\n   - Choose \"Modify model access\"\\n   - Request access to specific models or all models\\n   - Submit the access request\\n\\n6. Wait for access to be granted, which may take several minutes.\\n\\nThe main difference in the process for users within your AWS account versus those from other accounts is in the initial step of adding them to the role. Internal users are granted permissions to switch roles, while external users are added directly to the role. The subsequent steps for requesting access to foundation models remain the same for both types of users.',\n",
       "  'question_type': 'complex',\n",
       "  'contexts': \"To add users to the Amazon Bedrock role\\n1. For users to access an IAM role, you must add them to the role. You can add both users in your\\naccount or from other accounts. To grant users permissions to switch to the Amazon Bedrock\\nrole that you created, follow the steps at Granting a user permissions to switch roles and\\nspecify the Amazon Bedrock role as the Resource.\\nI already have an AWS account 8\\nAmazon Bedrock User Guide\\nNote\\nIf you need to create more users in your account so that you can give them access\\nto the Amazon Bedrock role, follow the steps in Creating an IAM user in your AWS\\naccount.\\n2. After you've granted a user permissions to use the Amazon Bedrock role, provide the user\\nwith role name and ID or alias of the account to which the role belongs. Then, guide the user\\nthrough how to switch to the role by following the instructions at Providing information to the\\nuser.\\nRequest access to an Amazon Bedrock foundation model\\n After setting up your Amazon Bedrock IAM role, you can sign into the Amazon Bedrock console and\\nrequest access to foundation models.\\nTo request access to an Amazon Bedrock FM\\n1. Sign into the AWS Management Console and switch to the Amazon Bedrock role that you set\\nup (or that was set up for you) by following the steps under To switch to a role (console) in\\nSwitching to a role (console).\\n2. Open the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/.\\n3. For the purposes of this tutorial, you should be in the US East (N. Virginia) (us-east-1) Region.\\nTo change regions, choose the Region name at the top right of the console, next to your IAM\\nrole. Then select US East (N. Virginia) (us-east-1).\\n4. Select Model access at the bottom of the left navigation pane.\\n5. On the Model access page, you can review the End User License Agreement (EULA) for models\\nin the EULA column in the Base models table.\\n6. Choose Modify model access.\\n7. Do one of the following:\\n • To request access to all models, choose Enable all models. On the page you're taken to,\\nthe checkboxes next to all the models will be filled.\\n• To request access to specific models, choose Enable specific models. On the page you're\\ntaken to, you have the following options:\\nRequest access to an Amazon Bedrock foundation model 9\\nAmazon Bedrock User Guide\\n• To request access to all models by a provider, select the checkbox next to the provider\\nname.\\n• To request access to one model, select the checkbox next to the model name.\\n8. For the purposes of the following tutorials, you should minimally request access to the\\nAmazon Titan Text G1 - Express and Amazon Titan Image Generator G1 V1 models. Then\\nchoose Next.\\n9. Review the models that you're requesting access to and the Terms. When you're ready, choose\\nSubmit to request access.\\n10. Access may take several minutes to complete. When access is granted to a model, the Access\\nstatus for that model willbecome Access granted.\\n\"},\n",
       " {'question': 'Which Meta Llama model supports both text and image input?',\n",
       "  'ground_truth': 'The Meta Llama 3.2 11B and 90B Instruct models support both text and image input.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': 'Provider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nCohere Rerank cohere.re us- Text Text No Link N/A\\n3.5 rank- west-2\\nv3-5:0\\nap-\\nnorthe\\nast-1\\nca-\\ncentra\\nl-1\\neu-\\ncentra\\nl-1\\nSupported foundation models 60\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3 8B a3-8b- east-1 Chat\\nInstruct ins\\nus-\\ntruct-\\nwest-2\\nv1:0\\nus-gov-\\nwest-1\\nap-\\nsouth-1\\nca-\\ncentra\\nl-1\\neu-\\nwest-2\\nSupported foundation models 61\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3 70B a3-70b- east-1 Chat\\nInstruct in\\nus-\\nstruct-\\nwest-2\\nv1:0\\nus-gov-\\nwest-1\\nap-\\nsouth-1\\nca-\\n centra\\nl-1\\neu-\\nwest-2\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 8B a3-1-8b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 70B a3-1-70b- east-1* Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2\\nSupported foundation models 62\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 a3-1-405b east-2* Chat\\n405B -\\nus-\\nInstruct instruct\\nwest-2\\n-v1:0\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.2 1B a3-2-1b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2*\\neu-\\ncentra\\nl-1*\\neu-\\nwest-1\\n(Gated)*\\neu-\\nwest-3*\\nSupported foundation models 63\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\n Meta Llama meta.llam us- Text Text, Yes Link N/A\\n3.2 3B a3-2-3b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2*\\neu-\\ncentra\\nl-1*\\neu-\\nwest-1\\n(Gated)*\\neu-\\nwest-3*\\nMeta Llama meta.llam us- Text, Text, Yes Link N/A\\n3.2 11B a3-2-11b- east-1* Image Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2*\\nSupported foundation models 64\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text, Text, Yes Link N/A\\n3.2 90B a3-2-90b- east-1* Image Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2*\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.3 70B a3-3-70b- east-1* Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2\\nus-\\nwest-2*\\nSupported foundation models 65\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\n'},\n",
       " {'question': 'What are the key differences between using the InvokeModel and Converse operations in Amazon Bedrock, and in what scenario might you prefer one over the other?',\n",
       "  'ground_truth': \"The key differences between InvokeModel and Converse operations in Amazon Bedrock are:\\n\\n1. Unification: Converse unifies the inference request across Amazon Bedrock models, while InvokeModel is model-specific.\\n2. Multi-turn conversations: Converse simplifies the management of multi-turn conversations, which is not mentioned for InvokeModel.\\n3. Input format: InvokeModel uses a 'body' parameter with JSON content, while Converse uses 'messages' and 'inference-config' parameters.\\n4. Recommendation: Amazon Bedrock recommends using Converse over InvokeModel when supported.\\n\\nYou might prefer Converse when:\\n1. Working with multiple models and wanting a consistent interface.\\n2. Managing multi-turn conversations.\\n3. Seeking a more streamlined approach to generating responses.\\n\\nInvokeModel might be preferred when:\\n1. Working with a specific model that doesn't support Converse.\\n2. Needing more fine-grained control over the input format for certain models.\\n3. Maintaining compatibility with existing systems that use the InvokeModel format.\",\n",
       "  'question_type': 'complex',\n",
       "  'contexts': 'Test that your permissions are set up properly for Amazon Bedrock, using a user or role that you set\\nup with the proper permissions.\\nTopics\\n• List the foundation models that Amazon Bedrock has to offer\\n• Submit a text prompt to a model and generate a text response with InvokeModel\\n• Submit a text prompt to a model and generate a text response with Converse\\nList the foundation models that Amazon Bedrock has to offer\\nThe following example runs the ListFoundationModels operation using an Amazon Bedrock\\nendpoint. ListFoundationModels lists the foundation models (FMs) that are available in\\nAmazon Bedrock in your region. In a terminal, run the following command:\\naws bedrock list-foundation-models --region us-east-1\\nIf the command is successful, the response returns a list of foundation models that are available in\\nAmazon Bedrock.\\nSubmit a text prompt to a model and generate a text response with InvokeModel\\nThe following example runs the InvokeModel operation using an Amazon Bedrock runtime\\n endpoint. InvokeModel lets you submit a prompt to generate a model response. In a terminal, run\\nthe following command:\\naws bedrock-runtime invoke-model \\\\\\n--model-id amazon.titan-text-express-v1 \\\\\\n--body \\'{\"inputText\": \"Describe the purpose of a \\\\\"hello world\\\\\" program in one line.\",\\n\"textGenerationConfig\" : {\"maxTokenCount\": 512, \"temperature\": 0.5, \"topP\": 0.9}}\\' \\\\\\n--cli-binary-format raw-in-base64-out \\\\\\ninvoke-model-output-text.txt\\nRun examples with the AWS CLI 19\\nAmazon Bedrock User Guide\\nIf the command is successful, the response generated by the model is written to the invoke-\\nmodel-output-text.txt file. The text response is returned in the outputText field, alongside\\naccompanying information.\\nSubmit a text prompt to a model and generate a text response with Converse\\nThe following example runs the Converse operation using an Amazon Bedrock runtime endpoint.\\nConverse lets you submit a prompt to generate a model response. We recommend using\\n Converse operation over InvokeModel when supported, because it unifies the inference request\\nacross Amazon Bedrock models and simplifies the management of multi-turn conversations. In a\\nterminal, run the following command:\\naws bedrock-runtime converse \\\\\\n--model-id amazon.titan-text-express-v1 \\\\\\n--messages \\'[{\"role\": \"user\", \"content\": [{\"text\": \"Describe the purpose of a \\\\\"hello\\nworld\\\\\" program in one line.\"}]}]\\' \\\\\\n--inference-config \\'{\"maxTokens\": 512, \"temperature\": 0.5, \"topP\": 0.9}\\'\\nIf the command is successful, the response generated by the model is returned in the text field,\\nalongside accompanying information.\\nRun example Amazon Bedrock API requests through the AWS SDK for\\nPython (Boto3)\\nThis section guides you through trying out some common operations in Amazon Bedrock with the\\nAWS Python to test that your permissions and authentication are set up properly. Before you run\\nthe following examples, you should check that you have fulfilled the following prerequisites:\\n'},\n",
       " {'question': 'What command lists the foundation models available in Amazon Bedrock?',\n",
       "  'ground_truth': 'The command to list foundation models available in Amazon Bedrock is: aws bedrock list-foundation-models --region us-east-1',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': 'Test that your permissions are set up properly for Amazon Bedrock, using a user or role that you set\\nup with the proper permissions.\\nTopics\\n• List the foundation models that Amazon Bedrock has to offer\\n• Submit a text prompt to a model and generate a text response with InvokeModel\\n• Submit a text prompt to a model and generate a text response with Converse\\nList the foundation models that Amazon Bedrock has to offer\\nThe following example runs the ListFoundationModels operation using an Amazon Bedrock\\nendpoint. ListFoundationModels lists the foundation models (FMs) that are available in\\nAmazon Bedrock in your region. In a terminal, run the following command:\\naws bedrock list-foundation-models --region us-east-1\\nIf the command is successful, the response returns a list of foundation models that are available in\\nAmazon Bedrock.\\nSubmit a text prompt to a model and generate a text response with InvokeModel\\nThe following example runs the InvokeModel operation using an Amazon Bedrock runtime\\n endpoint. InvokeModel lets you submit a prompt to generate a model response. In a terminal, run\\nthe following command:\\naws bedrock-runtime invoke-model \\\\\\n--model-id amazon.titan-text-express-v1 \\\\\\n--body \\'{\"inputText\": \"Describe the purpose of a \\\\\"hello world\\\\\" program in one line.\",\\n\"textGenerationConfig\" : {\"maxTokenCount\": 512, \"temperature\": 0.5, \"topP\": 0.9}}\\' \\\\\\n--cli-binary-format raw-in-base64-out \\\\\\ninvoke-model-output-text.txt\\nRun examples with the AWS CLI 19\\nAmazon Bedrock User Guide\\nIf the command is successful, the response generated by the model is written to the invoke-\\nmodel-output-text.txt file. The text response is returned in the outputText field, alongside\\naccompanying information.\\nSubmit a text prompt to a model and generate a text response with Converse\\nThe following example runs the Converse operation using an Amazon Bedrock runtime endpoint.\\nConverse lets you submit a prompt to generate a model response. We recommend using\\n Converse operation over InvokeModel when supported, because it unifies the inference request\\nacross Amazon Bedrock models and simplifies the management of multi-turn conversations. In a\\nterminal, run the following command:\\naws bedrock-runtime converse \\\\\\n--model-id amazon.titan-text-express-v1 \\\\\\n--messages \\'[{\"role\": \"user\", \"content\": [{\"text\": \"Describe the purpose of a \\\\\"hello\\nworld\\\\\" program in one line.\"}]}]\\' \\\\\\n--inference-config \\'{\"maxTokens\": 512, \"temperature\": 0.5, \"topP\": 0.9}\\'\\nIf the command is successful, the response generated by the model is returned in the text field,\\nalongside accompanying information.\\nRun example Amazon Bedrock API requests through the AWS SDK for\\nPython (Boto3)\\nThis section guides you through trying out some common operations in Amazon Bedrock with the\\nAWS Python to test that your permissions and authentication are set up properly. Before you run\\nthe following examples, you should check that you have fulfilled the following prerequisites:\\n'},\n",
       " {'question': 'How do the capabilities and regional availability of Claude 3 Opus compare to Claude 3.5 Sonnet, and what implications might this have for developers choosing between these models?',\n",
       "  'ground_truth': 'Claude 3 Opus and Claude 3.5 Sonnet have some key differences in capabilities and regional availability. Claude 3 Opus is available in fewer regions (only us-east-1 and us-west-2) compared to Claude 3.5 Sonnet, which is available in multiple regions across the Americas, Europe, and Asia Pacific. Both models support text and image input, and text chat output with streaming inference. However, Claude 3.5 Sonnet has two versions (v1 and v2) while Opus has only one. This suggests that Sonnet might be more actively updated. The wider availability of Sonnet could make it more suitable for global applications or those requiring lower latency in specific regions. Developers might choose Opus for potentially more advanced capabilities in supported regions, while Sonnet offers broader geographical flexibility and possibly more frequent updates. The choice would depend on the specific requirements of the application, such as performance needs, data residency requirements, and target user locations.',\n",
       "  'question_type': 'complex',\n",
       "  'contexts': 'l-1\\nAnthropic Claude anthropic us- Text Text, Yes Link N/A\\n2 .claude- east-1 Chat\\nv2\\nus-\\nwest-2\\nap-\\nsouthe\\nast-1\\n(Gated)\\neu-\\ncentra\\nl-1\\nSupported foundation models 48\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n3 Haiku .claude-3 east-1 Image Chat\\n-\\nus-\\nhaiku-20\\neast-2*\\n240307-\\nv1:0\\nus-\\nwest-2\\nus-gov-\\neast-1*\\nus-gov-\\nwest-1\\nap-\\nnorthe\\nast-1\\nap-\\nnorthe\\nast-2\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-1\\n(Gated)\\nap-\\nsouthe\\nast-1\\n(Gated)\\nSupported foundation models 49\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\ncentra\\nl-1\\neu-\\ncentra\\nl-2\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n 3 Opus .claude-3 east-1* Image Chat\\n-\\nus-\\nopus-202\\nwest-2\\n40229-\\nv1:0\\nSupported foundation models 50\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n3 .claude-3 east-1 Image Chat\\nSonnet -\\nus-\\nsonnet-2\\nwest-2\\n0240229-\\nv1:0\\nap-\\nnorthe\\nast-1*\\nap-\\nnorthe\\nast-2*\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-1\\n(Gated)*\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\ncentra\\nl-1\\nSupported foundation models 51\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n3.5 .claude-3 east-1* Image Chat\\nHaiku -5-\\nus-\\nhaiku-\\neast-2*\\n20241022-\\nv1:0\\nus-\\nwest-2\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n 3.5 .claude-3 east-1* Image Chat\\nSonnet -5-\\nus-\\nv2 sonnet\\nwest-2\\n-20241022\\n-v2:0\\nSupported foundation models 52\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n3.5 .claude-3 east-1 Image Chat\\nSonnet -5-\\nus-\\nsonnet\\neast-2*\\n-20240620\\n-v1:0\\nus-\\nwest-2\\nus-gov-\\neast-1*\\nus-gov-\\nwest-1\\nap-\\nnorthe\\nast-1\\nap-\\nnorthe\\nast-2\\nap-\\nsouth-\\n1*\\nap-\\nsouthe\\nast-1\\n(Gated)\\nap-\\nsouthe\\nSupported foundation models 53\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nast-1\\n(Gated)\\nap-\\nsouthe\\nast-2*\\neu-\\ncentra\\nl-1\\neu-\\ncentra\\nl-2\\neu-\\nwest-1\\n(Gated)*\\neu-\\nwest-3*\\nSupported foundation models 54\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\n'},\n",
       " {'question': 'How do AWS GovCloud (US) customers enable model access for Amazon Bedrock?',\n",
       "  'ground_truth': 'AWS GovCloud (US) customers first use their standard AWS account ID to enable model access in the Amazon Bedrock console in us-east-1 or us-west-2. Then, they log into their AWS GovCloud (US) account and follow the same model access sign-up steps in us-gov-west-1 to gain regional entitlement for accessing models in that region.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': \"• AWS GovCloud (US) customers use their standard AWS account ID (which is linked to\\ntheir AWS GovCloud (US) account ID) to first enable model access. Navigate to the model\\naccess page on Amazon Bedrock console in either us-east-1 or us-west-2. Select the\\nmodel(s) that you want to enable. Select Request model access and follow the step-by-\\nstep subscription flow.\\n• Log into your AWS GovCloud (US) account and navigate to Amazon Bedrock in us-gov-\\nwest-1 and follow the same model access sign-up steps. This will grant you a regional\\nentitlement to access the models in us-gov-west-1.\\n• The model will be accessible to the linked AWS GovCloud (US) account on us-gov-\\nwest-1.\\nIf you don't have permissions to request access to a model, an error banner appears. Contact\\nyour account administrator to ask them to request access to the model for you or to provide you\\npermissions to request access to the model.\\nAdd or remove access to foundation models 34\\nAmazon Bedrock User Guide\\n Amazon Bedrock foundation model information\\nA foundation model is an Artificial Intellgence model with a large number of parameters and\\ntrained on a massive amount of diverse data. A foundation model can generate a variety of\\nresponses for a wide range of use cases. Foundation models can generate text or image, and can\\nalso convert input into embeddings. This section provides information about the foundation models\\n(FM) that you can use in Amazon Bedrock, such as the features that models support and the AWS\\nregions in which models are available. For information about the foundation models that Amazon\\nBedrock supports, see Supported foundation models in Amazon Bedrock.\\nYou must request access to a model before you can use it. After doing so, you can then use FMs in\\nthe following ways.\\n• Run inference by sending prompts to a model and generating responses. The playgrounds offer\\na user-friendly interface in the AWS Management Console for generating text, images, or chats.\\n See the Output modality column to determine the models you can use in each playground.\\nNote\\nThe console playgrounds don't support running inference on embeddings models. Use\\nthe API to run inference on embeddings models.\\n• Evaluate models to compare outputs and determine the best model for your use-case.\\n• Set up a knowledge base with the help of an embeddings model. Then use a text model to\\ngenerate responses to queries.\\n• Create an agent and use a model to run inference on prompts to carry out orchestration.\\n• Customize a model by feeding training and validation data to adjust model parameters for your\\nuse-case. To use a customized model, you must purchase Provisioned Throughput for it.\\n• Purchase Provisioned Throughput for a model to increase throughput for it.\\nTo use an FM with the Amazon Bedrock API, you need to determine the appropriate model ID to\\nuse. Refer to the following table to determine where to find the model ID that you need to use.\\nUse case How to find the model ID\\n\"},\n",
       " {'question': \"How does Amazon Bedrock's pricing model work, and what factors should a developer consider when estimating costs for a project that involves heavy use of foundation models?\",\n",
       "  'ground_truth': \"Amazon Bedrock's pricing model is based on the volume of input and output tokens processed during model inference. Developers should consider several factors when estimating costs:\\n\\n1. Model selection: Different foundation models have varying pricing structures.\\n2. Input/output volume: Costs are directly related to the amount of data processed.\\n3. Provisioned Throughput: Purchasing this can affect pricing and is beneficial for high-volume use cases.\\n4. Use case complexity: More complex prompts or tasks may require more tokens, increasing costs.\\n5. Model access: Some models require requesting access before use.\\n\\nTo estimate costs accurately, developers should:\\n- Review the specific pricing for each model on the Model providers page in the Amazon Bedrock console.\\n- Consider the potential benefits of Provisioned Throughput for high-volume applications.\\n- Monitor usage through the AWS Billing and Cost Management console.\\n- Factor in the possibility of costs changing as they only pay for services used.\\n\\nBy carefully considering these aspects, developers can better predict and optimize their Amazon Bedrock expenses for projects involving extensive use of foundation models.\",\n",
       "  'question_type': 'complex',\n",
       "  'contexts': \"How do I get started with Amazon Bedrock? 2\\nAmazon Bedrock User Guide\\n4. Read the documentation for the features that you want to include in your application.\\nAmazon Bedrock pricing\\nWhen you sign up for AWS, your AWS account is automatically signed up for all services in AWS,\\nincluding Amazon Bedrock. However, you are charged only for the services that you use.\\nFor information about pricing for different Amazon Bedrock resources, see Amazon Bedrock\\nPricing.\\nTo see your bill, go to the Billing and Cost Management Dashboard in the AWS Billing and Cost\\nManagement console. To learn more about AWS account billing, see the AWS Billing User Guide. If\\nyou have questions concerning AWS billing and AWS accounts, contact AWS Support.\\nWith Amazon Bedrock, you pay to run inference on any of the third-party foundation models.\\nPricing is based on the volume of input tokens and output tokens, and on whether you have\\n purchased Provisioned Throughput for the model. For more information, see the Model providers\\npage in the Amazon Bedrock console. For each model, pricing is listed following the model version.\\nFor more information about purchasing Provisioned Throughput, see Increase model invocation\\ncapacity with Provisioned Throughput in Amazon Bedrock.\\nKey terminology\\nThis chapter explains terminology that will help you understand what Amazon Bedrock offers\\nand how it works. Read through the following list to understand generative AI terminology and\\nAmazon Bedrock's fundamental capabilities:\\n• Foundation model (FM) – An AI model with a large number of parameters and trained on a\\nmassive amount of diverse data. A foundation model can generate a variety of responses for a\\nwide range of use cases. Foundation models can generate text or image, and can also convert\\ninput into embeddings. Before you can use an Amazon Bedrock foundation model, you must\\n request access. For more information about foundation models, see Supported foundation\\nmodels in Amazon Bedrock.\\n• Base model – A foundation model that is packaged by a provider and ready to use. Amazon\\nBedrock offers a variety of industry-leading foundation models from leading providers. For more\\ninformation, see Supported foundation models in Amazon Bedrock.\\nAmazon Bedrock pricing 3\\nAmazon Bedrock User Guide\\n• Model inference – The process of a foundation model generating an output (response) from a\\ngiven input (prompt). For more information, see Submit prompts and generate responses with\\nmodel inference.\\n• Prompt – An input provided to a model to guide it to generate an appropriate response or\\noutput for the input. For example, a text prompt can consist of a single line for the model\\nto respond to, or it can detail instructions or a task for the model to perform. The prompt\\ncan contain the context of the task, examples of outputs, or text for a model to use in its\\n\"},\n",
       " {'question': 'Which AI model is available in the most AWS regions?',\n",
       "  'ground_truth': 'Based on the information provided, Claude 3 Sonnet by Anthropic appears to be available in the most AWS regions, with \"Yes\" or \"Yes*\" entries for many regions including US East, US West, various parts of Europe, Asia, and South America.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': 'ModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAmazon\\nYes No Yes No No No No Yes No Yes Yes Yes No GatedYes Yes Yes\\nTitan\\nText\\nG1\\n-\\nLite\\nAmazon\\nYes No No No No No No No No No No No No No No No No\\nTitan\\nText\\nG1\\n-\\nPremier\\nAnthropic\\nYes No Yes No No Yes No No No No No Yes No No No No No\\nClaude\\n2.1\\nAnthropic\\nYes No Yes No No No No No GatedNo No Yes No No No No No\\nClaude\\n2\\nAnthropic\\nYes Yes* Yes Yes* Yes Yes Yes Yes GatedYes Yes Yes Yes GatedYes Yes Yes\\nClaude\\n3\\nHaiku\\nAnthropic\\nYes* No Yes No No No No No No No No No No No No No No\\nClaude\\n3\\nOpus\\nModel support by Region 74\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAnthropic\\nYes No Yes No No Yes* Yes* Yes GatedYes Yes Yes No GatedYes Yes Yes\\nClaude\\n3\\nSonnet\\nAnthropic\\nYes* Yes* Yes No No No No No No No No No No No No No No\\nClaude\\n3.5\\nHaiku\\nAnthropic\\nYes* No Yes No No No No No No No No No No No No No No\\nClaude\\n3.5\\nSonnet\\nv2\\nAnthropic\\nYes Yes* Yes Yes* Yes Yes Yes Yes* GatedYes* No Yes Yes GatedNo Yes* No\\nClaude\\n3.5\\nSonnet\\nAnthropic\\nYes No Yes No No Yes No No GatedNo No Yes No No No No No\\nClaude\\nInstant\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nLight\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nR+\\nModel support by Region 75\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nR\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nEnglish\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nMultiling\\nual\\nCohere\\nNo No Yes No No Yes No No No No Yes Yes No No No No No\\nRerank\\n3.5\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n8B\\nInstruct\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n70B\\nInstruct\\nModel support by Region 76\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n'},\n",
       " {'question': \"How does the availability of AI21 Labs models compare to Stability AI's SDXL 1.0 model across AWS regions, and what implications might this have for developers choosing between these options?\",\n",
       "  'ground_truth': \"AI21 Labs models (J2 Grande Instruct, J2 Jumbo Instruct, Jurassic-2 Mid, and Jurassic-2 Ultra) are only available in the US East (N. Virginia) region, while Stability AI's SDXL 1.0 model is available in both US East (N. Virginia) and US West (Oregon) regions. This limited availability of AI21 Labs models compared to SDXL 1.0 may impact developers' choices, as those requiring multi-region deployment or specific to the US West region would find SDXL 1.0 more suitable. However, developers focused on the US East region have access to a wider variety of AI21 Labs models, potentially offering more specialized options for their applications.\",\n",
       "  'question_type': 'complex',\n",
       "  'contexts': 'No No Yes No No No No No No No No No No No No No No\\nAI\\nStable\\nImage\\nUltra\\n1.0\\nStability\\nNo No Yes No No No No No No No No No No No No No No\\nAI\\nStable\\nImage\\nUltra\\n1.0\\nModel support by Region 80\\nAmazon Bedrock User Guide\\nNote\\n* Some models are accessible in some Regions only through cross-region inference. To learn\\nmore about cross-region inference, see Increase throughput with cross-region inference and\\nSupported Regions and models for inference profiles.\\nThe following table shows Region support for models that have a target date for deprecation. For\\nmore information, see Model lifecycle.\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJ2\\n Grande\\nInstruct\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJ2\\nJumbo\\nInstruct\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJurassic-\\n2\\nMid\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJurassic-\\nModel support by Region 81\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\n2\\nUltra\\nStability\\nYes No Yes No No No No No No No No No No No No No No\\nAI\\nSDXL\\n1.0\\nTo learn more about Region and model support for specific features, see the following links:\\n• Converse API\\n• Batch inference\\n• Inference profiles\\n• Latency optimization\\n• Prompt management\\n• Prompt management\\n• Prompt optimization\\n• Amazon Bedrock Guardrails\\n• Model evaluation\\n • RAG evaluation\\n• Amazon Bedrock Knowledge Bases\\n• Rerank\\n• Amazon Bedrock Agents\\n• Amazon Bedrock Flows\\n• Model customization\\n• Amazon Bedrock Custom Model Import\\n• Provisioned Throughput\\n• Amazon Bedrock Studio\\nModel support by Region 82'},\n",
       " {'question': 'How can you send a text message to Amazon Titan Text G1 - Express?',\n",
       "  'ground_truth': 'You can send a text message to Amazon Titan Text G1 - Express using the Conversation API with Amazon Bedrock Runtime client.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': '# Use the Conversation API to send a text message to Amazon Titan Text G1 - Express.\\nimport boto3\\nfrom botocore.exceptions import ClientError\\n# Create an Amazon Bedrock Runtime client.\\nbrt = boto3.client(\"bedrock-runtime\")\\n# Set the model ID, e.g., Amazon Titan Text G1 - Express.\\nmodel_id = \"amazon.titan-text-express-v1\"\\n# Start a conversation with the user message.\\nuser_message = \"Describe the purpose of a \\'hello world\\' program in one line.\"\\nconversation = [\\n{\\n\"role\": \"user\",\\n\"content\": [{\"text\": user_message}],\\n}\\n]\\ntry:\\n# Send the message to the model, using a basic inference configuration.\\nresponse = brt.converse(\\nmodelId=model_id,\\nmessages=conversation,\\ninferenceConfig={\"maxTokens\": 512, \"temperature\": 0.5, \"topP\": 0.9},\\n)\\n# Extract and print the response text.\\nRun examples with a SageMaker AI notebook 26\\nAmazon Bedrock User Guide\\nresponse_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\\nprint(response_text)\\nexcept (ClientError, Exception) as e:\\n print(f\"ERROR: Can\\'t invoke \\'{model_id}\\'. Reason: {e}\")\\nexit(1)\\nIf the command is successful, the response returns the text generated by the model in response to\\nthe prompt.\\nUsing Amazon Bedrock with an AWS SDK\\nAWS software development kits (SDKs) are available for many popular programming languages.\\nEach SDK provides an API, code examples, and documentation that make it easier for developers to\\nbuild applications in their preferred language.\\nSDK documentation Code examples\\nAWS SDK for C++ AWS SDK for C++ code examples\\nAWS CLI AWS CLI code examples\\nAWS SDK for Go AWS SDK for Go code examples\\nAWS SDK for Java AWS SDK for Java code examples\\nAWS SDK for JavaScript AWS SDK for JavaScript code examples\\nAWS SDK for Kotlin AWS SDK for Kotlin code examples\\nAWS SDK for .NET AWS SDK for .NET code examples\\nAWS SDK for PHP AWS SDK for PHP code examples\\nAWS Tools for PowerShell Tools for PowerShell code examples\\nAWS SDK for Python (Boto3) AWS SDK for Python (Boto3) code examples\\n AWS SDK for Ruby AWS SDK for Ruby code examples\\nAWS SDK for Rust AWS SDK for Rust code examples\\nWorking with AWS SDKs 27\\nAmazon Bedrock User Guide\\nSDK documentation Code examples\\nAWS SDK for SAP ABAP AWS SDK for SAP ABAP code examples\\nAWS SDK for Swift AWS SDK for Swift code examples\\nExample availability\\nCan\\'t find what you need? Request a code example by using the Provide feedback link at\\nthe bottom of this page.\\nWorking with AWS SDKs 28\\nAmazon Bedrock User Guide\\nAccess Amazon Bedrock foundation models\\nAccess to Amazon Bedrock foundation models isn\\'t granted by default. You can request access, or\\nmodify access, to foundation models only by using the Amazon Bedrock console.\\nNote\\nIf you\\'re new to Amazon Bedrock and this is your first time requesting model access, follow\\nthe steps at Getting started with Amazon Bedrock instead.\\nTo request or modify access, first, make sure the IAM role that you use has sufficent IAM\\n'},\n",
       " {'question': \"How might Amazon Bedrock's features enable a company to develop a more efficient and cost-effective AI-powered customer service chatbot compared to building one from scratch?\",\n",
       "  'ground_truth': \"Amazon Bedrock offers several features that can help a company develop an efficient and cost-effective AI-powered customer service chatbot:\\n\\n1. Access to pre-trained foundation models: Companies can experiment with various high-performing models through a unified API, saving time and resources on model development.\\n\\n2. Retrieval Augmented Generation (RAG): By creating knowledge bases with company-specific data, the chatbot can provide more accurate and contextual responses without extensive custom training.\\n\\n3. Agent capabilities: Bedrock allows building agents that can reason through tasks and make API calls, enabling the chatbot to perform complex actions and integrate with existing systems.\\n\\n4. Fine-tuning and customization: Companies can adapt models to their specific domain and tasks, improving performance without starting from scratch.\\n\\n5. Provisioned Throughput: This feature allows for more efficient and cost-effective inference, particularly beneficial for high-volume customer service operations.\\n\\n6. Model evaluation tools: Companies can determine the best model for their use case, ensuring optimal performance.\\n\\n7. Guardrails: These help prevent inappropriate content, crucial for maintaining a professional customer service interaction.\\n\\n8. Serverless experience: This reduces infrastructure management overhead, allowing the company to focus on improving the chatbot's functionality.\\n\\nBy leveraging these features, a company can quickly develop a sophisticated, customized, and scalable customer service chatbot while minimizing development time, costs, and infrastructure management compared to building one from scratch.\",\n",
       "  'question_type': 'complex',\n",
       "  'contexts': \"Amazon Bedrock User Guide\\nWhat is Amazon Bedrock?\\nAmazon Bedrock is a fully managed service that makes high-performing foundation models (FMs)\\nfrom leading AI companies and Amazon available for your use through a unified API. You can\\nchoose from a wide range of foundation models to find the model that is best suited for your use\\ncase. Amazon Bedrock also offers a broad set of capabilities to build generative AI applications with\\nsecurity, privacy, and responsible AI. Using Amazon Bedrock, you can easily experiment with and\\nevaluate top foundation models for your use cases, privately customize them with your data using\\ntechniques such as fine-tuning and Retrieval Augmented Generation (RAG), and build agents that\\nexecute tasks using your enterprise systems and data sources.\\nWith Amazon Bedrock's serverless experience, you can get started quickly, privately customize\\nfoundation models with your own data, and easily and securely integrate and deploy them into\\n your applications using AWS tools without having to manage any infrastructure.\\nTopics\\n• What can I do with Amazon Bedrock?\\n• How do I get started with Amazon Bedrock?\\n• Amazon Bedrock pricing\\n• Key terminology\\nWhat can I do with Amazon Bedrock?\\nYou can use Amazon Bedrock to do the following:\\n• Experiment with prompts and configurations – Submit prompts and generate responses with\\nmodel inference by sending prompts using different configurations and foundation models to\\ngenerate responses. You can use the API or the text, image, and chat playgrounds in the console\\nto experiment in a graphical interface. When you're ready, set up your application to make\\nrequests to the InvokeModel APIs.\\n• Augment response generation with information from your data sources – Create knowledge\\nbases by uploading data sources to be queried in order to augment a foundation model's\\ngeneration of responses.\\nWhat can I do with Amazon Bedrock? 1\\nAmazon Bedrock User Guide\\n • Create applications that reason through how to help a customer – Build agents that use\\nfoundation models, make API calls, and (optionally) query knowledge bases in order to reason\\nthrough and carry out tasks for your customers.\\n• Adapt models to specific tasks and domains with training data – Customize an Amazon\\nBedrock foundation model by providing training data for fine-tuning or continued-pretraining in\\norder to adjust a model's parameters and improve its performance on specific tasks or in certain\\ndomains.\\n• Improve your FM-based application's efficiency and output – Purchase Provisioned Throughput\\nfor a foundation model in order to run inference on models more efficiently and at discounted\\nrates.\\n• Determine the best model for your use case – Evaluate outputs of different models with built-in\\nor custom prompt datasets to determine the model that is best suited for your application.\\n• Prevent inappropriate or unwanted content – Use guardrails to implement safeguards for your\\n\"},\n",
       " {'question': 'How can users access an IAM role for Amazon Bedrock?',\n",
       "  'ground_truth': 'Users can be added to the Amazon Bedrock role. To grant users permissions to switch to the role, follow the steps in \"Granting a user permissions to switch roles\" and specify the Amazon Bedrock role as the Resource.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': 'Configure user access with the default IAM Identity Center directory in the AWS IAM Identity\\nCenter User Guide.\\nSign in as the user with administrative access\\n• To sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email\\naddress when you created the IAM Identity Center user.\\nFor help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in\\nthe AWS Sign-In User Guide.\\nTo learn more about IAM, see Identity and access management for Amazon Bedrock and the IAM\\nUser Guide.\\nAfter you have created an administrative user, proceed to I already have an AWS account to set up\\npermissions for Amazon Bedrock.\\nI already have an AWS account\\nUse IAM to create a role for with the necessary permissions to use Amazon Bedrock. You can then\\nadd users to this role to grant the permissions.\\nI already have an AWS account 7\\nAmazon Bedrock User Guide\\nTo create an Amazon Bedrock role\\n 1. Create a role with a name of your choice by following the steps at Creating a role to delegate\\npermissions to an IAM user in the IAM User Guide. When you reach the step to attach a policy\\nto the role, attach the AmazonBedrockFullAccess AWS managed policy.\\n2. Create a new policy to allow your role to manage access to Amazon Bedrock models. From the\\nfollowing list, select the link that corresponds to your method of choice and follow the steps.\\nUse the following JSON object as the policy.\\n• Creating IAM policies (console)\\n• Creating IAM policies (AWS CLI)\\n• Creating IAM policies (AWS API)\\n{\\n\"Version\": \"2012-10-17\",\\n\"Statement\": [\\n{\\n\"Sid\": \"MarketplaceBedrock\",\\n\"Effect\": \"Allow\",\\n\"Action\": [\\n\"aws-marketplace:ViewSubscriptions\",\\n\"aws-marketplace:Unsubscribe\",\\n\"aws-marketplace:Subscribe\"\\n],\\n\"Resource\": \"*\"\\n}\\n]\\n}\\n3. Attach the policy that you created in the last step to your Amazon Bedrock role by following\\nthe steps at Adding and removing IAM identity permissions.\\n To add users to the Amazon Bedrock role\\n1. For users to access an IAM role, you must add them to the role. You can add both users in your\\naccount or from other accounts. To grant users permissions to switch to the Amazon Bedrock\\nrole that you created, follow the steps at Granting a user permissions to switch roles and\\nspecify the Amazon Bedrock role as the Resource.\\nI already have an AWS account 8\\nAmazon Bedrock User Guide\\nNote\\nIf you need to create more users in your account so that you can give them access\\nto the Amazon Bedrock role, follow the steps in Creating an IAM user in your AWS\\naccount.\\n2. After you\\'ve granted a user permissions to use the Amazon Bedrock role, provide the user\\nwith role name and ID or alias of the account to which the role belongs. Then, guide the user\\nthrough how to switch to the role by following the instructions at Providing information to the\\nuser.\\nRequest access to an Amazon Bedrock foundation model\\n'},\n",
       " {'question': 'How can a developer efficiently retrieve information about multiple Amazon Bedrock foundation models, including their support for Provisioned Throughput, and what are the key differences in using custom models versus base models?',\n",
       "  'ground_truth': 'To efficiently retrieve information about multiple Amazon Bedrock foundation models, a developer can use the ListFoundationModels API request, which returns FoundationModelSummary objects containing details such as ARNs, model IDs, supported modalities, features, and deprecation status. For specific model information, they can use the GetFoundationModel request with a particular model ID.\\n\\nKey differences in using custom models versus base models include:\\n\\n1. Model ID lookup: Base model IDs are found in the base model IDs chart, while custom models use their name or ARN as the model ID.\\n\\n2. Provisioned Throughput: For base models, look up the ID in the model IDs for Provisioned Throughput chart and use it in the CreateProvisionedModelThroughput request. For custom models, use the model name or ARN directly in the request.\\n\\n3. Usage after Provisioned Throughput: Both types return a provisionedModelArn, which becomes the model ID for subsequent use.\\n\\n4. Flexibility: Custom models may offer more tailored functionality but might require additional steps, such as purchasing Provisioned Throughput before use.\\n\\nDevelopers should note that the ListFoundationModels response may include deprecated or backwards-compatible model IDs not found in the standard charts, requiring careful consideration when selecting models for implementation.',\n",
       "  'question_type': 'complex',\n",
       "  'contexts': \"Use a base model Look up the ID in the base model IDs chart\\n35\\nAmazon Bedrock User Guide\\nUse case How to find the model ID\\nPurchase Provisioned Throughput for a base Look up the ID in the model IDs for Provision\\nmodel ed Throughput chart and use it as the\\nmodelId in the CreateProvisionedModelThrou\\nghput request.\\nPurchase Provisioned Throughput for a Use the name of the custom model or its ARN\\ncustom model as the modelId in the CreateProvisionedM\\nodelThroughput request.\\nUse a provisioned model After you create a Provisioned Throughput,\\nit returns a provisionedModelArn . This\\nARN is the model ID.\\nUse a custom model Purchase Provisioned Throughput for\\nthe custom model and use the returned\\nprovisionedModelArn as the model ID.\\nFor example code, see the documentation for the feature you are using and also Code examples for\\nAmazon Bedrock using AWS SDKs.\\nTopics\\n• Get information about foundation models\\n• Supported foundation models in Amazon Bedrock\\n • Model support by AWS Region in Amazon Bedrock\\n• Feature support by AWS Region in Amazon Bedrock\\n• Model support by feature\\n• Inference request parameters and response fields for foundation models\\n• Custom model hyperparameters\\n• Model lifecycle\\n36\\nAmazon Bedrock User Guide\\nGet information about foundation models\\nIn the Amazon Bedrock console, you can find overarching information about Amazon Bedrock\\nfoundation model providers and the models they provide in the Providers and Base models\\nsections.\\nUse the API to retrieve information about Amazon Bedrock foundation model, including its\\nARN, model ID, modalities and features it supports, and whether it is deprecated or not, in a\\nFoundationModelSummary object.\\n• To return information about all the foundation models that Amazon Bedrock provides, send a\\nListFoundationModels request.\\nNote\\nThe response also returns model IDs that aren't in the base model ID or base model IDs\\n for Provisioned Throughput charts. These model IDs are deprecated or for backwards\\ncompability.\\n• To return information about a specific foundation model, send a GetFoundationModel request,\\nspecifying the model ID.\\nChoose a tab to see code examples in an interface or language.\\nAWS CLI\\nList the Amazon Bedrock foundation models.\\naws bedrock list-foundation-models\\nGet information about Anthropic Claude v2.\\naws bedrock get-foundation-model --model-identifier anthropic.claude-v2\\nPython\\nList the Amazon Bedrock foundation models.\\nimport boto3\\nbedrock = boto3.client(service_name='bedrock')\\nGet model information 37\\nAmazon Bedrock User Guide\\nbedrock.list_foundation_models()\\nGet information about Anthropic Claude v2.\\nimport boto3\\nbedrock = boto3.client(service_name='bedrock')\\nbedrock.get_foundation_model(modelIdentifier='anthropic.claude-v2')\\nSupported foundation models in Amazon Bedrock\\nAmazon Bedrock supports foundation models (FMs) from multiple providers.\\n\"},\n",
       " {'question': 'What are the two main prerequisites for running Amazon Bedrock examples?',\n",
       "  'ground_truth': 'The two main prerequisites are having an AWS account with necessary permissions for Amazon Bedrock, and requesting access to the Amazon Titan Text G1 - Express model.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': 'up properly. Before you run the following examples, you should check that you have fulfilled the\\nfollowing prerequisites:\\nPrerequisites\\n• You have an AWS account and have permissions to access a role with the necessary permissions\\nfor Amazon Bedrock. Otherwise, follow the steps at I already have an AWS account.\\n• You\\'ve requested access to the Amazon Titan Text G1 - Express model. Otherwise, follow the\\nsteps at Request access to an Amazon Bedrock foundation model.\\n• Carry out the following steps to set up IAM permissions for SageMaker AI and create a notebook:\\n1. Modify the trust policy of the Amazon Bedrock role that you set up in I already have an AWS\\naccount through the console, CLI, or API. Attach the following trust policy to the role to\\nallow both the Amazon Bedrock and SageMaker AI services to assume the Amazon Bedrock\\nrole:\\n{\\n\"Version\": \"2012-10-17\",\\n\"Statement\": [\\n{\\n\"Sid\": \"BedrockTrust\",\\n\"Effect\": \"Allow\",\\n\"Principal\": {\\n\"Service\": \"bedrock.amazonaws.com\"\\n},\\n Run examples with a SageMaker AI notebook 24\\nAmazon Bedrock User Guide\\n\"Action\": \"sts:AssumeRole\"\\n},\\n{\\n\"Sid\": \"SagemakerTrust\",\\n\"Effect\": \"Allow\",\\n\"Principal\": {\\n\"Service\": \"sagemaker.amazonaws.com\"\\n},\\n\"Action\": \"sts:AssumeRole\"\\n}\\n]\\n}\\n2. Sign into the Amazon Bedrock role whose trust policy you just modified.\\n3. Follow the steps at Create an Amazon SageMaker AI Notebook Instance for the tutorial and\\nspecify the ARN of the Amazon Bedrock role that you created to create an SageMaker AI\\nnotebook instance.\\n4. When the Status of the notebook instance is InService, choose the instance and then choose\\nOpen JupyterLab.\\nAfter you open up your SageMaker AI notebook, you can try out the following examples:\\nTopics\\n• List the foundation models that Amazon Bedrock has to offer\\n• Submit a text prompt to a model and generate a response\\nList the foundation models that Amazon Bedrock has to offer\\nThe following example runs the ListFoundationModels operation using an Amazon Bedrock client.\\n ListFoundationModels lists the foundation models (FMs) that are available in Amazon Bedrock\\nin your region. Run the following SDK for Python script to create an Amazon Bedrock client and\\ntest the ListFoundationModels operation:\\n# Use the ListFoundationModels API to show the models that are available in your\\nregion.\\nimport boto3\\n# Create an &BR; client in the &region-us-east-1; Region.\\nbedrock = boto3.client(\\nRun examples with a SageMaker AI notebook 25\\nAmazon Bedrock User Guide\\nservice_name=\"bedrock\"\\n)\\nbedrock.list_foundation_models()\\nIf the script is successful, the response returns a list of foundation models that are available in\\nAmazon Bedrock.\\nSubmit a text prompt to a model and generate a response\\nThe following example runs the Converse operation using an Amazon Bedrock client. Converse\\nlets you submit a prompt to generate a model response. Run the following SDK for Python script to\\ncreate an Amazon Bedrock runtime client and test the Converse operation:\\n'},\n",
       " {'question': 'Which AI model has the most widespread availability across different AWS regions, and what unique pattern does its availability follow compared to other models?',\n",
       "  'ground_truth': 'The AI model with the most widespread availability across different AWS regions is Anthropic\\'s Claude 3 Sonnet. It has a unique availability pattern compared to other models, being available in 11 out of the 17 listed regions. What makes its pattern distinct is that it\\'s the only model available in some regions where others aren\\'t, such as AWS GovCloud (US-West), and it has \"Gated\" access in regions like Asia Pacific (Mumbai) and Europe (Frankfurt). Additionally, it\\'s marked with asterisks (*) in several regions, indicating potential limitations or special conditions for its use in those areas.',\n",
       "  'question_type': 'complex',\n",
       "  'contexts': 'ModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAmazon\\nYes No Yes No No No No Yes No Yes Yes Yes No GatedYes Yes Yes\\nTitan\\nText\\nG1\\n-\\nLite\\nAmazon\\nYes No No No No No No No No No No No No No No No No\\nTitan\\nText\\nG1\\n-\\nPremier\\nAnthropic\\nYes No Yes No No Yes No No No No No Yes No No No No No\\nClaude\\n2.1\\nAnthropic\\nYes No Yes No No No No No GatedNo No Yes No No No No No\\nClaude\\n2\\nAnthropic\\nYes Yes* Yes Yes* Yes Yes Yes Yes GatedYes Yes Yes Yes GatedYes Yes Yes\\nClaude\\n3\\nHaiku\\nAnthropic\\nYes* No Yes No No No No No No No No No No No No No No\\nClaude\\n3\\nOpus\\nModel support by Region 74\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAnthropic\\nYes No Yes No No Yes* Yes* Yes GatedYes Yes Yes No GatedYes Yes Yes\\nClaude\\n3\\nSonnet\\nAnthropic\\nYes* Yes* Yes No No No No No No No No No No No No No No\\nClaude\\n3.5\\nHaiku\\nAnthropic\\nYes* No Yes No No No No No No No No No No No No No No\\nClaude\\n3.5\\nSonnet\\nv2\\nAnthropic\\nYes Yes* Yes Yes* Yes Yes Yes Yes* GatedYes* No Yes Yes GatedNo Yes* No\\nClaude\\n3.5\\nSonnet\\nAnthropic\\nYes No Yes No No Yes No No GatedNo No Yes No No No No No\\nClaude\\nInstant\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nLight\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nR+\\nModel support by Region 75\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nR\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nEnglish\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nMultiling\\nual\\nCohere\\nNo No Yes No No Yes No No No No Yes Yes No No No No No\\nRerank\\n3.5\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n8B\\nInstruct\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n70B\\nInstruct\\nModel support by Region 76\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n'},\n",
       " {'question': 'Which Llama 3.2 model supports both text and image input?',\n",
       "  'ground_truth': 'The Llama 3.2 11B and 90B models support both text and image input modalities.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': 'centra\\nl-1\\neu-\\nwest-2\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 8B a3-1-8b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 70B a3-1-70b- east-1* Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2\\nSupported foundation models 62\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 a3-1-405b east-2* Chat\\n405B -\\nus-\\nInstruct instruct\\nwest-2\\n-v1:0\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.2 1B a3-2-1b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2*\\neu-\\ncentra\\nl-1*\\neu-\\nwest-1\\n(Gated)*\\neu-\\nwest-3*\\nSupported foundation models 63\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\n Meta Llama meta.llam us- Text Text, Yes Link N/A\\n3.2 3B a3-2-3b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2*\\neu-\\ncentra\\nl-1*\\neu-\\nwest-1\\n(Gated)*\\neu-\\nwest-3*\\nMeta Llama meta.llam us- Text, Text, Yes Link N/A\\n3.2 11B a3-2-11b- east-1* Image Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2*\\nSupported foundation models 64\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text, Text, Yes Link N/A\\n3.2 90B a3-2-90b- east-1* Image Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2*\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.3 70B a3-3-70b- east-1* Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2\\nus-\\nwest-2*\\nSupported foundation models 65\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\n Mistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI 7B istral-7b east-1\\nInstruct -\\nus-\\ninstruct\\nwest-2\\n-v0:2\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nSupported foundation models 66\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI Large istral-la east-1\\n(24.02) rge-2402-\\nus-\\nv1:0\\nwest-2\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nMistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI Large istral-la west-2\\n(24.07) rge-2407-\\nv1:0\\nSupported foundation models 67\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI Small istral- east-1\\n'},\n",
       " {'question': 'What are the key steps and considerations when requesting access to specific Amazon Bedrock foundation models, and how does the process differ for requesting access to all models?',\n",
       "  'ground_truth': 'When requesting access to specific Amazon Bedrock foundation models, users should first sign into the AWS Management Console and switch to their Amazon Bedrock IAM role. They then need to open the Amazon Bedrock console, ensure they\\'re in the US East (N. Virginia) region, and select \"Model access\" from the navigation pane. After reviewing the EULAs, users choose \"Modify model access\" and select \"Enable specific models.\" They can then request access to individual models or all models from a specific provider by selecting the appropriate checkboxes. For tutorials, it\\'s recommended to request access to at least Amazon Titan Text G1 - Express and Amazon Titan Image Generator G1 V1 models. The process differs for requesting access to all models by simply choosing \"Enable all models\" instead of \"Enable specific models.\" In both cases, users must review the selected models and terms before submitting the request. Access may take several minutes to be granted, and the status will change to \"Access granted\" once approved.',\n",
       "  'question_type': 'complex',\n",
       "  'contexts': \"After setting up your Amazon Bedrock IAM role, you can sign into the Amazon Bedrock console and\\nrequest access to foundation models.\\nTo request access to an Amazon Bedrock FM\\n1. Sign into the AWS Management Console and switch to the Amazon Bedrock role that you set\\nup (or that was set up for you) by following the steps under To switch to a role (console) in\\nSwitching to a role (console).\\n2. Open the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/.\\n3. For the purposes of this tutorial, you should be in the US East (N. Virginia) (us-east-1) Region.\\nTo change regions, choose the Region name at the top right of the console, next to your IAM\\nrole. Then select US East (N. Virginia) (us-east-1).\\n4. Select Model access at the bottom of the left navigation pane.\\n5. On the Model access page, you can review the End User License Agreement (EULA) for models\\nin the EULA column in the Base models table.\\n6. Choose Modify model access.\\n7. Do one of the following:\\n • To request access to all models, choose Enable all models. On the page you're taken to,\\nthe checkboxes next to all the models will be filled.\\n• To request access to specific models, choose Enable specific models. On the page you're\\ntaken to, you have the following options:\\nRequest access to an Amazon Bedrock foundation model 9\\nAmazon Bedrock User Guide\\n• To request access to all models by a provider, select the checkbox next to the provider\\nname.\\n• To request access to one model, select the checkbox next to the model name.\\n8. For the purposes of the following tutorials, you should minimally request access to the\\nAmazon Titan Text G1 - Express and Amazon Titan Image Generator G1 V1 models. Then\\nchoose Next.\\n9. Review the models that you're requesting access to and the Terms. When you're ready, choose\\nSubmit to request access.\\n10. Access may take several minutes to complete. When access is granted to a model, the Access\\nstatus for that model willbecome Access granted.\\n (Optional tutorials) Explore Amazon Bedrock features through\\nthe console or API\\nAfter requesting access to the foundation models that you want to use, you'll be ready to explore\\nthe different capabilities offered by Amazon Bedrock.\\nIf you want to familiarize yourself more with Amazon Bedrock first, you can continue to the\\nfollowing pages:\\n• To learn how to run basic prompts and generate model responses using the Playgrounds in the\\nAmazon Bedrock console, continue to Getting started in the Amazon Bedrock console.\\n• To learn how to set up access to Amazon Bedrock operations through the Amazon Bedrock API\\nand test out some API calls, continue to Getting started with the API.\\n• To learn about the software development kits (SDKs) supported by Amazon Bedrock, continue to\\nUsing Amazon Bedrock with an AWS SDK.\\nGetting started in the Amazon Bedrock console\\nThis section describes how to use the playgrounds in the AWS console to submit a text prompt to a\\n\"},\n",
       " {'question': 'Which Meta Llama model supports both text and image input?',\n",
       "  'ground_truth': 'The Meta Llama 3.2 11B and 90B Instruct models support both text and image input.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': 'Provider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nCohere Rerank cohere.re us- Text Text No Link N/A\\n3.5 rank- west-2\\nv3-5:0\\nap-\\nnorthe\\nast-1\\nca-\\ncentra\\nl-1\\neu-\\ncentra\\nl-1\\nSupported foundation models 60\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3 8B a3-8b- east-1 Chat\\nInstruct ins\\nus-\\ntruct-\\nwest-2\\nv1:0\\nus-gov-\\nwest-1\\nap-\\nsouth-1\\nca-\\ncentra\\nl-1\\neu-\\nwest-2\\nSupported foundation models 61\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3 70B a3-70b- east-1 Chat\\nInstruct in\\nus-\\nstruct-\\nwest-2\\nv1:0\\nus-gov-\\nwest-1\\nap-\\nsouth-1\\nca-\\n centra\\nl-1\\neu-\\nwest-2\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 8B a3-1-8b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 70B a3-1-70b- east-1* Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2\\nSupported foundation models 62\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.1 a3-1-405b east-2* Chat\\n405B -\\nus-\\nInstruct instruct\\nwest-2\\n-v1:0\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.2 1B a3-2-1b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2*\\neu-\\ncentra\\nl-1*\\neu-\\nwest-1\\n(Gated)*\\neu-\\nwest-3*\\nSupported foundation models 63\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\n Meta Llama meta.llam us- Text Text, Yes Link N/A\\n3.2 3B a3-2-3b- east-1* Chat\\nInstruct i\\nus-\\nnstruct-\\neast-2*\\nv1:0\\nus-\\nwest-2*\\neu-\\ncentra\\nl-1*\\neu-\\nwest-1\\n(Gated)*\\neu-\\nwest-3*\\nMeta Llama meta.llam us- Text, Text, Yes Link N/A\\n3.2 11B a3-2-11b- east-1* Image Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2*\\nSupported foundation models 64\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMeta Llama meta.llam us- Text, Text, Yes Link N/A\\n3.2 90B a3-2-90b- east-1* Image Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2*\\nus-\\nwest-2*\\nMeta Llama meta.llam us- Text Text, Yes Link N/A\\n3.3 70B a3-3-70b- east-1* Chat\\nInstruct instruct-\\nus-\\nv1:0\\neast-2\\nus-\\nwest-2*\\nSupported foundation models 65\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\n'},\n",
       " {'question': 'How do the capabilities of Claude 3 Haiku, Claude 3 Opus, and Claude 3 Sonnet differ in terms of input modalities, regional availability, and potential use cases based on their characteristics?',\n",
       "  'ground_truth': \"Claude 3 Haiku, Opus, and Sonnet have distinct capabilities:\\n\\n1. Input modalities:\\nAll three models support both text and image inputs.\\n\\n2. Regional availability:\\n- Claude 3 Haiku: Available in 19 regions, including various US, Asia Pacific, European, and South American regions.\\n- Claude 3 Opus: Limited availability in us-east-1 and us-west-2 regions.\\n- Claude 3 Sonnet: Available in 13 regions, covering US, Asia Pacific, European, and South American areas.\\n\\n3. Potential use cases based on characteristics:\\n- Claude 3 Haiku: Widest regional availability suggests it's suitable for global applications requiring broad geographic coverage.\\n- Claude 3 Opus: Limited regional availability might indicate it's a more specialized or powerful model, potentially for high-performance tasks in specific regions.\\n- Claude 3 Sonnet: Balanced regional availability, potentially for applications requiring good performance and wider geographic reach than Opus, but not as extensive as Haiku.\\n\\nThe differences in regional availability might impact latency, compliance requirements, and scalability of applications using these models. Users should choose the appropriate model based on their specific needs for performance, geographic reach, and potentially, cost considerations.\",\n",
       "  'question_type': 'complex',\n",
       "  'contexts': 'Provider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\neu-\\nwest-3\\nsa-\\neast-1\\nSupported foundation models 46\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAmazon Titan amazon.ti us- Text Text Yes Link Link\\nText G1 tan- east-1\\n- Lite text-\\nus-\\nlite-v1\\nwest-2\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\ncentra\\nl-1\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nSupported foundation models 47\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAmazon Titan amazon.ti us- Text Text Yes Link Link\\nText tan- east-1\\nG1 - text-\\nPremier premier-\\nv1:0\\nAnthropic Claude anthropic us- Text Text, Yes Link N/A\\n2.1 .claude- east-1 Chat\\nv2:1\\nus-\\nwest-2\\nap-\\nnorthe\\nast-1\\neu-\\ncentra\\n l-1\\nAnthropic Claude anthropic us- Text Text, Yes Link N/A\\n2 .claude- east-1 Chat\\nv2\\nus-\\nwest-2\\nap-\\nsouthe\\nast-1\\n(Gated)\\neu-\\ncentra\\nl-1\\nSupported foundation models 48\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n3 Haiku .claude-3 east-1 Image Chat\\n-\\nus-\\nhaiku-20\\neast-2*\\n240307-\\nv1:0\\nus-\\nwest-2\\nus-gov-\\neast-1*\\nus-gov-\\nwest-1\\nap-\\nnorthe\\nast-1\\nap-\\nnorthe\\nast-2\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-1\\n(Gated)\\nap-\\nsouthe\\nast-1\\n(Gated)\\nSupported foundation models 49\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\ncentra\\nl-1\\neu-\\ncentra\\nl-2\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n 3 Opus .claude-3 east-1* Image Chat\\n-\\nus-\\nopus-202\\nwest-2\\n40229-\\nv1:0\\nSupported foundation models 50\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n3 .claude-3 east-1 Image Chat\\nSonnet -\\nus-\\nsonnet-2\\nwest-2\\n0240229-\\nv1:0\\nap-\\nnorthe\\nast-1*\\nap-\\nnorthe\\nast-2*\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-1\\n(Gated)*\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\ncentra\\nl-1\\nSupported foundation models 51\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n3.5 .claude-3 east-1* Image Chat\\nHaiku -5-\\nus-\\nhaiku-\\neast-2*\\n20241022-\\nv1:0\\nus-\\nwest-2\\nAnthropic Claude anthropic us- Text, Text, Yes Link N/A\\n'},\n",
       " {'question': 'How can you make IAM user access keys time-bound?',\n",
       "  'ground_truth': 'You can make IAM user access keys time-bound by creating an inline policy that specifies a date after which the keys will no longer be valid. This ensures that the credentials expire in case they are mishandled.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': \"• For AWS SDKs and tools,\\nsee Authenticate using\\nlong-term credentials in\\nthe AWS SDKs and Tools\\nReference Guide.\\n• For AWS APIs, see\\nManaging access keys for\\nIAM users in the IAM User\\nGuide.\\nIAM roles Use temporary credentials to Following the instructions in\\nsign programmatic requests Using temporary credentia\\nto the AWS CLI, AWS SDKs, or ls with AWS resources in the\\nAWS APIs. IAM User Guide.\\nWorkforce identity Use temporary credentials to Following the instructions for\\nsign programmatic requests the interface that you want to\\n(Users managed in IAM\\nto the AWS CLI, AWS SDKs, or use.\\nIdentity Center)\\nAWS APIs.\\n• For the AWS CLI, see\\nConfiguring the AWS\\nCLI to use AWS IAM\\nIdentity Center in the AWS\\nCommand Line Interface\\nUser Guide.\\nGet credentials to grant programmatic access 14\\nAmazon Bedrock User Guide\\nWhich principal needs To By\\nprogrammatic access?\\n• For AWS SDKs, tools, and\\nAWS APIs, see IAM Identity\\nCenter authentication in\\nthe AWS SDKs and Tools\\nReference Guide.\\n How to configure access keys for an IAM user\\nIf you decide to use access keys for an IAM user, AWS recommends that you set an expiration for\\nthe IAM user by including a restrictive inline policy.\\nImportant\\nHeed the following warnings:\\n• Do NOT use your account's root credentials to access AWS resources. These credentials\\nprovide unrestricted account access and are difficult to revoke.\\n• Do NOT put literal access keys or credential information in your application files. If you\\ndo, you create a risk of accidentally exposing your credentials if, for example, you upload\\nthe project to a public repository.\\n• Do NOT include files that contain credentials in your project area.\\n• Manage your access keys securely. Do not provide your access keys to unauthorized\\nparties, even to help find your account identifiers. By doing this, you might give someone\\npermanent access to your account.\\n• Be aware that any credentials stored in the shared AWS credentials file are stored in\\nplaintext.\\n For more details, see Best practices for managing AWS access keys in the AWS General Reference.\\nCreate an IAM user\\n1. On the AWS Management Console Home page, select the IAM service or navigate to the IAM\\nconsole at https://console.aws.amazon.com/iam/.\\nGet credentials to grant programmatic access 15\\nAmazon Bedrock User Guide\\n2. In the navigation pane, select Users and then select Create user.\\n3. Follow the guidance in the IAM console to set up a programmatic user (without access to the\\nAWS Management Console) and without permissions.\\nRestrict user access to a limited time window\\nAny IAM user access keys that you create are long-term credentials. To ensure that these\\ncredentials expire in case they are mishandled, you can make these credentials time-bound by\\ncreating an inline policy that specifies a date after which the keys will no longer be valid.\\n1. Open the IAM user that you just created. In the Permissions tab, choose Add permissions and\\nthen choose Create inline policy.\\n\"},\n",
       " {'question': 'How does the process of granting access to Anthropic models in Amazon Bedrock differ from other models, and what additional steps are required for AWS GovCloud (US) customers?',\n",
       "  'ground_truth': 'The process of granting access to Anthropic models in Amazon Bedrock requires additional steps compared to other models. After selecting the Anthropic models, users must describe their use case details by submitting a form. Access is then granted or denied based on the answers provided in this form.\\n\\nFor AWS GovCloud (US) customers, the process involves extra steps:\\n1. They must first locate their standard AWS account ID associated with their AWS GovCloud (US) account ID.\\n2. They need to navigate to the model access page on the Amazon Bedrock console.\\n3. Select the desired model(s) to enable.\\n4. Choose \"Request model access\" and follow the step-by-step subscription flow.\\n\\nThese additional requirements for Anthropic models and AWS GovCloud (US) customers ensure a more thorough vetting process and compliance with specific regulations, distinguishing them from the standard access granting procedure for other models in Amazon Bedrock.',\n",
       "  'question_type': 'complex',\n",
       "  'contexts': \"using an IAM policy and specifying the model ID. For more information, see Deny access for\\ninference of foundation models.\\nOnce access is provided to a model, it is available for all users in the AWS account.\\nTo add or remove access to foundation models\\n1. Make sure you have permissions to request access, or modify access, to Amazon Bedrock\\nfoundation models.\\n2. Sign into the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/.\\n3. In the left navigation pane, under Bedrock configurations, choose Model access.\\n4. On the Model access page, choose Modify model access.\\n5. Select the models that you want the account to have access to and unselect the models that\\nyou don't want the account to have access to. You have the following options:\\nAdd or remove access to foundation models 32\\nAmazon Bedrock User Guide\\nBe sure to review the End User License Agreement (EULA) for terms and conditions of using a\\nmodel before requesting access to it.\\n • Select the check box next to an individual model to check or uncheck it.\\n• Select the top check box to check or uncheck all models.\\n• Select how the models are grouped and then check or uncheck all the models in a group\\nby selecting the check box next to the group. For example, you can choose to Group by\\nprovider and then select the check box next to Cohere to check or uncheck all Cohere\\nmodels.\\n6. Choose Next.\\n7. If you add access to Anthropic models, you must describe your use case details. Choose Submit\\nuse case details, fill out the form, and then select Submit form. Notification of access is\\ngranted or denied based on your answers when completing the form for the provider.\\n8. Review the access changes you're making, and then read the Terms.\\nNote\\nYour use of Amazon Bedrock foundation models is subject to the seller's pricing terms,\\nEULA, and the AWS service terms.\\n9. If you agree with the terms, choose Submit. The changes can take several minutes to be\\nreflected in the console.\\n Note\\nIf you revoke access to a model, it can still be accessed through the API for some time\\nafter you complete this action while the changes propagate. To immediately remove\\naccess in the meantime, add an IAM policy to a role to deny access to the model.\\n10. If your request is successful, the Access status changes to Access granted or Available to\\nrequest.\\nNote\\nFor AWS GovCloud (US) customers, follow these steps to access models that are available in\\nAWS GovCloud (US):\\nAdd or remove access to foundation models 33\\nAmazon Bedrock User Guide\\n• AWS GovCloud (US) users must locate their standard AWS account ID associated with\\ntheir AWS GovCloud (US) account ID. AWS GovCloud (US) users can follow this guide\\nFinding your associated standard AWS account ID, if they don't already know their ID.\\nNavigate to the model access page on Amazon Bedrock console. Select the model(s)\\nthat you want to enable. Select Request model access and follow the step-by-step\\nsubscription flow.\\n\"},\n",
       " {'question': 'What is embedding in the context of Amazon Bedrock?',\n",
       "  'ground_truth': 'Embedding is the process of condensing information by transforming input into a vector of numerical values, known as embeddings, to compare similarity between different objects using a shared numerical representation. It can be used to compare sentences, images, or even text and images for relevance or similarity.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': \"of a response or the occurrence of specified sequences. For more information and definitions of\\nspecific inference parameters, see Influence response generation with inference parameters.\\n• Playground – A user-friendly graphical interface in the AWS Management Console in which\\nyou can experiment with running model inference to familiarize yourself with Amazon Bedrock.\\nUse the playground to test out the effects of different models, configurations, and inference\\nparameters on the responses generated for different prompts that you enter. For more\\ninformation, see Generate responses in the console using playgrounds.\\n• Embedding – The process of condensing information by transforming input into a vector\\nof numerical values, known as the embeddings, in order to compare the similarity between\\ndifferent objects by using a shared numerical representation. For example, sentences can be\\ncompared to determine the similarity in meaning, images can be compared to determine visual\\n similarity, or text and image can be compared to see if they're relevant to each other. You can\\nalso combine text and image inputs into an averaged embeddings vector if it's relevant to\\nyour use case. For more information, see Submit prompts and generate responses with model\\ninference and Retrieve data and generate AI responses with Amazon Bedrock Knowledge Bases.\\nKey terminology 4\\nAmazon Bedrock User Guide\\n• Orchestration – The process of coordinating between foundation models and enterprise data\\nand applications in order to carry out a task. For more information, see Automate tasks in your\\napplication using AI agents.\\n• Agent – An application that carry out orchestrations through cyclically interpreting inputs and\\nproducing outputs by using a foundation model. An agent can be used to carry out customer\\nrequests. For more information, see Automate tasks in your application using AI agents.\\n• Retrieval augmented generation (RAG) – The process of querying and retrieving information\\n from a data source in order to augment a generated response to a prompt. For more\\ninformation, see Retrieve data and generate AI responses with Amazon Bedrock Knowledge\\nBases.\\n• Model customization – The process of using training data to adjust the model parameter values\\nin a base model in order to create a custom model. Examples of model customization include\\nFine-tuning, which uses labeled data (inputs and corresponding outputs), and Continued\\nPre-training, which uses unlabeled data (inputs only) to adjust model parameters. For more\\ninformation about model customization techniques available in Amazon Bedrock, see Customize\\nyour model to improve its performance for your use case.\\n• Hyperparameters – Values that can be adjusted for model customization to control the training\\nprocess and, consequently, the output custom model. For more information and definitions of\\nspecific hyperparameters, see Custom model hyperparameters.\\n\"},\n",
       " {'question': 'Which AI model offers the most comprehensive global coverage, and how does its availability compare to other models in key regions like US East, Europe, and Asia Pacific?',\n",
       "  'ground_truth': 'Based on the information provided, Claude 3 Sonnet by Anthropic offers the most comprehensive global coverage. It is available in most regions, including US East (N. Virginia), Europe (Frankfurt, London, Paris), and multiple Asia Pacific locations. \\n\\nSpecifically:\\n- It\\'s available in US East (N. Virginia), US West (Oregon), and Canada.\\n- In Europe, it\\'s available in Frankfurt, London, and Paris.\\n- In Asia Pacific, it\\'s available in Tokyo, Seoul, Mumbai, Singapore, and Sydney.\\n- It\\'s also available in São Paulo (South America) and marked as \"Gated\" in AWS GovCloud.\\n\\nCompared to other models:\\n- Most Amazon Titan models have limited availability outside the US.\\n- Other Anthropic models like Claude 2 and Claude Instant have more limited regional availability.\\n- Cohere and Meta models are generally available in fewer regions.\\n\\nClaude 3 Sonnet stands out for its wide availability across North America, Europe, Asia Pacific, and South America, making it one of the most globally accessible AI models in the lineup.',\n",
       "  'question_type': 'complex',\n",
       "  'contexts': 'ModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAmazon\\nYes No Yes No No No No Yes No Yes Yes Yes No GatedYes Yes Yes\\nTitan\\nText\\nG1\\n-\\nLite\\nAmazon\\nYes No No No No No No No No No No No No No No No No\\nTitan\\nText\\nG1\\n-\\nPremier\\nAnthropic\\nYes No Yes No No Yes No No No No No Yes No No No No No\\nClaude\\n2.1\\nAnthropic\\nYes No Yes No No No No No GatedNo No Yes No No No No No\\nClaude\\n2\\nAnthropic\\nYes Yes* Yes Yes* Yes Yes Yes Yes GatedYes Yes Yes Yes GatedYes Yes Yes\\nClaude\\n3\\nHaiku\\nAnthropic\\nYes* No Yes No No No No No No No No No No No No No No\\nClaude\\n3\\nOpus\\nModel support by Region 74\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAnthropic\\nYes No Yes No No Yes* Yes* Yes GatedYes Yes Yes No GatedYes Yes Yes\\nClaude\\n3\\nSonnet\\nAnthropic\\nYes* Yes* Yes No No No No No No No No No No No No No No\\nClaude\\n3.5\\nHaiku\\nAnthropic\\nYes* No Yes No No No No No No No No No No No No No No\\nClaude\\n3.5\\nSonnet\\nv2\\nAnthropic\\nYes Yes* Yes Yes* Yes Yes Yes Yes* GatedYes* No Yes Yes GatedNo Yes* No\\nClaude\\n3.5\\nSonnet\\nAnthropic\\nYes No Yes No No Yes No No GatedNo No Yes No No No No No\\nClaude\\nInstant\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nLight\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nR+\\nModel support by Region 75\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nR\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nEnglish\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nMultiling\\nual\\nCohere\\nNo No Yes No No Yes No No No No Yes Yes No No No No No\\nRerank\\n3.5\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n8B\\nInstruct\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n70B\\nInstruct\\nModel support by Region 76\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n'},\n",
       " {'question': 'Which regions support the Cohere Command model?',\n",
       "  'ground_truth': 'The Cohere Command model is supported in US East (N. Virginia) and US West (Oregon) regions.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': 'East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nR\\nCohere\\nYes No Yes No No No No No No No No No No No No No No\\nCommand\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nEnglish\\nCohere\\nYes No Yes No No Yes No Yes GatedYes Yes Yes No GatedYes Yes Yes\\nEmbed\\nMultiling\\nual\\nCohere\\nNo No Yes No No Yes No No No No Yes Yes No No No No No\\nRerank\\n3.5\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n8B\\nInstruct\\nMeta\\nYes No Yes No Yes No No Yes No No Yes No No No Yes No No\\nLlama\\n3\\n70B\\nInstruct\\nModel support by Region 76\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\n East East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nMeta\\nYes* Yes* Yes No No No No No No No No No No No No No No\\nLlama\\n3.1\\n8B\\nInstruct\\nMeta\\nYes* Yes* Yes No No No No No No No No No No No No No No\\nLlama\\n3.1\\n70B\\nInstruct\\nMeta\\nNo Yes* Yes No No No No No No No No No No No No No No\\nLlama\\n3.1\\n405B\\nInstruct\\nMeta\\nYes* Yes* Yes* No No No No No No No No Yes* No GatedNo Yes* No\\nLlama\\n3.2\\n1B\\nInstruct\\nMeta\\nYes* Yes* Yes* No No No No No No No No Yes* No GatedNo Yes* No\\nLlama\\n3.2\\n3B\\nInstruct\\nModel support by Region 77\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n (N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nMeta\\nYes* Yes* Yes* No No No No No No No No No No No No No No\\nLlama\\n3.2\\n11B\\nInstruct\\nMeta\\nYes* Yes* Yes* No No No No No No No No No No No No No No\\nLlama\\n3.2\\n90B\\nInstruct\\nMeta\\nYes* Yes Yes* No No No No No No No No No No No No No No\\nLlama\\n3.3\\n70B\\nInstruct\\nMistral\\nYes No Yes No No No No Yes No Yes Yes No No GatedYes Yes Yes\\nAI\\nMistral\\n7B\\nInstruct\\nMistral\\nYes No Yes No No No No Yes No Yes Yes No No GatedYes Yes Yes\\nAI\\nMistral\\nLarge\\n(24.02)\\nModel support by Region 78\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nMistral\\nNo No Yes No No No No No No No No No No No No No No\\n'},\n",
       " {'question': 'How does the InvokeModel operation in Amazon Bedrock handle model-specific configurations, and what are the key components of the request payload when using the AWS SDK for Python?',\n",
       "  'ground_truth': 'The InvokeModel operation in Amazon Bedrock handles model-specific configurations through a structured request payload that is formatted according to the model\\'s native structure. When using the AWS SDK for Python, the key components of the request payload include:\\n\\n1. The input text or prompt for the model.\\n2. A textGenerationConfig object containing parameters such as:\\n   - maxTokenCount: to limit the length of the generated response\\n   - temperature: to control the randomness of the output\\n   - topP: to influence the diversity of the generated text\\n\\nThe payload is then converted to JSON format before being sent to the model. For example, with the Amazon Titan Text G1 - Express model, the request payload would look like this:\\n\\n{\\n  \"inputText\": \"Describe the purpose of a \\'hello world\\' program in one line.\",\\n  \"textGenerationConfig\": {\\n    \"maxTokenCount\": 512,\\n    \"temperature\": 0.5,\\n    \"topP\": 0.9\\n  }\\n}\\n\\nThis structured approach allows for flexible configuration of different models while maintaining a consistent interface for the InvokeModel operation across various foundation models in Amazon Bedrock.',\n",
       "  'question_type': 'complex',\n",
       "  'contexts': 'languages. For more information, see Code examples for Amazon Bedrock using AWS SDKs.\\nTopics\\n• List the foundation models that Amazon Bedrock has to offer\\n• Submit a text prompt to a model and generate a text response with InvokeModel\\n• Submit a text prompt to a model and generate a text response with Converse\\nList the foundation models that Amazon Bedrock has to offer\\nThe following example runs the ListFoundationModels operation using an Amazon Bedrock client.\\nListFoundationModels lists the foundation models (FMs) that are available in Amazon Bedrock\\nin your region. Run the following SDK for Python script to create an Amazon Bedrock client and\\ntest the ListFoundationModels operation:\\n# Use the ListFoundationModels API to show the models that are available in your\\nregion.\\nimport boto3\\n# Create an &BR; client in the &region-us-east-1; Region.\\nbedrock = boto3.client(\\nservice_name=\"bedrock\"\\n)\\nbedrock.list_foundation_models()\\n If the script is successful, the response returns a list of foundation models that are available in\\nAmazon Bedrock.\\nSubmit a text prompt to a model and generate a text response with InvokeModel\\nThe following example runs the InvokeModel operation using an Amazon Bedrock client.\\nInvokeModel lets you submit a prompt to generate a model response. Run the following SDK for\\nPython script to create an Amazon Bedrock runtime client and generate a text response with the\\noperation:\\nRun examples with the AWS SDK for Python (Boto3) 21\\nAmazon Bedrock User Guide\\n# Use the native inference API to send a text message to Amazon Titan Text G1 -\\nExpress.\\nimport boto3\\nimport json\\nfrom botocore.exceptions import ClientError\\n# Create an Amazon Bedrock Runtime client.\\nbrt = boto3.client(\"bedrock-runtime\")\\n# Set the model ID, e.g., Amazon Titan Text G1 - Express.\\nmodel_id = \"amazon.titan-text-express-v1\"\\n# Define the prompt for the model.\\n prompt = \"Describe the purpose of a \\'hello world\\' program in one line.\"\\n# Format the request payload using the model\\'s native structure.\\nnative_request = {\\n\"inputText\": prompt,\\n\"textGenerationConfig\": {\\n\"maxTokenCount\": 512,\\n\"temperature\": 0.5,\\n\"topP\": 0.9\\n},\\n}\\n# Convert the native request to JSON.\\nrequest = json.dumps(native_request)\\ntry:\\n# Invoke the model with the request.\\nresponse = brt.invoke_model(modelId=model_id, body=request)\\nexcept (ClientError, Exception) as e:\\nprint(f\"ERROR: Can\\'t invoke \\'{model_id}\\'. Reason: {e}\")\\nexit(1)\\n# Decode the response body.\\nmodel_response = json.loads(response[\"body\"].read())\\n# Extract and print the response text.\\nresponse_text = model_response[\"results\"][0][\"outputText\"]\\nRun examples with the AWS SDK for Python (Boto3) 22\\nAmazon Bedrock User Guide\\nprint(response_text)\\nIf the command is successful, the response returns the text generated by the model in response to\\nthe prompt.\\n'},\n",
       " {'question': 'How can you secure your AWS account root user?',\n",
       "  'ground_truth': 'To secure your AWS account root user, you should turn on multi-factor authentication (MFA) for the root user.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': \"and choosing My Account.\\nSecure your AWS account root user\\n1. Sign in to the AWS Management Console as the account owner by choosing Root user and\\nentering your AWS account email address. On the next page, enter your password.\\nFor help signing in by using root user, see Signing in as the root user in the AWS Sign-In User\\nGuide.\\n2. Turn on multi-factor authentication (MFA) for your root user.\\nFor instructions, see Enable a virtual MFA device for your AWS account root user (console) in\\nthe IAM User Guide.\\nI need to install the AWS CLI or an AWS SDK\\nTo install the AWS CLI, follow the steps at Install or update to the latest version of the AWS CLI.\\nTo install an AWS SDK, select the tab that corresponds to the programming language that you\\nwant to use at Tools to Build on AWS. AWS software development kits (SDKs) are available\\nfor many popular programming languages. Each SDK provides an API, code examples, and\\n documentation that make it easier for developers to build applications in their preferred language.\\nSDKs automatically perform useful tasks for you, such as:\\n• Cryptographically sign your service requests\\n• Retry requests\\n• Handle error responses\\nGet credentials to grant programmatic access\\nUsers need programmatic access if they want to interact with AWS outside of the AWS\\nManagement Console. The way to grant programmatic access depends on the type of user that's\\naccessing AWS.\\nTo grant users programmatic access, choose one of the following options.\\nGet credentials to grant programmatic access 13\\nAmazon Bedrock User Guide\\nWhich principal needs To By\\nprogrammatic access?\\nIAM users Limit the duration of long- Following the instructions for\\nterm credentials to sign the interface that you want to\\nprogrammatic requests to the use.\\nAWS CLI, AWS SDKs, or AWS\\n• For the AWS CLI, see\\nAPIs.\\nAuthenticating using IAM\\nuser credentials in the AWS\\nCommand Line Interface\\nUser Guide.\\n • For AWS SDKs and tools,\\nsee Authenticate using\\nlong-term credentials in\\nthe AWS SDKs and Tools\\nReference Guide.\\n• For AWS APIs, see\\nManaging access keys for\\nIAM users in the IAM User\\nGuide.\\nIAM roles Use temporary credentials to Following the instructions in\\nsign programmatic requests Using temporary credentia\\nto the AWS CLI, AWS SDKs, or ls with AWS resources in the\\nAWS APIs. IAM User Guide.\\nWorkforce identity Use temporary credentials to Following the instructions for\\nsign programmatic requests the interface that you want to\\n(Users managed in IAM\\nto the AWS CLI, AWS SDKs, or use.\\nIdentity Center)\\nAWS APIs.\\n• For the AWS CLI, see\\nConfiguring the AWS\\nCLI to use AWS IAM\\nIdentity Center in the AWS\\nCommand Line Interface\\nUser Guide.\\nGet credentials to grant programmatic access 14\\nAmazon Bedrock User Guide\\nWhich principal needs To By\\nprogrammatic access?\\n• For AWS SDKs, tools, and\\nAWS APIs, see IAM Identity\\nCenter authentication in\\nthe AWS SDKs and Tools\\nReference Guide.\\n\"},\n",
       " {'question': 'How does the regional availability of Amazon Nova models compare to AI21 Labs models in Amazon Bedrock, and what implications might this have for developers choosing between these providers?',\n",
       "  'ground_truth': 'The regional availability of Amazon Nova models is broader compared to AI21 Labs models in Amazon Bedrock. Amazon Nova models (Lite, Micro, and Pro) are available in US East (N. Virginia), and have cross-region inference support in US East (Ohio) and US West (Oregon). In contrast, AI21 Labs models (Jamba 1.5 Large, Jamba 1.5 Mini, and Jamba-Instruct) are only available in US East (N. Virginia) with no cross-region inference support mentioned. This difference in availability implies that developers choosing Amazon Nova models have more flexibility in terms of geographical deployment and potentially lower latency for users in different regions. However, those requiring AI21 Labs models may face limitations in regional deployment options and possible higher latency for users outside the US East region.',\n",
       "  'question_type': 'complex',\n",
       "  'contexts': 'Stability Stable stability us- Text Image No Link N/A\\nAI Image .stable- west-2\\nUltra image-\\n1.0 ultra-\\nv1:1\\nSupported foundation models 69\\nAmazon Bedrock User Guide\\nNote\\n* Some models are accessible in some Regions only through cross-region inference. To learn\\nmore about cross-region inference, see Increase throughput with cross-region inference and\\nSupported Regions and models for inference profiles.\\nThe following table lists models that have a target date for deprecation. For more information, see\\nModel lifecycle:\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAI21 J2 ai21.j2- us- Text Text, No Link N/A\\nLabs Grande grande- east-1 Chat\\nInstruct instruct\\nAI21 J2 ai21.j2- us- Text Text, No Link N/A\\nLabs Jumbo jumbo- east-1 Chat\\nInstruct instruct\\nAI21 Jurassic- ai21.j2- us- Text Text, No Link N/A\\nLabs 2 Mid mid-v1 east-1 Chat\\nAI21 Jurassic- ai21.j2- us- Text Text, No Link N/A\\n Labs 2 Ultra ultra-v1 east-1 Chat\\nStability SDXL stability us- Text, Image No Link N/A\\nAI 1.0 .stable- east-1 Image\\nd\\nus-\\niffusion-\\nwest-2\\nxl-v1\\nSupported foundation models 70\\nAmazon Bedrock User Guide\\nModel support by AWS Region in Amazon Bedrock\\nFor a list of AWS Regions that support Amazon Bedrock, see Amazon Bedrock endpoints and\\nquotas. Amazon Bedrock foundation models differ in their regional support.\\nThe following table shows Region support by model:\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJamba\\n1.5\\nLarge\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJamba\\n1.5\\nMini\\nAI21\\n Yes No No No No No No No No No No No No No No No No\\nLabs\\nJamba-\\nIns\\ntruct\\nAmazon\\nYes No No No No No No No No No No No No No No No No\\nNova\\nCanvas\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nLite\\nModel support by Region 71\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nMicro\\nAmazon\\nYes Yes* Yes* No No No No No No No No No No No No No No\\nNova\\nPro\\nAmazon\\nYes No No No No No No No No No No No No No No No No\\nNova\\nReel\\nAmazon\\nNo No Yes No No Yes No No No No Yes Yes No No No No No\\nRerank\\n1.0\\nAmazon\\nYes No Yes No No Yes No No No No No Yes No No No No No\\nTitan\\nEmbedding\\ns\\nG1\\n-\\nText\\nAmazon\\n'},\n",
       " {'question': 'Which provider offers the Stable Diffusion 3.5 Large model in Amazon Bedrock?',\n",
       "  'ground_truth': 'Stability AI offers the Stable Diffusion 3.5 Large model in Amazon Bedrock.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': 'Mistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI 7B istral-7b east-1\\nInstruct -\\nus-\\ninstruct\\nwest-2\\n-v0:2\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nSupported foundation models 66\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI Large istral-la east-1\\n(24.02) rge-2402-\\nus-\\nv1:0\\nwest-2\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nMistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI Large istral-la west-2\\n(24.07) rge-2407-\\nv1:0\\nSupported foundation models 67\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nMistral Mistral mistral.m us- Text Text Yes Link N/A\\nAI Small istral- east-1\\n (24.02) sm\\nall-2402-\\nv1:0\\nMistral Mixtral mistral.m us- Text Text Yes Link N/A\\nAI 8x7B ixtral-8x east-1\\nInstruct 7b-\\nus-\\ninstru\\nwest-2\\nct-v0:1\\nap-\\nsouth-1\\nap-\\nsouthe\\nast-2\\nca-\\ncentra\\nl-1\\neu-\\nwest-1\\n(Gated)\\neu-\\nwest-2\\neu-\\nwest-3\\nsa-\\neast-1\\nSupported foundation models 68\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nStability SD3 stability us- Text, Image No Link N/A\\nAI Large .sd3- west-2 Image\\n1.0 large-\\nv1:0\\nStability Stable stability us- Text, Image No Link N/A\\nAI Diffusion .sd3-5- west-2 Image\\n3.5 large-\\nLarge v1:0\\nStability Stable stability us- Text Image No Link N/A\\nAI Image .stable- west-2\\nCore image-\\n1.0 core-\\nv1:0\\nStability Stable stability us- Text Image No Link N/A\\nAI Image .stable- west-2\\nCore image-\\n1.0 core-\\nv1:1\\nStability Stable stability us- Text Image No Link N/A\\nAI Image .stable- west-2\\nUltra image-\\n1.0 ultra-\\nv1:0\\n Stability Stable stability us- Text Image No Link N/A\\nAI Image .stable- west-2\\nUltra image-\\n1.0 ultra-\\nv1:1\\nSupported foundation models 69\\nAmazon Bedrock User Guide\\nNote\\n* Some models are accessible in some Regions only through cross-region inference. To learn\\nmore about cross-region inference, see Increase throughput with cross-region inference and\\nSupported Regions and models for inference profiles.\\nThe following table lists models that have a target date for deprecation. For more information, see\\nModel lifecycle:\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAI21 J2 ai21.j2- us- Text Text, No Link N/A\\nLabs Grande grande- east-1 Chat\\nInstruct instruct\\nAI21 J2 ai21.j2- us- Text Text, No Link N/A\\nLabs Jumbo jumbo- east-1 Chat\\nInstruct instruct\\nAI21 Jurassic- ai21.j2- us- Text Text, No Link N/A\\nLabs 2 Mid mid-v1 east-1 Chat\\nAI21 Jurassic- ai21.j2- us- Text Text, No Link N/A\\n'},\n",
       " {'question': 'How can a developer use the ListFoundationModels operation in Amazon Bedrock, and what strategic advantage does this provide when building AI-powered applications?',\n",
       "  'ground_truth': 'A developer can use the ListFoundationModels operation in Amazon Bedrock by creating an Amazon Bedrock client and calling the list_foundation_models() method. This operation lists all available foundation models (FMs) in the specified AWS region. The strategic advantage this provides is twofold: First, it allows developers to dynamically discover which AI models are accessible in their region, enabling them to make informed decisions about which models to use for their specific use cases. Second, it facilitates the creation of more flexible and region-aware applications that can adapt to the available AI capabilities, potentially improving performance and reducing costs by selecting the most appropriate model for each task.',\n",
       "  'question_type': 'complex',\n",
       "  'contexts': 'languages. For more information, see Code examples for Amazon Bedrock using AWS SDKs.\\nTopics\\n• List the foundation models that Amazon Bedrock has to offer\\n• Submit a text prompt to a model and generate a text response with InvokeModel\\n• Submit a text prompt to a model and generate a text response with Converse\\nList the foundation models that Amazon Bedrock has to offer\\nThe following example runs the ListFoundationModels operation using an Amazon Bedrock client.\\nListFoundationModels lists the foundation models (FMs) that are available in Amazon Bedrock\\nin your region. Run the following SDK for Python script to create an Amazon Bedrock client and\\ntest the ListFoundationModels operation:\\n# Use the ListFoundationModels API to show the models that are available in your\\nregion.\\nimport boto3\\n# Create an &BR; client in the &region-us-east-1; Region.\\nbedrock = boto3.client(\\nservice_name=\"bedrock\"\\n)\\nbedrock.list_foundation_models()\\n If the script is successful, the response returns a list of foundation models that are available in\\nAmazon Bedrock.\\nSubmit a text prompt to a model and generate a text response with InvokeModel\\nThe following example runs the InvokeModel operation using an Amazon Bedrock client.\\nInvokeModel lets you submit a prompt to generate a model response. Run the following SDK for\\nPython script to create an Amazon Bedrock runtime client and generate a text response with the\\noperation:\\nRun examples with the AWS SDK for Python (Boto3) 21\\nAmazon Bedrock User Guide\\n# Use the native inference API to send a text message to Amazon Titan Text G1 -\\nExpress.\\nimport boto3\\nimport json\\nfrom botocore.exceptions import ClientError\\n# Create an Amazon Bedrock Runtime client.\\nbrt = boto3.client(\"bedrock-runtime\")\\n# Set the model ID, e.g., Amazon Titan Text G1 - Express.\\nmodel_id = \"amazon.titan-text-express-v1\"\\n# Define the prompt for the model.\\n prompt = \"Describe the purpose of a \\'hello world\\' program in one line.\"\\n# Format the request payload using the model\\'s native structure.\\nnative_request = {\\n\"inputText\": prompt,\\n\"textGenerationConfig\": {\\n\"maxTokenCount\": 512,\\n\"temperature\": 0.5,\\n\"topP\": 0.9\\n},\\n}\\n# Convert the native request to JSON.\\nrequest = json.dumps(native_request)\\ntry:\\n# Invoke the model with the request.\\nresponse = brt.invoke_model(modelId=model_id, body=request)\\nexcept (ClientError, Exception) as e:\\nprint(f\"ERROR: Can\\'t invoke \\'{model_id}\\'. Reason: {e}\")\\nexit(1)\\n# Decode the response body.\\nmodel_response = json.loads(response[\"body\"].read())\\n# Extract and print the response text.\\nresponse_text = model_response[\"results\"][0][\"outputText\"]\\nRun examples with the AWS SDK for Python (Boto3) 22\\nAmazon Bedrock User Guide\\nprint(response_text)\\nIf the command is successful, the response returns the text generated by the model in response to\\nthe prompt.\\n'},\n",
       " {'question': 'How can you retrieve information about all foundation models in Amazon Bedrock?',\n",
       "  'ground_truth': 'You can send a ListFoundationModels request using the Amazon Bedrock API to retrieve information about all the foundation models that Amazon Bedrock provides.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': \"• Model support by AWS Region in Amazon Bedrock\\n• Feature support by AWS Region in Amazon Bedrock\\n• Model support by feature\\n• Inference request parameters and response fields for foundation models\\n• Custom model hyperparameters\\n• Model lifecycle\\n36\\nAmazon Bedrock User Guide\\nGet information about foundation models\\nIn the Amazon Bedrock console, you can find overarching information about Amazon Bedrock\\nfoundation model providers and the models they provide in the Providers and Base models\\nsections.\\nUse the API to retrieve information about Amazon Bedrock foundation model, including its\\nARN, model ID, modalities and features it supports, and whether it is deprecated or not, in a\\nFoundationModelSummary object.\\n• To return information about all the foundation models that Amazon Bedrock provides, send a\\nListFoundationModels request.\\nNote\\nThe response also returns model IDs that aren't in the base model ID or base model IDs\\n for Provisioned Throughput charts. These model IDs are deprecated or for backwards\\ncompability.\\n• To return information about a specific foundation model, send a GetFoundationModel request,\\nspecifying the model ID.\\nChoose a tab to see code examples in an interface or language.\\nAWS CLI\\nList the Amazon Bedrock foundation models.\\naws bedrock list-foundation-models\\nGet information about Anthropic Claude v2.\\naws bedrock get-foundation-model --model-identifier anthropic.claude-v2\\nPython\\nList the Amazon Bedrock foundation models.\\nimport boto3\\nbedrock = boto3.client(service_name='bedrock')\\nGet model information 37\\nAmazon Bedrock User Guide\\nbedrock.list_foundation_models()\\nGet information about Anthropic Claude v2.\\nimport boto3\\nbedrock = boto3.client(service_name='bedrock')\\nbedrock.get_foundation_model(modelIdentifier='anthropic.claude-v2')\\nSupported foundation models in Amazon Bedrock\\nAmazon Bedrock supports foundation models (FMs) from multiple providers.\\n The following table lists each model alongside the ID that you can use to make on-demand API\\ncalls, the AWS Regions that support it, its capabilities, and links to relevant documentation:\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\nAI21 Jamba ai21.jamb us- Text Text, Yes Link N/A\\nLabs 1.5 a-1-5- east-1 Chat\\nLarge large-\\nv1:0\\nAI21 Jamba ai21.jamb us- Text Text, Yes Link N/A\\nLabs 1.5 Mini a-1-5- east-1 Chat\\nmini-\\nv1:0\\nAI21 Jamba- ai21.jamb us- Text Text, Yes Link N/A\\nLabs Instruct a- east-1 Chat\\ninstruc\\nt-v1:0\\nAmazon Nova amazon.no us- Text, Image No Link Link\\nCanvas va- east-1 Image\\nSupported foundation models 38\\nAmazon Bedrock User Guide\\nProvider Model Model Regions Input Output Streaming Inference Hyperpara\\nname ID supportedmodalitie modalitie supportedparameter meters\\ns s s\\ncanvas-\\nv1:0\\nAmazon Nova amazon.no us- Text, Text Yes Link Link\\nLite va-lite- east-1 Image,\\nv1:0 Video\\nus-\\neast-2*\\n\"},\n",
       " {'question': 'How can an organization implement fine-grained control over which Amazon Bedrock foundation models their IAM users can request access to, and what are the potential implications of this approach?',\n",
       "  'ground_truth': \"An organization can implement fine-grained control over which Amazon Bedrock foundation models their IAM users can request access to by using the aws-marketplace:ProductId condition key in combination with the aws-marketplace:Subscribe action in their IAM policies. This approach allows administrators to restrict subscription requests to specific models by their Product IDs.\\n\\nFor example, an IAM policy could be crafted to allow subscription requests only for certain models, such as Anthropic Claude and Cohere Command, by specifying their respective Product IDs (c468b48a-84df-43a4-8c46-8870630108a7 and a61c46fe-1747-41aa-9af0-2e0ae8a9ce05).\\n\\nImplications of this approach include:\\n1. Enhanced security and compliance by limiting access to only necessary models.\\n2. Potential cost control by restricting access to more expensive models.\\n3. Increased administrative overhead in managing and updating policies as new models become available or requirements change.\\n4. The need for careful planning to ensure that users have access to the most appropriate models for their tasks without overly restricting innovation or productivity.\\n\\nIt's important to note that this fine-grained control applies to requesting access, not to making inference calls. To prevent users from making inference calls to specific models, a separate IAM policy specifying the model ID would be required.\",\n",
       "  'question_type': 'complex',\n",
       "  'contexts': 'permissions to manage access to foundation models. Then, add or remove access to a model by\\nfollowing the instructions at Add or remove access to Amazon Bedrock foundation models.\\nFor information about model pricing, refer to Amazon Bedrock Pricing.\\nTopics\\n• Grant IAM permissions to request access to Amazon Bedrock foundation models\\n• Add or remove access to Amazon Bedrock foundation models\\nGrant IAM permissions to request access to Amazon Bedrock\\nfoundation models\\nBefore you can request access, or modify access, to Amazon Bedrock foundation models, you need\\nto attach an identity-based IAM policy with the following AWS Marketplace actions to the IAM role\\nthat allows access to Amazon Bedrock:\\n• aws-marketplace:Subscribe\\n• aws-marketplace:Unsubscribe\\n• aws-marketplace:ViewSubscriptions\\nFor information creating the policy, see I already have an AWS account.\\nFor the aws-marketplace:Subscribe action only, you can use the aws-\\n marketplace:ProductId condition key to restrict subscription to specific models.\\nGrant permissions to request access to foundation models 29\\nAmazon Bedrock User Guide\\nNote\\nYou can\\'t remove request access from the Amazon Titan, Mistral AI, and Meta Llama 3\\nInstruct models. You can prevent users from making inference calls to these models by\\nusing an IAM policy and specifying the model ID. For more information, see Deny access for\\ninference of foundation models.\\nThe following table lists product IDs for Amazon Bedrock foundation models:\\nThe following is the format of the IAM policy you can attach to a role to control model access\\npermissions:\\nModel Product ID\\nAI21 Labs Jurassic-2 Mid 1d288c71-65f9-489a-a3e2-9c7f4f6e6a85\\nAI21 Labs Jurassic-2 Ultra cc0bdd50-279a-40d8-829c-4009b77a1fcc\\nAI21 Jamba-Instruct prod-dr2vpvd4k73aq\\nAI21 Labs Jamba 1.5 Large prod-evcp4w4lurj26\\nAI21 Labs Jamba 1.5 Mini prod-ggrzjm65qmjhm\\nAnthropic Claude c468b48a-84df-43a4-8c46-8870630108a7\\n Anthropic Claude Instant b0eb9475-3a2c-43d1-94d3-56756fd43737\\nAnthropic Claude 3 Sonnet prod-6dw3qvchef7zy\\nAnthropic Claude 3.5 Sonnet prod-m5ilt4siql27k\\nAnthropic Claude 3.5 Sonnet v2 prod-cx7ovbu5wex7g\\nAnthropic Claude 3 Haiku prod-ozonys2hmmpeu\\nAnthropic Claude 3.5 Haiku prod-5oba7y7jpji56\\nAnthropic Claude 3 Opus prod-fm3feywmwerog\\nGrant permissions to request access to foundation models 30\\nAmazon Bedrock User Guide\\nModel Product ID\\nCohere Command a61c46fe-1747-41aa-9af0-2e0ae8a9ce05\\nCohere Command Light 216b69fd-07d5-4c7b-866b-936456d68311\\nCohere Command R prod-tukx4z3hrewle\\nCohere Command R+ prod-nb4wqmplze2pm\\nCohere Embed (English) b7568428-a1ab-46d8-bab3-37def50f6f6a\\nCohere Embed (Multilingual) 38e55671-c3fe-4a44-9783-3584906e7cad\\nCohere Rerank 3.5 prod-2o5bej62oxkbi\\nStable Diffusion XL 1.0 prod-2lvuzn4iy6n6o\\nStable Image Core 1.0 prod-eacdrmv7zfc5e\\nStable Diffusion 3 Large 1.0 prod-cqfmszl26sxu4\\nStable Image Ultra 1.0 prod-7boen2z2wnxrg\\n{\\n\"Version\": \"2012-10-17\",\\n'},\n",
       " {'question': 'Which region supports the most AI models in Amazon Bedrock?',\n",
       "  'ground_truth': 'US East (N. Virginia) supports the most AI models in Amazon Bedrock, with \"Yes\" indicated for several models across different providers.',\n",
       "  'question_type': 'simple',\n",
       "  'contexts': 'AI\\nMistral\\nLarge\\n(24.07)\\nMistral\\nYes No No No No No No No No No No No No No No No No\\nAI\\nMistral\\nSmall\\n(24.02)\\nMistral\\nYes No Yes No No No No Yes No Yes Yes No No GatedYes Yes Yes\\nAI\\nMixtral\\n8x7B\\nInstruct\\nStability\\nNo No Yes No No No No No No No No No No No No No No\\nAI\\nSD3\\nLarge\\n1.0\\nStability\\nNo No Yes No No No No No No No No No No No No No No\\nAI\\nStable\\nDiffusion\\n3.5\\nLarge\\nModel support by Region 79\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nStability\\nNo No Yes No No No No No No No No No No No No No No\\nAI\\nStable\\nImage\\nCore\\n1.0\\nStability\\nNo No Yes No No No No No No No No No No No No No No\\nAI\\nStable\\nImage\\nCore\\n1.0\\nStability\\n No No Yes No No No No No No No No No No No No No No\\nAI\\nStable\\nImage\\nUltra\\n1.0\\nStability\\nNo No Yes No No No No No No No No No No No No No No\\nAI\\nStable\\nImage\\nUltra\\n1.0\\nModel support by Region 80\\nAmazon Bedrock User Guide\\nNote\\n* Some models are accessible in some Regions only through cross-region inference. To learn\\nmore about cross-region inference, see Increase throughput with cross-region inference and\\nSupported Regions and models for inference profiles.\\nThe following table shows Region support for models that have a target date for deprecation. For\\nmore information, see Model lifecycle.\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJ2\\n Grande\\nInstruct\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJ2\\nJumbo\\nInstruct\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJurassic-\\n2\\nMid\\nAI21\\nYes No No No No No No No No No No No No No No No No\\nLabs\\nJurassic-\\nModel support by Region 81\\nAmazon Bedrock User Guide\\nModeUlsS US US AWS AWS Asia Asia Asia Asia Asia CanadEau ropEeu ropEeu ropEeu ropEeu ropSeo uth\\nEast East West GovClGoouvdC lPoaucdifi Pc acifiPc acifiPc acifiPc acifi(cC ent(rFarla)nk(Zfuurr ic(hIr)elan(Ldo)nd(oPna)risA)merica\\n(N. (Ohio()Oreg(oUnS)- (US- (Toky(oS)eou(lM) um(bSaini)ga(Spyodrn ey) t) (São\\nVirginia) East)West) e) Paulo)\\n2\\nUltra\\nStability\\nYes No Yes No No No No No No No No No No No No No No\\nAI\\nSDXL\\n1.0\\nTo learn more about Region and model support for specific features, see the following links:\\n• Converse API\\n• Batch inference\\n• Inference profiles\\n• Latency optimization\\n• Prompt management\\n• Prompt management\\n• Prompt optimization\\n• Amazon Bedrock Guardrails\\n• Model evaluation\\n'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_qa_dataset(chunks_with_metadata, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
